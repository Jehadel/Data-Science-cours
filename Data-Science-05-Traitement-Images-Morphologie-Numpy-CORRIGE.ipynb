{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science 5 : Traitement d'Images avec Python et Filtres Morphologiques\n",
    "\n",
    "Enseignant : Jean Delpech\n",
    "\n",
    "Cours : Data Science\n",
    "\n",
    "Classe : M1 Data/IA\n",
    "\n",
    "Année scolaire : 2025/2026\n",
    "\n",
    "Dernière mise à jour : janvier 2026\n",
    "\n",
    "## Module Data Science M1 - Séances 11 & 12\n",
    "\n",
    "**Objectifs du cours :**\n",
    "- Rappels : Comprendre la représentation numérique des images (pixels, canaux, dimensions)\n",
    "- Rappels : Maîtriser la manipulation d'images avec NumPy\n",
    "- Rappels : Comprendre les espaces colorimétriques (RGB, niveaux de gris, HSV)\n",
    "- Comprendre les fondements mathématiques de la morphologie mathématique\n",
    "- Implémenter des filtres morphologiques \"from scratch\" avec NumPy\n",
    "- Appliquer ces techniques à des cas d'usage réels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports et configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install jupyterlab-mathjax2=4.0.0 # installer s’il y a des pb dans l’affichage des formules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from PIL import Image\n",
    "\n",
    "# Configuration\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Représentation Numérique des Images\n",
    "\n",
    "### 1.1 Qu'est-ce qu'une image numérique ?\n",
    "\n",
    "Une **image numérique** est une matrice de valeurs numériques. Chaque élément est un **pixel**.\n",
    "\n",
    "| Propriété | Description |\n",
    "|-----------|-------------|\n",
    "| **Hauteur (H)** | Nombre de lignes de pixels |\n",
    "| **Largeur (W)** | Nombre de colonnes de pixels |\n",
    "| **Canaux (C)** | 1 pour gris, 3 pour RGB |\n",
    "| **Profondeur** | 8 bits → valeurs 0-255 |\n",
    "\n",
    "Exemple de création d’une image en niveaux de gris (un seul canal) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image en niveaux de gris 5x5\n",
    "img_gray_simple = np.array([\n",
    "    [0,   0,   0,   0,   0],\n",
    "    [0, 128, 128, 128,   0],\n",
    "    [0, 128, 255, 128,   0],\n",
    "    [0, 128, 128, 128,   0],\n",
    "    [0,   0,   0,   0,   0]\n",
    "], dtype=np.uint8)\n",
    "\n",
    "print(f\"Shape : {img_gray_simple.shape}\")\n",
    "print(f\"Type : {img_gray_simple.dtype}\")\n",
    "print(f\"Min/Max : {img_gray_simple.min()} / {img_gray_simple.max()}\")\n",
    "\n",
    "# Visualisation\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "axes[0].imshow(img_gray_simple, cmap='gray', vmin=0, vmax=255)\n",
    "axes[0].set_title('Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "im = axes[1].imshow(img_gray_simple, cmap='gray', vmin=0, vmax=255)\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        color = 'white' if img_gray_simple[i, j] < 128 else 'black'\n",
    "        axes[1].text(j, i, str(img_gray_simple[i, j]), ha='center', va='center', color=color)\n",
    "axes[1].set_title('Valeurs des pixels')\n",
    "axes[1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Images couleur RGB\n",
    "\n",
    "Pour créer une image en couleur, selon la logique de la synthèse additive (cf. cours [Data-Science 01](./Data-Science-01-vecteurs-kmeans.ipynb), section illustration pratique des combinaisons linéaires), on va encoder l’image sur 3 canaux, c’est-à-dire 3 matrices de couleurs élémentaires, dont la combinaison va donner une couleur donnée à l’écran. Par exemple un pixel jaune sera un mélange de rouge et de vert :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'une image RGB\n",
    "img_rgb = np.zeros((100, 100, 3), dtype=np.uint8)\n",
    "img_rgb[0:50, 0:50] = [255, 0, 0]      # Rouge\n",
    "img_rgb[0:50, 50:100] = [0, 255, 0]    # Vert\n",
    "img_rgb[50:100, 0:50] = [0, 0, 255]    # Bleu\n",
    "img_rgb[50:100, 50:100] = [255, 255, 0] # Jaune\n",
    "\n",
    "print(f\"Shape RGB : {img_rgb.shape}\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(14, 3))\n",
    "axes[0].imshow(img_rgb)\n",
    "axes[0].set_title('Image RGB')\n",
    "axes[0].axis('off')\n",
    "\n",
    "for i, (titre, cmap) in enumerate([('Rouge', 'Reds'), ('Vert', 'Greens'), ('Bleu', 'Blues')]):\n",
    "    axes[i+1].imshow(img_rgb[:, :, i], cmap=cmap, vmin=0, vmax=255)\n",
    "    axes[i+1].set_title(f'Canal {titre}')\n",
    "    axes[i+1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Image exemple pour le cours\n",
    "\n",
    "Créons une image de manière procédurale, qui nous servira d’exemple pour le cours et nous permettra de bien voir les manipulation et transformations que nous allons implémenter :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creer_image_exemple():\n",
    "    \"\"\"Crée une image d'exemple.\"\"\"\n",
    "    h, w = 256, 256\n",
    "    img = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Dégradé\n",
    "    for i in range(h):\n",
    "        img[i, :, 0] = int(100 + 100 * np.sin(i * np.pi / h))\n",
    "        img[i, :, 2] = int(100 + 100 * np.cos(i * np.pi / h))\n",
    "    \n",
    "    # Cercle\n",
    "    y, x = np.ogrid[:h, :w]\n",
    "    mask = (x - w//2)**2 + (y - h//2)**2 <= 60**2\n",
    "    img[mask] = [255, 200, 100]\n",
    "    \n",
    "    # Rectangle\n",
    "    img[30:80, 30:120] = [50, 180, 50]\n",
    "    return img\n",
    "\n",
    "img_exemple = creer_image_exemple()\n",
    "\n",
    "print(f\"Shape: {img_exemple.shape}, Type: {img_exemple.dtype}\")\n",
    "print(f\"Pixels: {img_exemple.shape[0] * img_exemple.shape[1]:,}\")\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(img_exemple)\n",
    "plt.title('Image exemple')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 1 : Exploration d'une image\n",
    "\n",
    "Un petit exercice simple pour vérfier que vous avez bien assimilé les concepts de base : indiquez les caractéristique de cette image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCICE - Votre code !\n",
    "\n",
    "hauteur = #???  # Votre code\n",
    "largeur = #???  \n",
    "pixel_centre = #???  # np.array qui correspond au pixel au centre de l’image\n",
    "moyenne_rouge = #???\n",
    "moyenne_vert = #???\n",
    "moyenne_bleu = #???\n",
    "\n",
    "print(f\"Dimensions : {hauteur} x {largeur}\")\n",
    "print(f\"Pixel central : {pixel_centre}\")\n",
    "print(f\"Moyennes : R={moyenne_rouge:.1f}, G={moyenne_vert:.1f}, B={moyenne_bleu:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRIGÉ\n",
    "hauteur = img_exemple.shape[0]\n",
    "largeur = img_exemple.shape[1]\n",
    "pixel_centre = img_exemple[hauteur // 2, largeur // 2]\n",
    "moyenne_rouge = img_exemple[:, :, 0].mean()\n",
    "moyenne_vert = img_exemple[:, :, 1].mean()\n",
    "moyenne_bleu = img_exemple[:, :, 2].mean()\n",
    "\n",
    "print(f\"Dimensions : {hauteur} x {largeur}\")\n",
    "print(f\"Pixel central : R={pixel_centre[0]}, G={pixel_centre[1]}, B={pixel_centre[2]}\")\n",
    "print(f\"Moyennes : R={moyenne_rouge:.1f}, G={moyenne_vert:.1f}, B={moyenne_bleu:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Conversion en Niveaux de Gris\n",
    "\n",
    "### 2.1 Le retour de la combinaison linéaire\n",
    "\n",
    "En data science, lorsque nous aurons à analyser ou traiter des images, la couleur n’est pas toujours une information pertinente. Cela dépend évidemment de la tâche précise à accomplir, mais par exemple pour de la reconnaissance de forme ou de la classification « en général », ainsi on arrive très bien à discriminer un chat d’un chien sur une image en noir et blanc.\n",
    "\n",
    "Les images en noir et blanc (ou plus exactement « niveaux de gris ») étant codées sur un seul canal vs 3 canaux pour les images en couleur, il y a une différence significative en matière de ressources nécessaires au traitement d’une image en niveau de gris comparativement aux images en couleur (mémoire, temps de calcul, etc.)\n",
    "\n",
    "Une transformation à laquelle on procédera souvent sera donc la conversion d’une image en couleur en niveaux de gris, passer de 3 canaux à un seul. Il est presque intuitif que pour parvenir à ce résultat en conservant une part de l’information, on peut simplement réaliser une combinaison linéaire des valeurs des 3 canaux :\n",
    "\n",
    "$$\n",
    "niveau_gris = \\alpha · R + \\beta · G + \\gamma · B\n",
    "$$\n",
    "\n",
    "Mais quelle valeur choisir pour les coefficients $\\alpha$, $\\beta$ et $\\gamma$ ?\n",
    "\n",
    "Cela dépend de la « force » relative des canaux, de l’information que l’on veut conserver, et – encore une fois – de la tâche à accomplir.\n",
    "\n",
    "Par exemple, pour un-e photographe, un-e graphiste, un-e monteur, un-e artiste numérique, etc., la dimension esthétique sera primordiale, et pour obtenir une image finale conforme à ses desseins, il mixera par exemple les canaux de manière à obtenir une image en niveau de gris bien contrastée, équilibrée, avec des noirs profonds et des blancs éclatants sans perdre d’information (préserver les détails dans les ombres et les « hautes lumières »).\n",
    "\n",
    "Pour cela, il peut être intéressant de regarder comment son distribués les valeurs dans chaque canal, qu’il est courant de représenter sous forme d’histogramme (cf. des logiciels comme Photoshop ou Gimp) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "axes[0].hist(img_exemple[:, :, 0].flatten(), bins=256, color='red')\n",
    "axes[0].set_title('Histogramme canal rouge')\n",
    "\n",
    "axes[1].hist(img_exemple[:, :, 1].flatten(), bins=256, color='green')\n",
    "axes[1].set_title('Histogramme canal vert')\n",
    "\n",
    "axes[2].hist(img_exemple[:, :, 2].flatten(), bins=256, color='blue')\n",
    "axes[2].set_title('Histogramme canal bleu')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate que sur notre image :\n",
    "* les pixels rouges :\n",
    "    * ont en majorité des valeurs assez ressérées entre 100 et 200,\n",
    "    * un grand nombre sont très rouges (avec une valeur précise au dessus de 250)\n",
    "    * quelques uns sont faiblement rouge à 50\n",
    "* les pixels verts :\n",
    "    * la plupart ont une valeur de 0 (en réalité il n’y a que peu de pixels verts dans notre image)\n",
    "    * deux valeurs minoritaire avec des valeurs précises en dessous de 200\n",
    "* les pixels bleus :\n",
    "    * ils sont ditribués de manière équilibrée entre 0 et 200\n",
    "    * on distingue quelques pics (0, 50, 100 et 200)\n",
    "\n",
    "Comment interpréter les caractéristiques de ces ditributions ?\n",
    "\n",
    "* Pour le vert : on voit clairement que le vert ne figure pas parmi les dominantes de notre image. Il y a un rectangle uniformément vert, ce qui explique un des deux pics observés autour de 200, et un disque uniformément jaune (mélange de rouge et de vert), ce qui explique l’autre pic vert, ainsi que l’un des pics rouge (200 ou au dessus de 250). Pour le bleu, il est très présent dans le dégradé du fond, ce qui explique sa répartition équilibrée (avec la dominante rouge traduite par des valeurs plus ressérée), et notamment les couleurs violettes / pourpres sur le haut de l’image.\n",
    "\n",
    "Une autre méthode consiste à suivre des **normes** ou **spécifications** : des espaces colorimétriques avec des caractéristiques définies précisément (souvent liées à une méthode d’affichage spécifique) peuvent définir des correspondances, par exemple pour la spécification Rec. 601, la pondération est la suivante :\n",
    "\n",
    "$$\n",
    "niveau_gris = 0.299 · R + 0.587 · G + 0.114 · B\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_vers_gris(img_rgb):\n",
    "    \"\"\"Convertit RGB en niveaux de gris (Rec. 601).\"\"\"\n",
    "    return (0.299 * img_rgb[:, :, 0] + \n",
    "            0.587 * img_rgb[:, :, 1] + \n",
    "            0.114 * img_rgb[:, :, 2]).astype(np.uint8)\n",
    "\n",
    "img_gris = rgb_vers_gris(img_exemple)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes[0].imshow(img_exemple)\n",
    "axes[0].set_title('RGB')\n",
    "axes[0].axis('off')\n",
    "axes[1].imshow(img_gris, cmap='gray')\n",
    "axes[1].set_title('Niveaux de gris')\n",
    "axes[1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien sûr nous avons détaillé là, pour votre culture générale de développeur, des considérations purement esthétiques (ou techniques, en matière d’étalonnage), ces considérations concernent assez peu le data scientist qui se contentera généralement d’un mixage uniforme des canaux, sauf besoins métiers ou situations particulières (vous saurez alors comment faire).\n",
    "\n",
    "**Point important** : n’oubliez pas, lorsque vous calculez votre combinaison, de **normaliser** le résultat ! (par exemple, si vos pixels sont encodés en 8 bits, il faut notamment que la valeur maximum obtenue soit de 255).\n",
    "\n",
    "### 2.2 Aller un peu plus loin avec les histogrammes\n",
    "\n",
    "Commençons par créer une fonction qui permet d’afficher un histogramme d’une image en niveau de gris (ou d’un canal d’une image en couleur) avec quelques statistiques :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def afficher_histogramme(image, titre=\"Histogramme\", bins=256, afficher_stats=True, \n",
    "                         afficher_image=True, ax=None):\n",
    "    \"\"\"\n",
    "    Affiche l'histogramme d'une image en niveaux de gris ou d'un canal couleur,\n",
    "    avec optionnellement l'image elle-même à côté.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    image : ndarray\n",
    "        Image 2D (niveaux de gris ou canal unique).\n",
    "        Accepte uint8 (0-255) ou float (0-1).\n",
    "    titre : str\n",
    "        Titre du graphique.\n",
    "    bins : int\n",
    "        Nombre de bins pour l'histogramme (défaut: 256).\n",
    "    afficher_stats : bool\n",
    "        Si True, affiche moyenne, écart-type, min, max.\n",
    "    afficher_image : bool\n",
    "        Si True (défaut), affiche l'image à gauche de l'histogramme.\n",
    "    ax : matplotlib.axes.Axes, optional\n",
    "        Axes sur lesquels tracer l'histogramme. Si None, crée une nouvelle figure.\n",
    "        Note: si afficher_image=True et ax=None, crée une figure avec 2 sous-graphiques.\n",
    "              si afficher_image=True et ax fourni, l'image n'est pas affichée (ignoré).\n",
    "    \n",
    "    Retourne\n",
    "    --------\n",
    "    axes : matplotlib.axes.Axes ou tuple of Axes\n",
    "        L'objet axes du graphique (ou tuple (ax_image, ax_hist) si afficher_image=True).\n",
    "    \n",
    "    Exemples\n",
    "    --------\n",
    "    >>> afficher_histogramme(image_gris)\n",
    "    >>> afficher_histogramme(image_rgb[:, :, 0], titre=\"Canal Rouge\")\n",
    "    >>> afficher_histogramme(image_gris, afficher_image=False)  # histogramme seul\n",
    "    \"\"\"\n",
    "    # Validation\n",
    "    if image.ndim != 2:\n",
    "        raise ValueError(f\"L'image doit être 2D (reçu: {image.ndim}D). \"\n",
    "                        \"Pour une image RGB, passez un canal: image[:, :, 0]\")\n",
    "    \n",
    "    # Détection du type et normalisation\n",
    "    if image.dtype == np.uint8:\n",
    "        vmin, vmax = 0, 255\n",
    "        xlabel = \"Intensité (0-255)\"\n",
    "    elif np.issubdtype(image.dtype, np.floating):\n",
    "        if image.max() <= 1.0:\n",
    "            vmin, vmax = 0, 1\n",
    "            xlabel = \"Intensité (0-1)\"\n",
    "        else:\n",
    "            vmin, vmax = 0, 255\n",
    "            xlabel = \"Intensité\"\n",
    "    else:\n",
    "        vmin, vmax = image.min(), image.max()\n",
    "        xlabel = \"Intensité\"\n",
    "    \n",
    "    # Création de la figure\n",
    "    if ax is None:\n",
    "        if afficher_image:\n",
    "            fig, (ax_img, ax_hist) = plt.subplots(1, 2, figsize=(12, 4),\n",
    "                                                   gridspec_kw={'width_ratios': [1, 1.3]})\n",
    "        else:\n",
    "            fig, ax_hist = plt.subplots(figsize=(10, 5))\n",
    "            ax_img = None\n",
    "    else:\n",
    "        # Si ax est fourni, on l'utilise pour l'histogramme (pas d'image)\n",
    "        ax_hist = ax\n",
    "        ax_img = None\n",
    "        if afficher_image:\n",
    "            import warnings\n",
    "            warnings.warn(\"afficher_image ignoré car ax est fourni. \"\n",
    "                         \"Pour afficher l'image, ne passez pas ax.\")\n",
    "    \n",
    "    # Affichage de l'image\n",
    "    if ax_img is not None:\n",
    "        ax_img.imshow(image, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "        ax_img.set_title(\"Image\", fontsize=12, fontweight='bold')\n",
    "        ax_img.axis('off')\n",
    "    \n",
    "    # Tracé de l'histogramme\n",
    "    pixels = image.flatten()\n",
    "    counts, bin_edges, patches = ax_hist.hist(pixels, bins=bins, range=(vmin, vmax), \n",
    "                                               color='steelblue', edgecolor='black', \n",
    "                                               alpha=0.7, linewidth=0.5)\n",
    "    \n",
    "    # Mise en forme\n",
    "    ax_hist.set_xlabel(xlabel, fontsize=11)\n",
    "    ax_hist.set_ylabel(\"Nombre de pixels\", fontsize=11)\n",
    "    ax_hist.set_title(titre, fontsize=12, fontweight='bold')\n",
    "    ax_hist.set_xlim(vmin, vmax)\n",
    "    ax_hist.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # Statistiques\n",
    "    if afficher_stats:\n",
    "        moyenne = np.mean(pixels)\n",
    "        ecart_type = np.std(pixels)\n",
    "        val_min = np.min(pixels)\n",
    "        val_max = np.max(pixels)\n",
    "        \n",
    "        # Ligne de moyenne\n",
    "        ax_hist.axvline(x=moyenne, color='red', linestyle='-', linewidth=2, \n",
    "                        label=f'Moyenne: {moyenne:.1f}')\n",
    "        \n",
    "        # Zone ±1 écart-type\n",
    "        ax_hist.axvspan(moyenne - ecart_type, moyenne + ecart_type, \n",
    "                        alpha=0.2, color='red', label=f'±σ: {ecart_type:.1f}')\n",
    "        \n",
    "        # Boîte de stats\n",
    "        stats_text = (f\"Moyenne: {moyenne:.1f}\\n\"\n",
    "                     f\"Écart-type: {ecart_type:.1f}\\n\"\n",
    "                     f\"Min: {val_min:.1f}\\n\"\n",
    "                     f\"Max: {val_max:.1f}\")\n",
    "        \n",
    "        ax_hist.text(0.97, 0.95, stats_text, transform=ax_hist.transAxes, fontsize=10,\n",
    "                     verticalalignment='top', horizontalalignment='right',\n",
    "                     bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "        \n",
    "        ax_hist.legend(loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Retour\n",
    "    if ax_img is not None:\n",
    "        return ax_img, ax_hist\n",
    "    else:\n",
    "        return ax_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data\n",
    "img_chat = data.cat()\n",
    "for i in range(3):\n",
    "    print(\"=\"*10 + \"\\n\")\n",
    "    print(f\"Canal {i+1}\")\n",
    "    afficher_histogramme(img_chat[:,:,i], titre=\"Image de chat\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Dynamique d’un histogramme\n",
    "\n",
    "Les valeurs des pixels d’une image peuvent aller de 0 à 255 (en uint8). Pour différentes raisons, les images ne contiennent pas toujours des pixels qui contiennent toutes ces valeurs, pour des raisons esthétiques (faites une recherche high key/low key dans un moteur de recherches d’images) ou un problème d’exposition, de compression, etc. Une image qui contient un maximum d’information exploite la totalité de l’histogramme. Esthétiqueemnt, le fait qu’une photographie exploite toute la gamme de valeur est un critère notable (vous pouvez d’ailleurs voir que les images high/low key de qualité, si elles ont une dominante claire ou sombre, n’en contiennent pas moins des pixels avec toutes les valeurs, ce qui crée de beaux volumes par exemples). \n",
    "\n",
    "Nous pouvons explorer et modifier cette dynamique. Par exemples chargez l’image `images/histo-dyn-comp.jpg` : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "img = np.array(Image.open('images/histo-dyn-comp.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afficher les histogrammes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    afficher_histogramme(img[:,:,i], titre=\"Image dynamique histogramme\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate que l’histogramme est complètement compressé sur la gauche (valeurs proches de zéro, de 0 à 8), et on n’affiche donc qu’une image noire.\n",
    "\n",
    "Pour remédier à cela, il faut calculer une nouvelle image I’ avec des pixels dont les valeurs  s’étendent sur l’intervalle $[0, 255]$ en appliquant une transformation aux pixels de l’image I originale dont les valeurs appartiennent à $[0, 8]$.\n",
    "\n",
    "On peut s’en sortir avec une simple transformation linéaire :\n",
    "\n",
    "$$\n",
    "I’(i, j) = \\frac{I(i, j) - min_{i,j}I}{max_{i,j} I - min_{i,j} I} · (a - b) + a\n",
    "$$\n",
    "\n",
    "avec $a$ et $b$ l’intervalle voulu pour les valeurs des pixels de la nouvelle image.\n",
    "\n",
    "Complétez la fonction suivante en implémentant la formule ci-dessus :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etirer_dynamique(image, a=0, b=255):\n",
    "    \"\"\"\n",
    "    Étire la dynamique d'une image par transformation linéaire.\n",
    "    \n",
    "    Transforme les valeurs de pixels pour qu'elles occupent l'intervalle [a, b].\n",
    "    \n",
    "    Formule : I'(i,j) = (I(i,j) - min(I)) / (max(I) - min(I)) × (b - a) + a\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    image : ndarray\n",
    "        Image 2D en niveaux de gris.\n",
    "    a : float\n",
    "        Valeur minimale de l'intervalle de sortie (défaut: 0).\n",
    "    b : float\n",
    "        Valeur maximale de l'intervalle de sortie (défaut: 255).\n",
    "    \n",
    "    Retourne\n",
    "    --------\n",
    "    image_etiree : ndarray\n",
    "        Image avec la dynamique étendue à [a, b].\n",
    "        Même type que l'image d'entrée si uint8, sinon float.\n",
    "    \"\"\"\n",
    "    img_float = image.astype(np.float64)\n",
    "    \n",
    "    val_min = img_float.min()\n",
    "    val_max = img_float.max()\n",
    "    \n",
    "    if val_max == val_min:\n",
    "        image_etiree = np.full_like(img_float, (a + b) / 2)\n",
    "    else:\n",
    "        image_etiree = (img_float - val_min) / (val_max - val_min) * (b - a) + a\n",
    "    \n",
    "    image_etiree = np.clip(image_etiree, a, b)\n",
    "    \n",
    "    if a == 0 and b == 255:\n",
    "        return image_etiree.astype(np.uint8)\n",
    "    else:\n",
    "        return image_etiree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# étirer la dynamique de l’image donnée en exemple\n",
    "img_etiree = etirer_dynamique(img[:,:,0])\n",
    "# afficher l’image et l’histogramme\n",
    "afficher_histogramme(img_etiree, titre=\"Image - histogramme étiré\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque néanmoins que cette méthode ne fait pas de miracle : on passe de 9 valeurs (de 0 à 8) à toujours 9 valeurs, mais étalées entre 0 et 255 (ce qui rend l’image lisible à un œil humain).\n",
    "\n",
    "Dans l’exemple ci-dessus nous n’avons étiré l’histogramme d’un seul canal. Si vous voulez traiter une image en couleur, il faut bien sûr appliquer le traitement sur les 3 canaux (en prenant garde à la balance entre les couleurs). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 Égalisation d’un histogramme\n",
    "\n",
    "Nous pouvons généraliser la démarche vue à la section précédente, pour apporter toutes sortes de transformations à l’histogramme d’une image. \n",
    "\n",
    "Appliquer une transformation revient à créer une fonction qui met en correspondance une valeur donnée d’un ensemble de pixels de l’image d’origine avec une autre valeur pour les pixels correspondants de l’image transformée. Cette fonction de correspondance peut être représentée par ce que l’on va appeler une *lookup table* ou **LUT**. Une LUT peut représenter des fonctions linéaires ou non linéaires. Un bon exemple est l’outil `courbes` des logiciels de traitement d’image, comme *Photoshop* ou *Gimp* :\n",
    "\n",
    "![L’outil courbes de Gimp](./images/LUT-histo.png)\n",
    "\n",
    "Sur cette capture d’écran de l’outil `courbes` de Gimp, on distingue l’histogramme, en ordonnées les valeurs de sorties (image transformée) mises en correspondance avec les valeurs d’entrée en abscisse par la courbe que l’on peut modifier à la main (transforamtion non linéaire). On distingue également la droite $y = x$, qui est la transformation identité (pas de transformation), une transformation linéaire serait représentée par une droite de pente différente avec possiblement un décalage (offset). \n",
    "\n",
    "On peut distinguer des LUT avec un effet typique :\n",
    "\n",
    "* $f(x) = 255 - x$ (inversion de la pente de la droite avec origine à 255) correspondra  à l’inversion (effet « négatif » ) des valeurs de l’image, c’est une transformation linéaire\n",
    "* $f(x) = x + a$ avec $ a > 0$ correspondra à une augmentation uniforme (linéaire) de la luminosité (valeurs) de l’image (attention à écréter les valeurs à 255 ensuite). On peut bien sûr limiter cette augmentation de la luminosité à certains pixels (p. ex. les plus sombres) en posant des conditions d’application de la transformation.\n",
    "* nous avons vu dans la section précédente l’étirement de la dynamique qui est une transformation linéaire également \n",
    "* l’égalisation d’histogramme qui est une transformation non-linéaire qui permet par exemple d’ajuster le contraste d’une image en répartissant plus uniformément les valeurs des pixels sur toute l’étendue des niveaux de gris (nous détaillons la formule ci-dessous)\n",
    "* la correction gamma, qui est aussi une transformation linéaire à laquelle nous consacrons la section suivante\n",
    "\n",
    "Pour revenir à l’égalisation, l'objectif de l'égalisation est de redistribuer les niveaux de gris pour que l'histogramme devienne approximativement uniforme, ce qui maximise le contraste de l'image (autant de valeurs sombres que de valeurs moyennes et de valeurs claires). Pour cela revenons aux concepts d’histogrammes normalisés et cumulés (revoyez votre cours sur les distributions) :\n",
    "\n",
    "##### Histogramme normalisé $H(i)$\n",
    "\n",
    "L'histogramme normalisé représente la probabilité qu'un pixel ait l'intensité $i$ :\n",
    "\n",
    "$$\n",
    "H(i) = \\frac{\\text{nombre de pixels d'intensité } i}{\\text{nombre total de pixels}}\n",
    "$$\n",
    "\n",
    "Par exemple, si une image de 1000 pixels contient 50 pixels d'intensité 120, alors $H(120)=0.05$ (soit 5%).\n",
    "\n",
    "##### Histogramme cumulé C(k)\n",
    "\n",
    "$C(k)$ représente la probabilité qu'un pixel ait une intensité inférieure ou égale à $k$ :\n",
    "\n",
    "$$\n",
    "C(k) = \\sum_{i=0}^{k} H(i)\n",
    "$$\n",
    "\n",
    "C'est la somme progressive des probabilités. Par construction :\n",
    "\n",
    "* $C(0)=H(0)$ (probabilité d'avoir la valeur 0)\n",
    "* $C(k)$ croît de façon monotone\n",
    "* $C(255)=1$ (100% des pixels ont une valeur ≤ 255)\n",
    "\n",
    "En statistiques, $C(k)$ correspond à la fonction de répartition (**CDF** ou *Cumulative Distribution Function*) de la distribution des intensités.\n",
    "\n",
    "##### Fonction de transfert (LUT)\n",
    "\n",
    "La LUT qui transforme chaque niveau de gris $i$ en sa nouvelle valeur $i′$ est simplement :\n",
    "\n",
    "$$\n",
    "f(i) = L \\times C(i)\n",
    "$$\n",
    "où $L=255$ est le niveau de gris maximal.\n",
    "\n",
    "La logique derrière cette formule est que la CDF $C(i)$ varie entre 0 et 1. \n",
    "En la multipliant par 255, on \"étale\" les valeurs sur toute la plage [0, 255]. Les niveaux de gris fréquents (où $C$ augmente rapidement) seront davantage espacés, tandis que les niveaux rares seront compressés. Le résultat est un histogramme approximativement uniforme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def egaliser_histogramme(image):\n",
    "    \"\"\"\n",
    "    Égalise l'histogramme d'une image pour améliorer le contraste.\n",
    "    \n",
    "    L'égalisation redistribue les niveaux de gris pour que l'histogramme\n",
    "    soit approximativement uniforme, maximisant ainsi le contraste.\n",
    "    \n",
    "    Principe :\n",
    "    1. Calculer l'histogramme normalisé (probabilités)\n",
    "    2. Calculer l'histogramme cumulé (CDF)\n",
    "    3. Utiliser le CDF comme fonction de transformation\n",
    "    \n",
    "    Formule : I'(i,j) = (L-1) × CDF(I(i,j))\n",
    "              où L = 256 (nombre de niveaux de gris)\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    image : ndarray\n",
    "        Image 2D en niveaux de gris (uint8).\n",
    "    \n",
    "    Retourne\n",
    "    --------\n",
    "    image_egalisee : ndarray (uint8)\n",
    "        Image avec histogramme égalisé.\n",
    "    cdf : ndarray\n",
    "        Fonction de distribution cumulative (pour visualisation).\n",
    "    \"\"\"\n",
    "    # Vérification\n",
    "    if image.dtype != np.uint8:\n",
    "        image = np.clip(image, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    # 1. Histogramme (compte de pixels pour chaque niveau 0-255)\n",
    "    hist, bins = np.histogram(image.flatten(), bins=256, range=(0, 256))\n",
    "    \n",
    "    # 2. Histogramme normalisé (probabilités)\n",
    "    hist_norm = hist / hist.sum()\n",
    "    \n",
    "    # 3. CDF (Cumulative Distribution Function)\n",
    "    cdf = np.cumsum(hist_norm)\n",
    "    \n",
    "    # 4. Transformation : utiliser le CDF comme LUT (Look-Up Table)\n",
    "    # CDF va de 0 à 1, on le mappe vers [0, 255]\n",
    "    lut = (cdf * 255).astype(np.uint8)\n",
    "    \n",
    "    # 5. Appliquer la transformation\n",
    "    image_egalisee = lut[image]\n",
    "    \n",
    "    return image_egalisee, cdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 2\n",
    "\n",
    "Voici un exemple pas à pas d’égalisation d’histogramme sur une image simple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def demo_egalisation_pas_a_pas():\n",
    "    \"\"\"\n",
    "    Démonstration pas à pas de l'égalisation d'histogramme\n",
    "    avec un exemple numérique simple.\n",
    "    \"\"\"\n",
    "    \n",
    "    # =========================================================================\n",
    "    # EXEMPLE SIMPLIFIÉ : Image 4x4 avec seulement 8 niveaux de gris (0-7)\n",
    "    # =========================================================================\n",
    "    \n",
    "    # Image exemple (4x4 = 16 pixels, niveaux 0-7)\n",
    "    image_simple = np.array([\n",
    "        [1, 2, 3, 2],\n",
    "        [2, 3, 3, 4],\n",
    "        [3, 4, 4, 5],\n",
    "        [4, 5, 6, 6]\n",
    "    ], dtype=np.uint8)\n",
    "    \n",
    "    L = 7  # Niveau max (on travaille sur 0-7 pour simplifier)\n",
    "    n_pixels = image_simple.size  # 16 pixels\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"ÉGALISATION D'HISTOGRAMME - EXEMPLE PAS À PAS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # ÉTAPE 1 : Compter les pixels (histogramme brut)\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"\\n\" + \"─\" * 70)\n",
    "    print(\"ÉTAPE 1 : Histogramme brut (comptage des pixels)\")\n",
    "    print(\"─\" * 70)\n",
    "    \n",
    "    print(\"\\nImage originale (4×4 pixels, niveaux 0-7) :\")\n",
    "    print(image_simple)\n",
    "    \n",
    "    # Compter manuellement\n",
    "    hist_brut = np.zeros(L + 1, dtype=int)\n",
    "    for i in range(L + 1):\n",
    "        hist_brut[i] = np.sum(image_simple == i)\n",
    "    \n",
    "    print(\"\\nComptage des pixels par niveau :\")\n",
    "    print(\"┌─────────┬\" + \"───────┬\" * 7 + \"───────┐\")\n",
    "    print(\"│ Niveau  │\", end=\"\")\n",
    "    for i in range(L + 1):\n",
    "        print(f\"   {i}   │\", end=\"\")\n",
    "    print()\n",
    "    print(\"├─────────┼\" + \"───────┼\" * 7 + \"───────┤\")\n",
    "    print(\"│ Compte  │\", end=\"\")\n",
    "    for i in range(L + 1):\n",
    "        print(f\"   {hist_brut[i]}   │\", end=\"\")\n",
    "    print()\n",
    "    print(\"└─────────┴\" + \"───────┴\" * 7 + \"───────┘\")\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # ÉTAPE 2 : Histogramme normalisé H(i)\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"\\n\" + \"─\" * 70)\n",
    "    print(\"ÉTAPE 2 : Histogramme normalisé H(i) = compte(i) / total\")\n",
    "    print(\"─\" * 70)\n",
    "    \n",
    "    H = hist_brut / n_pixels\n",
    "    \n",
    "    print(f\"\\nNombre total de pixels : {n_pixels}\")\n",
    "    print(\"\\nCalcul de H(i) = compte(i) / 16 :\")\n",
    "    print()\n",
    "    for i in range(L + 1):\n",
    "        print(f\"  H({i}) = {hist_brut[i]:2d} / 16 = {H[i]:.4f}\")\n",
    "    \n",
    "    print(\"\\n→ H(i) représente la PROBABILITÉ qu'un pixel ait l'intensité i\")\n",
    "    print(f\"  Vérification : somme des H(i) = {H.sum():.4f} (doit être = 1)\")\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # ÉTAPE 3 : Histogramme cumulé C(k)\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"\\n\" + \"─\" * 70)\n",
    "    print(\"ÉTAPE 3 : Histogramme cumulé C(k) = Σ H(i) pour i de 0 à k\")\n",
    "    print(\"─\" * 70)\n",
    "    \n",
    "    C = np.cumsum(H)\n",
    "    \n",
    "    print(\"\\nCalcul progressif de C(k) :\")\n",
    "    print()\n",
    "    cumul = 0\n",
    "    for k in range(L + 1):\n",
    "        cumul += H[k]\n",
    "        detail = \" + \".join([f\"H({i})\" for i in range(k + 1)])\n",
    "        print(f\"  C({k}) = {detail}\")\n",
    "        print(f\"       = {' + '.join([f'{H[i]:.3f}' for i in range(k+1)])}\")\n",
    "        print(f\"       = {C[k]:.4f}\")\n",
    "        print()\n",
    "    \n",
    "    print(\"→ C(k) représente la probabilité qu'un pixel ait une intensité ≤ k\")\n",
    "    print(\"  C'est la FONCTION DE RÉPARTITION (CDF)\")\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # ÉTAPE 4 : Fonction de transfert (LUT)\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"\\n\" + \"─\" * 70)\n",
    "    print(\"ÉTAPE 4 : LUT (Look-Up Table) : f(i) = L × C(i)\")\n",
    "    print(\"─\" * 70)\n",
    "    \n",
    "    LUT = np.round(L * C).astype(np.uint8)\n",
    "    \n",
    "    print(f\"\\nAvec L = {L} (niveau max), on calcule f(i) = {L} × C(i) :\")\n",
    "    print()\n",
    "    print(\"┌─────────┬──────────┬─────────────┬──────────────┬─────────────┐\")\n",
    "    print(\"│ Entrée  │   C(i)   │  L × C(i)   │   arrondi    │   Sortie    │\")\n",
    "    print(\"│    i    │          │             │              │    f(i)     │\")\n",
    "    print(\"├─────────┼──────────┼─────────────┼──────────────┼─────────────┤\")\n",
    "    for i in range(L + 1):\n",
    "        produit = L * C[i]\n",
    "        print(f\"│    {i}    │  {C[i]:.4f}  │    {produit:.3f}    │      {LUT[i]}       │      {LUT[i]}       │\")\n",
    "    print(\"└─────────┴──────────┴─────────────┴──────────────┴─────────────┘\")\n",
    "    \n",
    "    print(\"\\n→ La LUT nous dit : 'le niveau i devient le niveau f(i)'\")\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # ÉTAPE 5 : Application à l'image\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"\\n\" + \"─\" * 70)\n",
    "    print(\"ÉTAPE 5 : Application de la LUT à l'image\")\n",
    "    print(\"─\" * 70)\n",
    "    \n",
    "    image_egalisee = LUT[image_simple]\n",
    "    \n",
    "    print(\"\\nImage originale :          Image égalisée :\")\n",
    "    print()\n",
    "    for row in range(4):\n",
    "        orig_row = \"  \".join([f\"{v}\" for v in image_simple[row]])\n",
    "        egal_row = \"  \".join([f\"{v}\" for v in image_egalisee[row]])\n",
    "        print(f\"    [{orig_row}]              [{egal_row}]\")\n",
    "    \n",
    "    print(\"\\nTransformations appliquées :\")\n",
    "    for i in range(L + 1):\n",
    "        if hist_brut[i] > 0:\n",
    "            print(f\"  {i} → {LUT[i]}  ({hist_brut[i]} pixels)\")\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # VISUALISATION\n",
    "    # -------------------------------------------------------------------------\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    \n",
    "    # Ligne 1 : Avant\n",
    "    axes[0, 0].imshow(image_simple, cmap='gray', vmin=0, vmax=L)\n",
    "    axes[0, 0].set_title('Image originale', fontweight='bold')\n",
    "    axes[0, 0].axis('off')\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            axes[0, 0].text(j, i, str(image_simple[i, j]), ha='center', va='center',\n",
    "                           color='red', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    axes[0, 1].bar(range(L + 1), hist_brut, color='steelblue', edgecolor='black')\n",
    "    axes[0, 1].set_title('Histogramme brut', fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Niveau de gris')\n",
    "    axes[0, 1].set_ylabel('Nombre de pixels')\n",
    "    axes[0, 1].set_xticks(range(L + 1))\n",
    "    \n",
    "    axes[0, 2].bar(range(L + 1), H, color='teal', edgecolor='black')\n",
    "    axes[0, 2].set_title('Histogramme normalisé H(i)', fontweight='bold')\n",
    "    axes[0, 2].set_xlabel('Niveau de gris')\n",
    "    axes[0, 2].set_ylabel('Probabilité')\n",
    "    axes[0, 2].set_xticks(range(L + 1))\n",
    "    \n",
    "    axes[0, 3].bar(range(L + 1), C, color='darkorange', edgecolor='black')\n",
    "    axes[0, 3].plot(range(L + 1), C, 'ro-', markersize=8)\n",
    "    axes[0, 3].set_title('Histogramme cumulé C(k)\\n(CDF)', fontweight='bold')\n",
    "    axes[0, 3].set_xlabel('Niveau de gris')\n",
    "    axes[0, 3].set_ylabel('Probabilité cumulée')\n",
    "    axes[0, 3].set_xticks(range(L + 1))\n",
    "    axes[0, 3].set_ylim(0, 1.1)\n",
    "    \n",
    "    # Ligne 2 : Après\n",
    "    axes[1, 0].imshow(image_egalisee, cmap='gray', vmin=0, vmax=L)\n",
    "    axes[1, 0].set_title('Image égalisée', fontweight='bold')\n",
    "    axes[1, 0].axis('off')\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            axes[1, 0].text(j, i, str(image_egalisee[i, j]), ha='center', va='center',\n",
    "                           color='lime', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # LUT\n",
    "    axes[1, 1].plot(range(L + 1), range(L + 1), 'k--', label='Identité', alpha=0.5)\n",
    "    axes[1, 1].plot(range(L + 1), LUT, 'ro-', markersize=10, linewidth=2, label='LUT')\n",
    "    axes[1, 1].set_title('LUT : f(i) = L × C(i)', fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Entrée i')\n",
    "    axes[1, 1].set_ylabel('Sortie f(i)')\n",
    "    axes[1, 1].set_xticks(range(L + 1))\n",
    "    axes[1, 1].set_yticks(range(L + 1))\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Histogramme après\n",
    "    hist_egal, _ = np.histogram(image_egalisee, bins=L+1, range=(0, L+1))\n",
    "    axes[1, 2].bar(range(L + 1), hist_egal, color='forestgreen', edgecolor='black')\n",
    "    axes[1, 2].set_title('Histogramme après égalisation', fontweight='bold')\n",
    "    axes[1, 2].set_xlabel('Niveau de gris')\n",
    "    axes[1, 2].set_ylabel('Nombre de pixels')\n",
    "    axes[1, 2].set_xticks(range(L + 1))\n",
    "    axes[1, 2].axhline(y=n_pixels/(L+1), color='red', linestyle='--', \n",
    "                       label=f'Uniforme idéal ({n_pixels/(L+1):.1f})')\n",
    "    axes[1, 2].legend()\n",
    "    \n",
    "    # Comparaison avant/après\n",
    "    x = np.arange(L + 1)\n",
    "    width = 0.35\n",
    "    axes[1, 3].bar(x - width/2, hist_brut, width, label='Avant', color='steelblue')\n",
    "    axes[1, 3].bar(x + width/2, hist_egal, width, label='Après', color='forestgreen')\n",
    "    axes[1, 3].set_title('Comparaison avant/après', fontweight='bold')\n",
    "    axes[1, 3].set_xlabel('Niveau de gris')\n",
    "    axes[1, 3].set_ylabel('Nombre de pixels')\n",
    "    axes[1, 3].set_xticks(range(L + 1))\n",
    "    axes[1, 3].legend()\n",
    "    \n",
    "    plt.suptitle('Égalisation d\\'histogramme - Exemple pas à pas', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # RÉSUMÉ FINAL\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"RÉSUMÉ\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\"\"\n",
    "    AVANT : L'histogramme était concentré sur les valeurs 2-6\n",
    "            → faible contraste, peu de niveaux utilisés\n",
    "    \n",
    "    APRÈS : L'histogramme est étalé sur 1-7\n",
    "            → meilleur contraste, utilisation plus uniforme des niveaux\n",
    "    \n",
    "    La \"magie\" de l'égalisation :\n",
    "    ─────────────────────────────\n",
    "    • Les niveaux FRÉQUENTS (ex: 3, 4) → C(i) augmente vite → écartés\n",
    "    • Les niveaux RARES (ex: 0, 1)     → C(i) augmente peu → compressés\n",
    "    \n",
    "    Résultat : les niveaux fréquents sont \"étalés\" pour occuper plus de place,\n",
    "               ce qui augmente le contraste perçu.\n",
    "    \"\"\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo_egalisation_pas_a_pas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créons une image plus réaliste (plus de dégradés, formes…). Analysez l’histogramme de cette image puis égalisez le :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================\n",
    "# Création d'une image \"sous-exposée\" (faible contraste, sombre)\n",
    "# =========================================================================\n",
    "    \n",
    "h, w = 256, 321  # 321 est divisible par 3\n",
    "    \n",
    "# Calcul explicite des bornes pour éviter les erreurs de broadcast\n",
    "w1 = w // 3       # 107\n",
    "w2 = 2 * w // 3   # 214\n",
    "    \n",
    "# Image avec plusieurs zones de textures\n",
    "img = np.zeros((h, w), dtype=np.float64)\n",
    "    \n",
    "# Zone 1 : dégradé\n",
    "for i in range(h):\n",
    "    img[i, :w1] = 40 + 30 * (i / h)\n",
    "    \n",
    "# Zone 2 : texture bruit\n",
    "zone2_width = w2 - w1\n",
    "img[:, w1:w2] = np.random.normal(55, 15, (h, zone2_width))\n",
    "    \n",
    "# Zone 3 : formes géométriques\n",
    "img[:, w2:] = 45\n",
    "# Cercle clair\n",
    "centre_x = w2 + (w - w2) // 2\n",
    "for i in range(h):\n",
    "    for j in range(w2, w):\n",
    "        if (i - h//2)**2 + (j - centre_x)**2 < 50**2:\n",
    "            img[i, j] = 80\n",
    "# Rectangle sombre\n",
    "img[h//4:h//4+60, w2+10:w2+70] = 30\n",
    "    \n",
    "# Limiter la dynamique à [25, 95] pour simuler une sous-exposition\n",
    "img_complexe = np.clip(img, 25, 95).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afficher_histogramme(img_complexe, titre='Image complexe');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_egalisation_image_reelle(img):\n",
    "    \"\"\"\n",
    "    Démonstration de l'égalisation d'histogramme sur une image réaliste.\n",
    "    \"\"\"\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Égalisation\n",
    "    # =========================================================================\n",
    "    \n",
    "    L = 255\n",
    "    \n",
    "    # Histogramme et CDF\n",
    "    hist, _ = np.histogram(img.flatten(), bins=256, range=(0, 256))\n",
    "    hist_norm = hist / hist.sum()\n",
    "    cdf = np.cumsum(hist_norm)\n",
    "    \n",
    "    # LUT\n",
    "    lut = (L * cdf).astype(np.uint8)\n",
    "    \n",
    "    # Application\n",
    "    img_egal = lut[img]\n",
    "    \n",
    "    # Histogramme après\n",
    "    hist_egal, _ = np.histogram(img_egal.flatten(), bins=256, range=(0, 256))\n",
    "    cdf_egal = np.cumsum(hist_egal / hist_egal.sum())\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Visualisation\n",
    "    # =========================================================================\n",
    "    \n",
    "    fig = plt.figure(figsize=(16, 12))\n",
    "    \n",
    "    # Layout personnalisé\n",
    "    gs = fig.add_gridspec(3, 4, height_ratios=[1, 1, 0.8], hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # --- Ligne 1 : Images ---\n",
    "    ax_img1 = fig.add_subplot(gs[0, 0:2])\n",
    "    ax_img1.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "    ax_img1.set_title(f'Image originale\\nDynamique : [{img.min()}, {img.max()}]', \n",
    "                      fontsize=12, fontweight='bold')\n",
    "    ax_img1.axis('off')\n",
    "    \n",
    "    ax_img2 = fig.add_subplot(gs[0, 2:4])\n",
    "    ax_img2.imshow(img_egal, cmap='gray', vmin=0, vmax=255)\n",
    "    ax_img2.set_title(f'Image égalisée\\nDynamique : [{img_egal.min()}, {img_egal.max()}]', \n",
    "                      fontsize=12, fontweight='bold')\n",
    "    ax_img2.axis('off')\n",
    "    \n",
    "    # --- Ligne 2 : Histogrammes ---\n",
    "    ax_hist1 = fig.add_subplot(gs[1, 0])\n",
    "    ax_hist1.bar(range(256), hist, width=1, color='steelblue', edgecolor='none')\n",
    "    ax_hist1.set_xlim(0, 255)\n",
    "    ax_hist1.set_xlabel('Niveau de gris')\n",
    "    ax_hist1.set_ylabel('Nombre de pixels')\n",
    "    ax_hist1.set_title('Histogramme original', fontsize=11, fontweight='bold')\n",
    "    ax_hist1.axvline(x=img.min(), color='red', linestyle='--', alpha=0.7)\n",
    "    ax_hist1.axvline(x=img.max(), color='red', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    ax_cdf1 = fig.add_subplot(gs[1, 1])\n",
    "    ax_cdf1.plot(range(256), cdf, color='darkorange', linewidth=2)\n",
    "    ax_cdf1.fill_between(range(256), cdf, alpha=0.3, color='darkorange')\n",
    "    ax_cdf1.set_xlim(0, 255)\n",
    "    ax_cdf1.set_ylim(0, 1)\n",
    "    ax_cdf1.set_xlabel('Niveau de gris')\n",
    "    ax_cdf1.set_ylabel('Probabilité cumulée')\n",
    "    ax_cdf1.set_title('CDF original (= LUT normalisée)', fontsize=11, fontweight='bold')\n",
    "    ax_cdf1.grid(True, alpha=0.3)\n",
    "    # Montrer la zone \"active\"\n",
    "    ax_cdf1.axvspan(img.min(), img.max(), alpha=0.2, color='red', label='Zone active')\n",
    "    ax_cdf1.legend(fontsize=9)\n",
    "    \n",
    "    ax_hist2 = fig.add_subplot(gs[1, 2])\n",
    "    ax_hist2.bar(range(256), hist_egal, width=1, color='forestgreen', edgecolor='none')\n",
    "    ax_hist2.set_xlim(0, 255)\n",
    "    ax_hist2.set_xlabel('Niveau de gris')\n",
    "    ax_hist2.set_ylabel('Nombre de pixels')\n",
    "    ax_hist2.set_title('Histogramme égalisé', fontsize=11, fontweight='bold')\n",
    "    # Ligne de référence uniforme\n",
    "    ax_hist2.axhline(y=img.size/256, color='red', linestyle='--', \n",
    "                     label='Uniforme idéal', alpha=0.7)\n",
    "    ax_hist2.legend(fontsize=9)\n",
    "    \n",
    "    ax_cdf2 = fig.add_subplot(gs[1, 3])\n",
    "    ax_cdf2.plot(range(256), cdf_egal, color='forestgreen', linewidth=2, label='CDF égalisé')\n",
    "    ax_cdf2.plot(range(256), np.linspace(0, 1, 256), 'r--', linewidth=1, label='CDF uniforme idéal')\n",
    "    ax_cdf2.set_xlim(0, 255)\n",
    "    ax_cdf2.set_ylim(0, 1)\n",
    "    ax_cdf2.set_xlabel('Niveau de gris')\n",
    "    ax_cdf2.set_ylabel('Probabilité cumulée')\n",
    "    ax_cdf2.set_title('CDF après égalisation', fontsize=11, fontweight='bold')\n",
    "    ax_cdf2.legend(fontsize=9)\n",
    "    ax_cdf2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # --- Ligne 3 : LUT et explication ---\n",
    "    ax_lut = fig.add_subplot(gs[2, 0:2])\n",
    "    ax_lut.plot(range(256), range(256), 'k--', linewidth=1, alpha=0.5, label='Identité')\n",
    "    ax_lut.plot(range(256), lut, color='purple', linewidth=2, label='LUT = 255 × CDF')\n",
    "    ax_lut.set_xlim(0, 255)\n",
    "    ax_lut.set_ylim(0, 255)\n",
    "    ax_lut.set_xlabel('Niveau d\\'entrée i', fontsize=11)\n",
    "    ax_lut.set_ylabel('Niveau de sortie f(i)', fontsize=11)\n",
    "    ax_lut.set_title('Look-Up Table (LUT)', fontsize=11, fontweight='bold')\n",
    "    ax_lut.legend(fontsize=10)\n",
    "    ax_lut.grid(True, alpha=0.3)\n",
    "    ax_lut.set_aspect('equal')\n",
    "    # Annotations\n",
    "    ax_lut.annotate(f'min={img.min()} → {lut[img.min()]}', \n",
    "                    xy=(img.min(), lut[img.min()]), \n",
    "                    xytext=(img.min()+30, lut[img.min()]-40),\n",
    "                    arrowprops=dict(arrowstyle='->', color='red'),\n",
    "                    fontsize=10, color='red')\n",
    "    ax_lut.annotate(f'max={img.max()} → {lut[img.max()]}', \n",
    "                    xy=(img.max(), lut[img.max()]), \n",
    "                    xytext=(img.max()+30, lut[img.max()]-40),\n",
    "                    arrowprops=dict(arrowstyle='->', color='red'),\n",
    "                    fontsize=10, color='red')\n",
    "    \n",
    "    # Explication textuelle\n",
    "    ax_txt = fig.add_subplot(gs[2, 2:4])\n",
    "    ax_txt.axis('off')\n",
    "    \n",
    "    plt.suptitle('Égalisation d\\'histogramme - Image 256 niveaux', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    plt.show()\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Stats\n",
    "    # =========================================================================\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"STATISTIQUES\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\"\"\n",
    "    Image originale :\n",
    "        Min / Max : {img.min()} / {img.max()}\n",
    "        Moyenne   : {img.mean():.1f}\n",
    "        Écart-type: {img.std():.1f}\n",
    "    \n",
    "    Image égalisée :\n",
    "        Min / Max : {img_egal.min()} / {img_egal.max()}\n",
    "        Moyenne   : {img_egal.mean():.1f}\n",
    "        Écart-type: {img_egal.std():.1f}\n",
    "    \n",
    "    → L'écart-type a augmenté de {img.std():.1f} à {img_egal.std():.1f}\n",
    "      ce qui traduit l'augmentation du contraste.\n",
    "    \"\"\")\n",
    "    \n",
    "    conclusions = \"\"\"\n",
    "    INTERPRÉTATION DE LA LUT\n",
    "    ━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    \n",
    "    • La LUT est plate pour les niveaux ABSENTS (0-24 et 96-255)\n",
    "      → Ces niveaux ne sont pas utilisés dans l'image originale\n",
    "    \n",
    "    • La LUT monte RAPIDEMENT dans la zone [25-95]\n",
    "      → Les niveaux présents sont \"étalés\" sur toute la plage [0-255]\n",
    "    \n",
    "    • Pente forte = niveaux fréquents → écartés (plus de contraste)\n",
    "    • Pente faible = niveaux rares → compressés\n",
    "    \n",
    "    RÉSULTAT\n",
    "    ━━━━━━━━\n",
    "    • Avant : dynamique [25, 95] → 70 niveaux utilisés\n",
    "    • Après : dynamique [0, 255] → 256 niveaux utilisés\n",
    "    • Le contraste est maximisé !\n",
    "    \"\"\"\n",
    "\n",
    "    print(conclusions)\n",
    "\n",
    "demo_egalisation_image_reelle(img_complexe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 Correction Gamma\n",
    "\n",
    "La correction gamma est une transformation non-linéaire qui permet d'ajuster la luminosité d'une image de manière plus naturelle qu'une simple multiplication. Elle est définie par :\n",
    "$$\n",
    "I'(i,j) = 255 \\times \\left(\\frac{I(i,j)}{255}\\right)^\\gamma\n",
    "$$\n",
    "Le paramètre γ contrôle la forme de la courbe de transformation :\n",
    "\n",
    "γ = 1 : fonction identité, l'image reste inchangée\n",
    "γ < 1 : éclaircit l'image, en relevant particulièrement les zones sombres\n",
    "γ > 1 : assombrit l'image, en compressant les valeurs claires\n",
    "\n",
    "L'intérêt de cette transformation réside dans son comportement asymétrique : elle affecte davantage certaines plages de valeurs que d'autres. Avec γ < 1, les pixels sombres (proches de 0) sont fortement relevés tandis que les pixels clairs (proches de 255) changent peu. C'est l'inverse avec γ > 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "  \n",
    "x = np.linspace(0, 255, 256)\n",
    "x_norm = x / 255  # Normalisation [0, 1]\n",
    "    \n",
    "gammas = [0.3, 0.5, 0.7, 1.0, 1.5, 2.2, 3.0]\n",
    "couleurs = ['#e41a1c', '#ff7f00', '#ffd700', '#000000', '#4daf4a', '#377eb8', '#984ea3']\n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(16, 5))\n",
    "    \n",
    "# --- Courbes de transformation ---\n",
    "for gamma, couleur in zip(gammas, couleurs):\n",
    "    y = 255 * (x_norm ** gamma)\n",
    "    style = '-' if gamma != 1.0 else '--'\n",
    "    lw = 2 if gamma != 1.0 else 3\n",
    "    ax.plot(x, y, style, color=couleur, linewidth=lw, label=f'γ = {gamma}')\n",
    "    \n",
    "ax.set_xlim(0, 255)\n",
    "ax.set_ylim(0, 255)\n",
    "ax.set_xlabel('Valeur d\\'entrée', fontsize=11)\n",
    "ax.set_ylabel('Valeur de sortie', fontsize=11)\n",
    "ax.set_title('Courbes de correction gamma', fontsize=12, fontweight='bold')\n",
    "ax.legend(loc='lower right', fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_aspect('equal')\n",
    "    \n",
    "# Annotations zones\n",
    "ax.fill_between([0, 80], [0, 0], [255, 255], alpha=0.1, color='blue')\n",
    "ax.fill_between([180, 255], [0, 0], [255, 255], alpha=0.1, color='red')\n",
    "ax.text(40, 240, 'Sombres', ha='center', fontsize=10, color='blue')\n",
    "ax.text(217, 240, 'Clairs', ha='center', fontsize=10, color='red')\n",
    "    \n",
    "# =========================================================================\n",
    "# Application sur un dégradé\n",
    "# =========================================================================\n",
    "    \n",
    "np.random.seed(42)\n",
    "    \n",
    "# Image test avec gradient et formes\n",
    "h, w = 150, 400\n",
    "img = np.zeros((h, w), dtype=np.uint8)\n",
    "    \n",
    "# Gradient horizontal\n",
    "for j in range(w):\n",
    "    img[:, j] = int(255 * j / w)\n",
    "    \n",
    "# Appliquer différents gamma\n",
    "gammas_demo = [0.4, 0.7, 1.0, 1.5, 2.5]\n",
    "    \n",
    "fig, axes = plt.subplots(len(gammas_demo), 2, figsize=(14, 10),\n",
    "                              gridspec_kw={'width_ratios': [2, 1]})\n",
    "    \n",
    "for idx, gamma in enumerate(gammas_demo):\n",
    "    # Correction gamma\n",
    "    img_gamma = (255 * ((img / 255) ** gamma)).astype(np.uint8)\n",
    "        \n",
    "    # Image\n",
    "    axes[idx, 0].imshow(img_gamma, cmap='gray', vmin=0, vmax=255)\n",
    "    if gamma < 1:\n",
    "        effet = \"éclaircit\"\n",
    "        couleur = 'darkorange'\n",
    "    elif gamma > 1:\n",
    "        effet = \"assombrit\"\n",
    "        couleur = 'steelblue'\n",
    "    else:\n",
    "        effet = \"identité\"\n",
    "        couleur = 'black'\n",
    "    axes[idx, 0].set_title(f'γ = {gamma} ({effet})', fontsize=11, \n",
    "                                fontweight='bold', color=couleur)\n",
    "    axes[idx, 0].axis('off')\n",
    "        \n",
    "    # Histogramme\n",
    "    axes[idx, 1].hist(img_gamma.flatten(), bins=256, range=(0, 256),\n",
    "                          color=couleur, alpha=0.7, edgecolor='none')\n",
    "    axes[idx, 1].set_xlim(0, 255)\n",
    "    axes[idx, 1].set_ylabel('Pixels')\n",
    "    if idx == len(gammas_demo) - 1:\n",
    "            axes[idx, 1].set_xlabel('Intensité')\n",
    "    axes[idx, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "plt.suptitle('Effet de la correction gamma sur un dégradé', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correction_gamma(image, gamma):\n",
    "    \"\"\"\n",
    "    Applique une correction gamma à une image.\n",
    "    \n",
    "    La correction gamma est une transformation non-linéaire qui permet\n",
    "    d'ajuster la luminosité de manière perceptuellement uniforme.\n",
    "    \n",
    "    Formule : I'(i,j) = 255 × (I(i,j) / 255)^gamma\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    image : ndarray\n",
    "        Image 2D en niveaux de gris.\n",
    "    gamma : float\n",
    "        Exposant gamma.\n",
    "        - gamma < 1 : éclaircit l'image (relève les ombres)\n",
    "        - gamma = 1 : image inchangée\n",
    "        - gamma > 1 : assombrit l'image (accentue les contrastes sombres)\n",
    "    \n",
    "    Retourne\n",
    "    --------\n",
    "    image_corrigee : ndarray (uint8)\n",
    "        Image avec correction gamma appliquée.\n",
    "    \"\"\"\n",
    "    # Normaliser vers [0, 1]\n",
    "    img_norm = image.astype(np.float64) / 255.0\n",
    "    \n",
    "    # Appliquer gamma\n",
    "    img_gamma = np.power(img_norm, gamma)\n",
    "    \n",
    "    # Revenir vers [0, 255]\n",
    "    image_corrigee = (img_gamma * 255).astype(np.uint8)\n",
    "    \n",
    "    return image_corrigee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_foncee = img_chat[:,:,2]\n",
    "# correction linéaire\n",
    "a = 50\n",
    "img_lin = img_chat[:,:,2] + a\n",
    "\n",
    "img_gamma = correction_gamma(img_foncee, 0.65)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 6))\n",
    "\n",
    "axes[0].imshow(img_foncee)\n",
    "axes[0].set_title('Image d’origine (foncée)', fontsize=11, fontweight='bold')\n",
    "\n",
    "axes[1].imshow(img_gamma)\n",
    "axes[1].set_title('Image corrigée (éclaircie avec γ = 0.65)', fontsize=11, fontweight='bold')\n",
    "\n",
    "axes[2].imshow(img_lin)\n",
    "axes[2].set_title('Image corrigée (éclaircie linéairement a = 50)', fontsize=11, fontweight='bold')\n",
    "\n",
    "fig.suptitle('Correction gamma sur une image « réelle »', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate que l’éclaircicement obtenu avec la correction gamma préserve mieux les contrastes (image plus équilibrée). Testez et comparez différentes valeurs de γ et de $a$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Seuillage\n",
    "\n",
    "### 3.1 Seuillage simple\n",
    "\n",
    "Une fois notre image convertie en niveau de gris, nous pouvons procéder à d’autres traitements, afin d’isoler, ou faciliter l’isolement de certains éléments (p. ex. ce que l’on appelle la segmentation) ou au contraire de les faire disparaître (en général pour nettoyer l’image : supprimer le bruit ou des artefact, etc.).\n",
    "\n",
    "Un exemple classique : le traitement des empreintes digitales. L’information utile dans une emprunte sont les motifs dessinés par les sillons, il n‘y a aucun intérêt à analyser des nuances de gris etc. Le seuillage permet d’extraire ces motifs :\n",
    "\n",
    "![photo empreinte digitale Wikimedia](./images/Fingerprintonpaper.jpg)\n",
    "CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=618743\n",
    "\n",
    "L’approche la plus simple (ou plutôt simpliste) consiste à effectuer un seuillage : on partitionne notre espace de valeurs en deux en fixant un seuil (*threshold*) $T$, c’est à dire la valeur limite à partir de laquelle le « gris » sera considéré comme du blanc, et en dessous de laquelle il sera considéré comme du noir. \n",
    "\n",
    "$$\n",
    "I'(x,y) = \\begin{cases} 255 & \\text{si } I(x,y) > T \\\\ 0 & \\text{sinon} \\end{cases}\n",
    "$$\n",
    "\n",
    "On transforme donc une image en niveau de gris en une image binaire, où une valeur de pixel (p. ex. le noir) pourra par exemple représenter le fond, et l’autre valeur, le premier plan. En fixant adroitement notre seuil, on peut isoler certains éléments de notre image :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seuillage_simple(img_gris, seuil):\n",
    "    \"\"\"Seuillage binaire.\"\"\"\n",
    "    return np.where(img_gris > seuil, 255, 0).astype(np.uint8)\n",
    "\n",
    "seuils = [50, 100, 150, 200]\n",
    "fig, axes = plt.subplots(1, 5, figsize=(16, 3))\n",
    "axes[0].imshow(img_gris, cmap='gray')\n",
    "axes[0].set_title('Original')\n",
    "axes[0].axis('off')\n",
    "\n",
    "for i, s in enumerate(seuils):\n",
    "    axes[i+1].imshow(seuillage_simple(img_gris, s), cmap='gray')\n",
    "    axes[i+1].set_title(f'Seuil = {s}')\n",
    "    axes[i+1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 3\n",
    "\n",
    "Appliquez cette fonction sur l’image d’emprunte digitale que vous aurez chargée (chemin : `./images/Fingerprintonpaper.jpg`. Comparez plusieurs valeurs de seuil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCICE 3 : VOTRE CODE ! \n",
    "fingerprint = np.array(Image.open('images/Fingerprintonpaper.jpg'))\n",
    "fingerprint_treated = seuillage_simple(fingerprint, 140)\n",
    "plt.imshow(fingerprint_treated)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les limites de cette approche sont évidentes : il nous faut une méthode pour déterminer la valeur seuil, des éléments différents peuvent avoir des niveaux identiques et donc seront traité comme un tout, etc. On peut bien sûr imaginer plusieurs seuils distincts pour segmenter notre image (par exemple ici avec deux niveaux on pourrait séparer le fond, le rectange et le disque), mais cela ne règle le problème qu’en partie et surtout ne résout pas la question : comment fixer ces seuils autrement que par essai/erreur.\n",
    "\n",
    "Comme nous sommes des data scientists nous allons d’abord chercher un moyen d’automatiser la procédure à partir des informations contenues dans l’image.\n",
    "\n",
    "Note : on applique généralement les seuils aux niveaux de gris (un seuil = un canal), mais on peut traiter un canal de couleur de la même manière, même si en pratique l’intérêt est souvent nul."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Seuillage d'Ōtsu (automatique)\n",
    "\n",
    "Cette méthode, comme son nom l’indique, a été inventée par *Nobuyuki Ōtsu* en 1979. Elle va chercher à fixer le seuil à partir de la distribution des valeurs des pixels (donc de l’histogramme), donc à partir des valeurs rencontrées dans l’image elle-même (et pas arbitrairement), ce qui permet d’adapter automatiquement le seuil à une image donnée. \n",
    "\n",
    "Le principe est somme toute assez simple : on va chercher une valeur limite (seuil) qui va minimiser la variance intra-classe des deux classes de valeurs des pixels qui constituent l’image finale.\n",
    "\n",
    "Plus précisément :\n",
    "\n",
    "* chaque pixel de l’image finale binaire a une valeur parmi deux possibles (0 ou 255 par exemple pour noir / blanc), ce qui définit deux classes\n",
    "* pour affecter les pixels de l’image d’origine à l’une ou l’autre classe, on va regarder s’ils sont supérieurs ou inférieurs à une valeur $S$ (seuil)\n",
    "* par exemple si on fixe le seuil à 124, la classe 0 va contenir l’ensemble des pixels dont les valeurs sont comprises entre 0 et 124, et la classe 255 tous les pixels de valeurs supérieures à 124\n",
    "* dans chacunes de ces classes, en fonction de l’image d’origine, on va retrouver des distributions différentes de valeurs\n",
    "* selon Ōtsu, le meilleur seuil est celui qui crée deux groupes les plus homogènes possibles, car une image qui peut être seuillée « efficacement » est une image dont l’histogramme contient deux distributions homogènes (p. ex. un histogramme qui montre une distribution bimodale. Si on « coupe » au bon endroit on devrait obtenir des classes qui ne contiennent que des pixels aux valeurs « similaires », avec une faible dispersion\n",
    "\n",
    "Voyons cela avec un histogramme créé pour l’exemple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =============================================================================\n",
    "# CRÉATION DES DONNÉES (même distribution bimodale)\n",
    "# =============================================================================\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Groupe 1 : pixels sombres (fond), centrés autour de 60\n",
    "pixels_fond = np.random.normal(60, 20, 3000).astype(int)\n",
    "pixels_fond = np.clip(pixels_fond, 0, 255)\n",
    "\n",
    "# Groupe 2 : pixels clairs (objets), centrés autour de 180\n",
    "pixels_objets = np.random.normal(180, 25, 2000).astype(int)\n",
    "pixels_objets = np.clip(pixels_objets, 0, 255)\n",
    "\n",
    "# Tous les pixels\n",
    "tous_pixels = np.concatenate([pixels_fond, pixels_objets])\n",
    "\n",
    "# =============================================================================\n",
    "# CALCUL DE LA VARIANCE INTRA-CLASSE POUR CHAQUE SEUIL\n",
    "# =============================================================================\n",
    "\n",
    "def calculer_variance_intra_classe(pixels, seuil):\n",
    "    \"\"\"\n",
    "    Calcule la variance intra-classe pondérée pour un seuil donné.\n",
    "    \n",
    "    Formule : σ²_intra = w0 × σ²_0 + w1 × σ²_1\n",
    "    \n",
    "    où :\n",
    "    - w0, w1 = proportions de pixels dans chaque classe\n",
    "    - σ²_0, σ²_1 = variances de chaque classe\n",
    "    \"\"\"\n",
    "    classe0 = pixels[pixels <= seuil]\n",
    "    classe1 = pixels[pixels > seuil]\n",
    "    \n",
    "    # Éviter les classes vides\n",
    "    if len(classe0) == 0 or len(classe1) == 0:\n",
    "        return np.inf\n",
    "    \n",
    "    # Proportions (poids)\n",
    "    w0 = len(classe0) / len(pixels)\n",
    "    w1 = len(classe1) / len(pixels)\n",
    "    \n",
    "    # Variances de chaque classe\n",
    "    var0 = np.var(classe0)\n",
    "    var1 = np.var(classe1)\n",
    "    \n",
    "    # Variance intra-classe pondérée\n",
    "    variance_intra = w0 * var0 + w1 * var1\n",
    "    \n",
    "    return variance_intra\n",
    "\n",
    "def calculer_variance_inter_classe(pixels, seuil):\n",
    "    \"\"\"\n",
    "    Calcule la variance inter-classe pour un seuil donné.\n",
    "    \n",
    "    Formule : σ²_inter = w0 × w1 × (μ0 - μ1)²\n",
    "    \n",
    "    C'est cette quantité qu'Otsu MAXIMISE (équivalent à minimiser σ²_intra)\n",
    "    \"\"\"\n",
    "    classe0 = pixels[pixels <= seuil]\n",
    "    classe1 = pixels[pixels > seuil]\n",
    "    \n",
    "    if len(classe0) == 0 or len(classe1) == 0:\n",
    "        return 0\n",
    "    \n",
    "    w0 = len(classe0) / len(pixels)\n",
    "    w1 = len(classe1) / len(pixels)\n",
    "    \n",
    "    mu0 = np.mean(classe0)\n",
    "    mu1 = np.mean(classe1)\n",
    "    \n",
    "    variance_inter = w0 * w1 * (mu0 - mu1) ** 2\n",
    "    \n",
    "    return variance_inter\n",
    "\n",
    "# Calculer pour tous les seuils possibles\n",
    "seuils = np.arange(1, 255)\n",
    "variances_intra = [calculer_variance_intra_classe(tous_pixels, t) for t in seuils]\n",
    "variances_inter = [calculer_variance_inter_classe(tous_pixels, t) for t in seuils]\n",
    "\n",
    "# Trouver le seuil optimal\n",
    "seuil_otsu = seuils[np.argmin(variances_intra)]\n",
    "variance_min = min(variances_intra)\n",
    "\n",
    "print(f\"Seuil optimal (Otsu) : {seuil_otsu}\")\n",
    "print(f\"Variance intra-classe minimale : {variance_min:.1f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# VISUALISATION COMPLÈTE\n",
    "# =============================================================================\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Layout : 2 lignes, avec la première divisée en 2\n",
    "ax1 = fig.add_subplot(2, 2, 1)  # Histogramme\n",
    "ax2 = fig.add_subplot(2, 2, 2)  # Variance intra-classe\n",
    "ax3 = fig.add_subplot(2, 1, 2)  # Explication visuelle avec 3 seuils\n",
    "\n",
    "# --- 1. Histogramme avec seuil optimal ---\n",
    "ax1.hist(tous_pixels, bins=50, range=(0, 255), color='steelblue', edgecolor='black', alpha=0.7)\n",
    "ax1.axvline(x=seuil_otsu, color='red', linestyle='-', linewidth=3, label=f'Seuil Otsu = {seuil_otsu}')\n",
    "ax1.fill_betweenx([0, ax1.get_ylim()[1] if ax1.get_ylim()[1] > 0 else 200], \n",
    "                   0, seuil_otsu, alpha=0.2, color='blue', label='Classe 0')\n",
    "ax1.fill_betweenx([0, ax1.get_ylim()[1] if ax1.get_ylim()[1] > 0 else 200], \n",
    "                   seuil_otsu, 255, alpha=0.2, color='orange', label='Classe 1')\n",
    "ax1.set_xlabel('Intensité des pixels', fontsize=11)\n",
    "ax1.set_ylabel('Nombre de pixels', fontsize=11)\n",
    "ax1.set_title('Histogramme de l\\'image', fontsize=12, fontweight='bold')\n",
    "ax1.legend(loc='upper right')\n",
    "ax1.set_xlim(0, 255)\n",
    "\n",
    "# Recalculer ylim après le plot\n",
    "ax1.hist(tous_pixels, bins=50, range=(0, 255), color='steelblue', edgecolor='black', alpha=0.7)\n",
    "ymax = ax1.get_ylim()[1]\n",
    "ax1.axvline(x=seuil_otsu, color='red', linestyle='-', linewidth=3)\n",
    "ax1.fill_betweenx([0, ymax], 0, seuil_otsu, alpha=0.2, color='blue')\n",
    "ax1.fill_betweenx([0, ymax], seuil_otsu, 255, alpha=0.2, color='orange')\n",
    "\n",
    "# --- 2. Courbe de variance intra-classe ---\n",
    "ax2.plot(seuils, variances_intra, 'b-', linewidth=2, label='Variance intra-classe')\n",
    "ax2.axvline(x=seuil_otsu, color='red', linestyle='--', linewidth=2)\n",
    "ax2.scatter([seuil_otsu], [variance_min], color='red', s=150, zorder=5, \n",
    "            label=f'Minimum : T={seuil_otsu}')\n",
    "ax2.set_xlabel('Seuil T', fontsize=11)\n",
    "ax2.set_ylabel('Variance intra-classe (σ²_intra)', fontsize=11)\n",
    "ax2.set_title('Variance intra-classe en fonction du seuil\\n(Otsu minimise cette courbe)', \n",
    "              fontsize=12, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.set_xlim(0, 255)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Annotation\n",
    "ax2.annotate(f'MINIMUM\\nT = {seuil_otsu}\\nσ²_intra = {variance_min:.0f}', \n",
    "             xy=(seuil_otsu, variance_min),\n",
    "             xytext=(seuil_otsu + 40, variance_min + 500),\n",
    "             fontsize=10,\n",
    "             arrowprops=dict(arrowstyle='->', color='red'),\n",
    "             bbox=dict(boxstyle='round', facecolor='lightyellow'))\n",
    "\n",
    "# --- 3. Comparaison de 3 seuils ---\n",
    "seuils_demo = [60, seuil_otsu, 200]\n",
    "couleurs = ['green', 'red', 'purple']\n",
    "titres = ['Trop bas', 'Optimal (Otsu)', 'Trop haut']\n",
    "\n",
    "# Créer 3 sous-zones dans ax3\n",
    "ax3.set_xlim(0, 300)\n",
    "ax3.set_ylim(0, 100)\n",
    "ax3.axis('off')\n",
    "ax3.set_title('Comparaison : pourquoi le seuil Otsu est optimal ?', fontsize=12, fontweight='bold')\n",
    "\n",
    "for idx, (seuil, couleur, titre) in enumerate(zip(seuils_demo, couleurs, titres)):\n",
    "    # Position horizontale\n",
    "    x_offset = idx * 100 + 10\n",
    "    \n",
    "    # Calculer les stats pour ce seuil\n",
    "    c0 = tous_pixels[tous_pixels <= seuil]\n",
    "    c1 = tous_pixels[tous_pixels > seuil]\n",
    "    var_intra = calculer_variance_intra_classe(tous_pixels, seuil)\n",
    "    \n",
    "    # Mini histogramme (simulé avec du texte et des barres)\n",
    "    ax_mini = fig.add_axes([0.1 + idx*0.3, 0.08, 0.25, 0.30])\n",
    "    \n",
    "    ax_mini.hist(c0, bins=30, range=(0, 255), alpha=0.7, color='blue', label='Classe 0')\n",
    "    ax_mini.hist(c1, bins=30, range=(0, 255), alpha=0.7, color='orange', label='Classe 1')\n",
    "    ax_mini.axvline(x=seuil, color=couleur, linestyle='-', linewidth=3)\n",
    "    \n",
    "    # Évaluation\n",
    "    if seuil == seuil_otsu:\n",
    "        evaluation = \"✓ Classes homogènes\"\n",
    "        title_color = 'green'\n",
    "    else:\n",
    "        evaluation = \"✗ Classes mélangées\"\n",
    "        title_color = 'red'\n",
    "    \n",
    "    ax_mini.set_title(f'{titre}\\nT = {seuil}\\n\\nσ²_intra = {var_intra:.0f}\\n{evaluation}', \n",
    "                      fontsize=10, color=title_color)\n",
    "    ax_mini.set_xlabel('Intensité')\n",
    "    ax_mini.set_xlim(0, 255)\n",
    "    \n",
    "    if idx == 0:\n",
    "        ax_mini.set_ylabel('Nb pixels')\n",
    "    \n",
    "    ax_mini.tick_params(labelsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('otsu_courbe_variance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Récap méthode d’Ōtsu \n",
    "\n",
    "1. Pour chaque seuil T possible (de 1 à 254) :\n",
    "   - On sépare les pixels en 2 classes : C0 (≤T) et C1 (>T)\n",
    "   - On calcule la variance DANS chaque classe\n",
    "   - On fait la moyenne pondérée : $\\sigma^2_{intra} = w_0 × \\sigma^2_0 + w_1 × \\sigma^2_1$\n",
    "\n",
    "2. On trace la courbe $\\sigma^2_{intra}$ en fonction de T\n",
    "\n",
    "3. Le seuil optimal est celui qui MINIMISE cette variance\n",
    "   → C'est le point le plus bas de la courbe\n",
    "\n",
    "4. Interprétation :\n",
    "   - Variance intra-classe FAIBLE = chaque classe est homogène\n",
    "   - Cela signifie qu'on a bien séparé le fond des objets\n",
    "\n",
    "Dans notre exemple :\n",
    "- Seuil optimal : T = {seuil_otsu}\n",
    "- Ce seuil se trouve dans la 'vallée' de l'histogramme\n",
    "- Il sépare naturellement les deux pics (fond sombre / objets clairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seuil_otsu(img_gris):\n",
    "    \"\"\"Calcule le seuil optimal (Otsu).\"\"\"\n",
    "    hist, _ = np.histogram(img_gris.flatten(), bins=256, range=(0, 256))\n",
    "    hist_norm = hist / hist.sum()\n",
    "    \n",
    "    meilleur_seuil, meilleure_variance = 0, 0\n",
    "    for t in range(1, 255):\n",
    "        w0, w1 = hist_norm[:t+1].sum(), hist_norm[t+1:].sum()\n",
    "        if w0 == 0 or w1 == 0: continue\n",
    "        \n",
    "        mu0 = (np.arange(t+1) * hist_norm[:t+1]).sum() / w0\n",
    "        mu1 = (np.arange(t+1, 256) * hist_norm[t+1:]).sum() / w1\n",
    "        variance_inter = w0 * w1 * (mu0 - mu1) ** 2\n",
    "        \n",
    "        if variance_inter > meilleure_variance:\n",
    "            meilleure_variance = variance_inter\n",
    "            meilleur_seuil = t\n",
    "    return meilleur_seuil\n",
    "\n",
    "seuil_opt = seuil_otsu(img_gris)\n",
    "img_otsu = seuillage_simple(img_gris, seuil_opt)\n",
    "print(f\"Seuil Otsu : {seuil_opt}\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "axes[0].imshow(img_gris, cmap='gray')\n",
    "axes[0].set_title('Original')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].hist(img_gris.flatten(), bins=256, color='gray', alpha=0.7)\n",
    "axes[1].axvline(x=seuil_opt, color='red', linewidth=2, label=f'Otsu={seuil_opt}')\n",
    "axes[1].legend()\n",
    "axes[1].set_title('Histogramme')\n",
    "\n",
    "axes[2].imshow(img_otsu, cmap='gray')\n",
    "axes[2].set_title(f'Seuillage Otsu')\n",
    "axes[2].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le seuillage d’Otsu permet d’isoler automatiquement le disque, qui est la  figure qui se détache plus nettement du fond que le rectangle gris foncé.\n",
    "\n",
    "Enfin, ne perdons pas de vue non plus que si nous avons appliqué la méthode des seuils sur une image en niveau de gris (un canal = un seuil) – par exemple issue d’une combinaison des différents canaux, on peut bien sûr aussi définir un seuil en se focalisant sur un canal de couleur donné selon le traitement voulu. \n",
    "\n",
    "Voyons, pour l’empreinte digitale, quel est le seuil déterminé par cette méthode :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE\n",
    "\n",
    "# Déjà, voyons à quoi ressemble l’histogramme de cette image \n",
    "\n",
    "afficher_histogramme(fingerprint[:,:,0], titre=\"Image - emprunte digitale\")\n",
    "\n",
    "# calculons le seuil d’Otsu et effectuons le seuillage\n",
    "seuil_emprunte = seuil_otsu(fingerprint)\n",
    "fingerprint_otsu = seuillage_simple(fingerprint, seuil_emprunte)\n",
    "print(f\"Seuil Otsu pour l’emprunte : {seuil_emprunte}\")\n",
    "# Afficher\n",
    "afficher_histogramme(fingerprint_otsu[:, :,0], titre=\"Traitement emprunte - Otsu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate que le succès n’est pas vraiment au rendez-vous : en effet l’histogramme de l’image de départ n’est pas vraiment bimodal. Peut-être qu’en augmentant le contraste avant le seuillage le résultat serait meilleur ? Il faudrait éclaircir les zones claires / floues (avec une correction gamma par exemple) puis seuiller :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fingerprint_egal = egaliser_histogramme(fingerprint)[0]\n",
    "afficher_histogramme(fingerprint_egal[:,:,0], titre=\"Emprunte digitale - égalisation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fingerprint_corrige = correction_gamma(fingerprint_egal, 0.1)\n",
    "afficher_histogramme(fingerprint_corrige[:,:,0], titre=\"Emprunte digitale - correction gamma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fingerprint_corrige = correction_gamma(fingerprint_corrige, 2)\n",
    "afficher_histogramme(fingerprint_corrige[:,:,0], titre=\"Emprunte digitale - correction gamma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquons maintenant le seuillage d’Otsu :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seuil_emprunte = seuil_otsu(fingerprint_corrige)\n",
    "fingerprint_otsu = seuillage_simple(fingerprint_corrige, seuil_emprunte)\n",
    "print(f\"Seuil Otsu pour l’emprunte : {seuil_emprunte}\")\n",
    "\n",
    "afficher_histogramme(fingerprint_otsu[:, :,2], titre=\"Traitement emprunte - Otsu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C’est beaucoup mieux, mais pas optimal. Il faudrait certainement appliquer une correction non linéaire qui offre un traitement plus différentiel dans les hautes/basses lumières que la correction gamma (une courbe en « S » par exemple) pour optimiser le contraste avant le seuillage. Ou utiliser des techniques plus sophistiqués qu’un simple seuillage, qui repèrerait directement les motifs dans les différentes zones de l’image. On voit dans cet exemple que le traitement de situations réelles est nettement plus compliqué que les exemples trop parfaits généralement vus en cours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 4 : Convolution\n",
    "\n",
    "### 4.1 : Filtres (ou masques)\n",
    "\n",
    "#### 4.1.1 : la Convolution\n",
    "\n",
    "La convolution est l'opération fondamentale du traitement d'images. Elle permet de transformer une image en combinant chaque pixel avec ses voisins selon une règle définie par un noyau (ou masque, ou filtre).\n",
    "C’est une opération qui est également utilisé en *deep learning*, notamment dans des architectures dites *CNN* (convolution neural network), particulièrement performants dans la reconnaissance d’image. Ainsi bien comprendre cette notion vous aidera lorsque vous ferez du *deep learning*.\n",
    "\n",
    "Cette méthode est capable de détecter des patterns particuliers dans une image (des changements de valeurs plus ou moins rapides, une organisation des valeurs dans une direction donnée, etc.), elle est donc très utile pour détecter des zones particulières d’une image, comme les contours des formes présentes dans l’image, etc.\n",
    "\n",
    "##### Principe (intuition)\n",
    "\n",
    "Comme dans tout ce que l’on a vu précédemment, on va chercher un moyen de calculer une nouvelle valeur (de sortie) pour un pixel donné dans une image, et ainsi créer une nouvelle image dont certaines caractéristiques auront reçu un traitement spécifique. Dans le cas de la convolution, au lieu de considérer uniquement ce pixel indépendemment des autres, on va prendre en compte tout son voisinage (par exemple une zone 3×3 – un « masque » – centrée sur lui), c’est à dire 3 pixels au dessus (le pixel immédiatement au dessus plus les deux diagonales), les trois en dessous (le pixel immédiatement au dessous plus les deux diagonales), et les deux pixels à ses côté (immédiatement à droite et à gauche). On va ensuite définir un noyau de convolution qui indique comment pondérer chaque voisin dans le calcul : si le masque est une matrice 3×3, le noyau correspondant est définit pas les valeurs des 9 coefficients de cette matrice.\n",
    "\n",
    "Comment utilise-t-on ce noyau ?\n",
    "\n",
    "Concrètement, on \"pose\" le noyau sur l'image, centré sur le pixel à transformer. On multiplie chaque valeur du noyau par le pixel correspondant de l'image, puis on fait la somme. Cette somme devient la nouvelle valeur du pixel.\n",
    "\n",
    "Voici une image qui illustre le processus, qui apparaît plus compliqué quand on l’écrit qu’il n’est réellement :\n",
    "\n",
    "![Schéma application masque convolution](./images/MasqueConvolution.png)\n",
    "\n",
    "Vous comprenez pourquoi on parle aussi de « masque » de convolution. Alors que l’on considérait l’ensemble de l’image quand on faisait des manipulation à partir de l’histogramme, ici le filtrage est déterminé par des valeurs considérées localement (un sous ensemble de l’image), c’est pour ça qu’on parlera aussi de filtrage local.\n",
    "\n",
    "**Note 1** : On constate que l’image transformée contient des valeurs qui ne font pas sens pour l’affichage (des valeurs négatives, etc.), il faut donc renormaliser ces valeurs, pour qu’elle soient comprises dans un intervalle $[0; 255]$. Cela est surtout vrai si on veut afficher l’image, on peut aussi destiner cette transformation à d’autres traitements.\n",
    "\n",
    "**Note 2** : détail pratique, le masque faisant une certaine largeur ou hauteur, il faut gérer aussi l’approche des bords de l’image (le masque centré sur un pixel au bord « débordera » de l’image). On peut utiliser différentes stratégies en fonction de la situation, qui reposent généralement sur du *padding* : on fait comme s’il y avait des pixels tout autour de l’image. On peut fixer différentes valeurs pour ces pixels rajoutés :\n",
    "* mise à zéro (valeur = 0)\n",
    "* continuité (valeur = valeur du pixel le plus proche sur le bord)\n",
    "* des choses plus sophistiquées : miroir (valeur du pixel symétrique par rapport au bord), sphérique/torique (valeur du pixel de l’autre côté, comme si l’image était plaquée sur un tore)\n",
    "\n",
    "Exemples de noyaux classiques (le choix du noyau détermine l'effet produit) :\n",
    "- Coefficients tous égaux (ex: 1/9 partout) -> Flou moyenneur (lisse l'image)\n",
    "- Coefficients gaussiens (plus forts au centre) -> Flou gaussien (lisse en préservant mieux les structures)\n",
    "- Coefficients positifs et négatifs -> Détection de contours (fait ressortir les transitions) ou amélioration de la netteté dans certains cas.\n",
    "On trouve dans [l’article dédié sur Wikipedia](https://fr.wikipedia.org/wiki/Noyau_(traitement_d%27image)) un certains nombre d’exemples de noyaux avec une illustration de leurs effets.\n",
    "\n",
    "##### Formulation mathématique\n",
    "Maintenant que nous avons posé le principe, voyons comment nous pouvons le formuler du point de vue mathématique.\n",
    "\n",
    "Pour une image $I$ et un noyau $K$, la convolution produit une nouvelle image $I’$ définie par :\n",
    "\n",
    "$$\n",
    "I’(x,y) = \\sum_{i,j} K(i,j) \\cdot I(x+i, y+j)\n",
    "$$\n",
    "\n",
    "où :\n",
    "\n",
    "* $(x,y)$ est la position du pixel qu'on calcule dans l'image de sortie\n",
    "* $(i,j)$ parcourt toutes les positions du noyau (par exemple de -1 à +1 pour un noyau 3×3)\n",
    "\n",
    "$K(i,j)$ est le coefficient du noyau à la position $(i,j)$\n",
    "$I(x+i,y+j)$ est l'intensité du pixel voisin correspondant dans l'image d'entrée\n",
    "\n",
    "En d'autres termes : on fait une somme pondérée des pixels voisins, où les poids sont donnés par le noyau.\n",
    "\n",
    "La formule ci-dessus peut sembler bien compliquée pour qui n’est pas habitué, mais en fait elle exprime une idée toute simple, illustrée par les schémas ci-dessous :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def demo_convolution_pas_a_pas():\n",
    "    \"\"\"\n",
    "    Démonstration pas à pas du calcul de convolution sur un exemple simple.\n",
    "    \"\"\"\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Image et noyau simples pour l'exemple\n",
    "    # =========================================================================\n",
    "    \n",
    "    # Image 6x6 avec des valeurs simples\n",
    "    image = np.array([\n",
    "        [10, 10, 10, 50, 50, 50],\n",
    "        [10, 10, 10, 50, 50, 50],\n",
    "        [10, 10, 10, 50, 50, 50],\n",
    "        [10, 10, 10, 50, 50, 50],\n",
    "        [10, 10, 10, 50, 50, 50],\n",
    "        [10, 10, 10, 50, 50, 50]\n",
    "    ], dtype=np.float64)\n",
    "    \n",
    "    # Noyau moyenneur 3x3\n",
    "    noyau_moyenne = np.array([\n",
    "        [1/9, 1/9, 1/9],\n",
    "        [1/9, 1/9, 1/9],\n",
    "        [1/9, 1/9, 1/9]\n",
    "    ])\n",
    "    \n",
    "    # Noyau de détection de contours verticaux (Sobel X simplifié)\n",
    "    noyau_contour = np.array([\n",
    "        [-1, 0, 1],\n",
    "        [-1, 0, 1],\n",
    "        [-1, 0, 1]\n",
    "    ])\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"CONVOLUTION - EXEMPLE PAS À PAS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Affichage de l'image et du noyau\n",
    "    # =========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"─\" * 70)\n",
    "    print(\"IMAGE D'ENTRÉE (6×6)\")\n",
    "    print(\"─\" * 70)\n",
    "    print(\"\\nL'image contient une transition verticale (10 → 50) :\")\n",
    "    print()\n",
    "    for row in image:\n",
    "        print(\"  \" + \"  \".join([f\"{int(v):3d}\" for v in row]))\n",
    "    \n",
    "    print(\"\\n\" + \"─\" * 70)\n",
    "    print(\"NOYAU MOYENNEUR (3×3)\")\n",
    "    print(\"─\" * 70)\n",
    "    print()\n",
    "    for row in noyau_moyenne:\n",
    "        print(\"  \" + \"  \".join([f\"{v:.3f}\" for v in row]))\n",
    "    print(\"\\n→ Chaque coefficient = 1/9 ≈ 0.111\")\n",
    "    print(\"→ La somme des coefficients = 1 (préserve la luminosité moyenne)\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Calcul détaillé pour UN pixel\n",
    "    # =========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"─\" * 70)\n",
    "    print(\"CALCUL DÉTAILLÉ POUR LE PIXEL (2, 3)\")\n",
    "    print(\"─\" * 70)\n",
    "    \n",
    "    x, y = 2, 3  # Position du pixel à calculer\n",
    "    \n",
    "    print(f\"\\nOn veut calculer G({x}, {y}) — le pixel à la ligne {x}, colonne {y}\")\n",
    "    print(\"\\nÉtape 1 : Extraire le voisinage 3×3 centré sur ({}, {})\".format(x, y))\n",
    "    print()\n",
    "    \n",
    "    # Extraire le voisinage\n",
    "    voisinage = image[x-1:x+2, y-1:y+2]\n",
    "    \n",
    "    print(\"Voisinage extrait :\")\n",
    "    print(\"┌─────┬─────┬─────┐\")\n",
    "    for i, row in enumerate(voisinage):\n",
    "        print(\"│\", end=\"\")\n",
    "        for j, v in enumerate(row):\n",
    "            print(f\" {int(v):3d} │\", end=\"\")\n",
    "        print()\n",
    "        if i < 2:\n",
    "            print(\"├─────┼─────┼─────┤\")\n",
    "    print(\"└─────┴─────┴─────┘\")\n",
    "    \n",
    "    print(\"\\nÉtape 2 : Multiplier élément par élément avec le noyau\")\n",
    "    print()\n",
    "    print(\"  Voisinage       ×       Noyau         =     Produits\")\n",
    "    print()\n",
    "    \n",
    "    produits = voisinage * noyau_moyenne\n",
    "    \n",
    "    for i in range(3):\n",
    "        v_str = \"  \".join([f\"{int(voisinage[i,j]):3d}\" for j in range(3)])\n",
    "        k_str = \"  \".join([f\"{noyau_moyenne[i,j]:.3f}\" for j in range(3)])\n",
    "        p_str = \"  \".join([f\"{produits[i,j]:5.2f}\" for j in range(3)])\n",
    "        \n",
    "        if i == 1:\n",
    "            print(f\"  [{v_str}]   ×   [{k_str}]   =   [{p_str}]\")\n",
    "        else:\n",
    "            print(f\"  [{v_str}]       [{k_str}]       [{p_str}]\")\n",
    "    \n",
    "    print(\"\\nÉtape 3 : Sommer tous les produits\")\n",
    "    print()\n",
    "    print(\"  G({}, {}) = \".format(x, y), end=\"\")\n",
    "    termes = []\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            termes.append(f\"{produits[i,j]:.2f}\")\n",
    "    print(\" + \".join(termes[:3]))\n",
    "    print(\"           + \" + \" + \".join(termes[3:6]))\n",
    "    print(\"           + \" + \" + \".join(termes[6:9]))\n",
    "    print()\n",
    "    resultat = produits.sum()\n",
    "    print(f\"  G({x}, {y}) = {resultat:.2f}\")\n",
    "    print()\n",
    "    print(f\"→ Le pixel (2,3) qui valait {int(image[x,y])} devient {resultat:.1f}\")\n",
    "    print(\"  (moyenne des 9 voisins : 6 pixels à 10 et 3 pixels à 50)\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Calcul pour un pixel sur le contour\n",
    "    # =========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"─\" * 70)\n",
    "    print(\"CALCUL POUR LE PIXEL (2, 2) — au bord de la transition\")\n",
    "    print(\"─\" * 70)\n",
    "    \n",
    "    x2, y2 = 2, 2\n",
    "    voisinage2 = image[x2-1:x2+2, y2-1:y2+2]\n",
    "    produits2 = voisinage2 * noyau_moyenne\n",
    "    resultat2 = produits2.sum()\n",
    "    \n",
    "    print(f\"\\nVoisinage de ({x2}, {y2}) :\")\n",
    "    for row in voisinage2:\n",
    "        print(\"  \" + \"  \".join([f\"{int(v):3d}\" for v in row]))\n",
    "    \n",
    "    print(f\"\\nG({x2}, {y2}) = {resultat2:.2f}\")\n",
    "    print(f\"→ Le pixel (2,2) qui valait {int(image[x2,y2])} devient {resultat2:.1f}\")\n",
    "    print(\"  (9 pixels à 10 → moyenne = 10)\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Visualisation graphique\n",
    "    # =========================================================================\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 9))\n",
    "    \n",
    "    # --- Ligne 1 : Convolution avec noyau moyenneur ---\n",
    "    \n",
    "    # Image originale avec zone surlignée\n",
    "    ax1 = axes[0, 0]\n",
    "    im1 = ax1.imshow(image, cmap='gray', vmin=0, vmax=60)\n",
    "    ax1.set_title('Image originale\\n(transition 10 → 50)', fontweight='bold')\n",
    "    # Annoter les valeurs\n",
    "    for i in range(6):\n",
    "        for j in range(6):\n",
    "            ax1.text(j, i, f'{int(image[i,j])}', ha='center', va='center',\n",
    "                    fontsize=10, color='red' if image[i,j] < 30 else 'blue')\n",
    "    # Rectangle pour le voisinage\n",
    "    rect = patches.Rectangle((y-1.5, x-1.5), 3, 3, linewidth=3,\n",
    "                               edgecolor='lime', facecolor='none')\n",
    "    ax1.add_patch(rect)\n",
    "    ax1.set_xticks(range(6))\n",
    "    ax1.set_yticks(range(6))\n",
    "    ax1.set_xlabel('Colonne (y)')\n",
    "    ax1.set_ylabel('Ligne (x)')\n",
    "    \n",
    "    # Noyau\n",
    "    ax2 = axes[0, 1]\n",
    "    ax2.imshow(noyau_moyenne, cmap='Blues', vmin=0, vmax=0.2)\n",
    "    ax2.set_title('Noyau moyenneur\\n(3×3, somme=1)', fontweight='bold')\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            ax2.text(j, i, f'{noyau_moyenne[i,j]:.2f}', ha='center', va='center',\n",
    "                    fontsize=12, color='black')\n",
    "    ax2.set_xticks([0, 1, 2])\n",
    "    ax2.set_yticks([0, 1, 2])\n",
    "    ax2.set_xticklabels(['-1', '0', '+1'])\n",
    "    ax2.set_yticklabels(['-1', '0', '+1'])\n",
    "    \n",
    "    # Produits\n",
    "    ax3 = axes[0, 2]\n",
    "    ax3.imshow(produits, cmap='Oranges', vmin=0, vmax=6)\n",
    "    ax3.set_title(f'Produits (voisinage × noyau)\\nSomme = {resultat:.1f}', fontweight='bold')\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            ax3.text(j, i, f'{produits[i,j]:.2f}', ha='center', va='center',\n",
    "                    fontsize=11, color='black')\n",
    "    ax3.set_xticks([0, 1, 2])\n",
    "    ax3.set_yticks([0, 1, 2])\n",
    "    \n",
    "    # Résultat complet\n",
    "    def convolution_complete(img, noyau):\n",
    "        h, w = img.shape\n",
    "        kh, kw = noyau.shape\n",
    "        pad = kh // 2\n",
    "        img_pad = np.pad(img, pad, mode='reflect')\n",
    "        resultat = np.zeros_like(img)\n",
    "        for i in range(h):\n",
    "            for j in range(w):\n",
    "                resultat[i, j] = np.sum(img_pad[i:i+kh, j:j+kw] * noyau)\n",
    "        return resultat\n",
    "    \n",
    "    img_moyenne = convolution_complete(image, noyau_moyenne)\n",
    "    \n",
    "    ax4 = axes[0, 3]\n",
    "    ax4.imshow(img_moyenne, cmap='gray', vmin=0, vmax=60)\n",
    "    ax4.set_title('Résultat : image floutée\\n(transition adoucie)', fontweight='bold')\n",
    "    for i in range(6):\n",
    "        for j in range(6):\n",
    "            ax4.text(j, i, f'{img_moyenne[i,j]:.0f}', ha='center', va='center',\n",
    "                    fontsize=9, color='red' if img_moyenne[i,j] < 30 else 'blue')\n",
    "    ax4.set_xticks(range(6))\n",
    "    ax4.set_yticks(range(6))\n",
    "    \n",
    "    # --- Ligne 2 : Convolution avec noyau de contours ---\n",
    "    \n",
    "    ax5 = axes[1, 0]\n",
    "    ax5.imshow(image, cmap='gray', vmin=0, vmax=60)\n",
    "    ax5.set_title('Image originale', fontweight='bold')\n",
    "    for i in range(6):\n",
    "        for j in range(6):\n",
    "            ax5.text(j, i, f'{int(image[i,j])}', ha='center', va='center',\n",
    "                    fontsize=10, color='red' if image[i,j] < 30 else 'blue')\n",
    "    ax5.set_xticks(range(6))\n",
    "    ax5.set_yticks(range(6))\n",
    "    \n",
    "    ax6 = axes[1, 1]\n",
    "    cmap_contour = plt.cm.RdBu_r\n",
    "    ax6.imshow(noyau_contour, cmap=cmap_contour, vmin=-1.5, vmax=1.5)\n",
    "    ax6.set_title('Noyau détection contours\\n(dérivée horizontale)', fontweight='bold')\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            val = noyau_contour[i, j]\n",
    "            color = 'white' if abs(val) > 0.5 else 'black'\n",
    "            ax6.text(j, i, f'{int(val):+d}', ha='center', va='center',\n",
    "                    fontsize=14, fontweight='bold', color=color)\n",
    "    ax6.set_xticks([0, 1, 2])\n",
    "    ax6.set_yticks([0, 1, 2])\n",
    "    ax6.set_xticklabels(['-1', '0', '+1'])\n",
    "    ax6.set_yticklabels(['-1', '0', '+1'])\n",
    "    \n",
    "    # Calcul détaillé pour contours\n",
    "    voisinage_contour = image[2:5, 2:5]\n",
    "    produits_contour = voisinage_contour * noyau_contour\n",
    "    \n",
    "    ax7 = axes[1, 2]\n",
    "    ax7.imshow(produits_contour, cmap=cmap_contour, vmin=-60, vmax=60)\n",
    "    ax7.set_title(f'Produits\\nSomme = {produits_contour.sum():.0f}', fontweight='bold')\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            val = produits_contour[i, j]\n",
    "            color = 'white' if abs(val) > 20 else 'black'\n",
    "            ax7.text(j, i, f'{val:.0f}', ha='center', va='center',\n",
    "                    fontsize=11, color=color)\n",
    "    ax7.set_xticks([0, 1, 2])\n",
    "    ax7.set_yticks([0, 1, 2])\n",
    "    \n",
    "    img_contour = convolution_complete(image, noyau_contour)\n",
    "    \n",
    "    ax8 = axes[1, 3]\n",
    "    im8 = ax8.imshow(img_contour, cmap=cmap_contour, vmin=-150, vmax=150)\n",
    "    ax8.set_title('Résultat : contours détectés\\n(fort gradient à la transition)', fontweight='bold')\n",
    "    for i in range(6):\n",
    "        for j in range(6):\n",
    "            val = img_contour[i, j]\n",
    "            color = 'white' if abs(val) > 50 else 'black'\n",
    "            ax8.text(j, i, f'{val:.0f}', ha='center', va='center',\n",
    "                    fontsize=9, color=color)\n",
    "    ax8.set_xticks(range(6))\n",
    "    ax8.set_yticks(range(6))\n",
    "    \n",
    "    plt.suptitle('Convolution pas à pas : deux noyaux, deux effets', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "demo_convolution_pas_a_pas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Interprétation :\n",
    "\n",
    "* NOYAU MOYENNEUR (flou)\n",
    "    * Tous les coefficients sont positifs et égaux (1/9)\n",
    "    * Chaque pixel devient la moyenne de ses voisins\n",
    "    * Effet : la transition brutale 10→50 devient progressive\n",
    "    * Les colonnes 2 et 3 ont des valeurs intermédiaires (~23 et ~37)\n",
    "    \n",
    "* NOYAU DÉTECTION DE CONTOURS (dérivée)\n",
    "    * Coefficients négatifs à gauche (-1), nuls au centre (0), positifs à droite (+1)\n",
    "    * Calcul : (voisins droite) - (voisins gauche)\n",
    "    * Si pas de variation horizontale → résultat proche de 0\n",
    "    * Si transition gauche→droite → résultat positif (contour détecté!)\n",
    "    \n",
    "    * Colonnes 0,1 : que des 10 autour → 10×(1+1+1) + 10×(-1-1-1) = 0\n",
    "    * Colonne 2,3 : transition → 50×(1+1+1) + 10×(-1-1-1) = 150 - 30 = 120\n",
    "    * Colonnes 4,5 : que des 50 autour → 50×(1+1+1) + 50×(-1-1-1) = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainsi on peut créer des filtres qui sont sensibles à certaines variations selon certaines directions, ce qui nous permettrait de détecter des contours :\n",
    "\n",
    "* détection horizontale avec le noyau :\n",
    "  $$\n",
    "  K = \\begin{bmatrix} -1 & 0 & +1 \\\\ -1 & 0 & +1 \\\\ -1 & 0 & +1 \\end{bmatrix}\n",
    "  $$\n",
    "* détection horizontale :\n",
    "  $$\n",
    "  K = \\begin{bmatrix} -1 & -1 & -1 \\\\ 0 & 0 & 0 \\\\ +1 & +1 & +1 \\end{bmatrix}\n",
    "  $$\n",
    "* en diagonale (+45° ou -45°) :\n",
    "  $$\n",
    "  K_{+45°} = \\begin{bmatrix} 0 & 0 & 0 \\\\ 0 & -1 & 0 \\\\ 0 & 0 & +1 \\end{bmatrix}\n",
    "  \\qquad\n",
    "  K_{-45°} = \\begin{bmatrix} 0 & 0 & 0 \\\\ 0 & 0 & +1 \\\\ 0 & -1 & 0 \\end{bmatrix}\n",
    "  $$\n",
    "\n",
    "Bien sûr, détecter des variations selon des directions privilégiées ont d’autres applications que détecter des contours, la détection de ces motifs de bases jouent aussi leur rôle dans la reconnaissance de forme, et sont au cœur de l’architecture CNN en *deep learning*.\n",
    "\n",
    "On peut créer des noyaux plus élaborés en choisissant des valeurs différentes de 1 pour certains coéfficient, ce qui permet de pondérer certaines directions (pixels voisins). Nous ne sommes pas non plus limité à des matices 3×3, par exemple on peut aussi utiliser des matrices 5×5, qui prendront alors en compte des pixels plus éloignés (masques plus grands).\n",
    "\n",
    "Nous allons voir un filtre très populaire en détection de contour : le filtre de Sobel.\n",
    "\n",
    "#### 4.1.2 : filtre de Sobel – Détection de contours\n",
    "\n",
    "Le filtre de Sobel est l'outil classique pour détecter les contours dans une image. Un contour correspond à une zone où l'intensité des pixels change brusquement — autrement dit, là où le gradient (la pente) de l'image est fort.\n",
    "\n",
    "##### Principe\n",
    "Pour détecter un contour, on cherche à mesurer à quelle vitesse l'intensité change quand on se déplace dans l'image. Cette variation s'appelle le gradient. Comme l'image est en 2D, on calcule le gradient selon deux directions :\n",
    "\n",
    "- Gradient horizontal $G_x$ : détecte les contours verticaux (transitions gauche-droite)\n",
    "- Gradient vertical $G_y$ : détecte les contours horizontaux (transitions haut-bas)\n",
    "\n",
    "Pour effectuer ces détection, Sobel propose deux noyaux (des matrices 3×3) définis ainsi :\n",
    "$$\n",
    "K_x = \\begin{bmatrix} -1 & 0 & +1 \\\\ -2 & 0 & +2 \\\\ -1 & 0 & +1 \\end{bmatrix}\n",
    "\\qquad\n",
    "K_y = \\begin{bmatrix} -1 & -2 & -1 \\\\ 0 & 0 & 0 \\\\ +1 & +2 & +1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "##### Compréhension intuitive\n",
    "\n",
    "Regardons $K_x$ de plus près :\n",
    "- Colonne de gauche : coefficients négatifs → on soustrait les voisins de gauche\n",
    "- Colonne de droite : coefficients positifs → on ajoute les voisins de droite\n",
    "- Le coefficient central (±2) donne plus de poids au voisin direct\n",
    "\n",
    "Le résultat $G_x$ sera donc élevé s'il y a une forte différence entre la droite et la gauche, c'est-à-dire un contour vertical. Le noyau $K_y$ fonctionne de la même façon mais verticalement.\n",
    "\n",
    "Un autre indice important est la **magnitude des gradients calculés** : une fois $G_x$ et $G_y$ calculés, on combine les deux pour obtenir la force totale du contour en chaque pixel.\n",
    "$$\n",
    "G = \\sqrt{G_x^2 + G_y^2}\n",
    "$$\n",
    "Cette magnitude est élevée là où il y a un contour (quelle que soit son orientation) et proche de zéro dans les zones uniformes. On obtiendra donc une image de sortie où les pixels clairs (de valeurs élevés) correspondront aux contours détectés, les autres pixels seront sombres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def demo_filtre_sobel():\n",
    "    \"\"\"\n",
    "    Démonstration du filtre de Sobel pour la détection de contours.\n",
    "    \"\"\"\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Création d'une image test avec différents types de contours\n",
    "    # =========================================================================\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    h, w = 200, 250\n",
    "    img = np.ones((h, w), dtype=np.float64) * 180\n",
    "    \n",
    "    # Rectangle (contours horizontaux et verticaux)\n",
    "    img[30:80, 30:100] = 60\n",
    "    \n",
    "    # Cercle (contours dans toutes les directions)\n",
    "    centre_x, centre_y = 180, 60\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            if (i - centre_y)**2 + (j - centre_x)**2 < 35**2:\n",
    "                img[i, j] = 50\n",
    "    \n",
    "    # Triangle (contours diagonaux)\n",
    "    for i in range(50):\n",
    "        gauche = 60 + i\n",
    "        droite = 140 - i\n",
    "        if gauche < droite:\n",
    "            img[100 + i, gauche:droite] = 70\n",
    "    \n",
    "    # Dégradé progressif (pas de contour net)\n",
    "    for j in range(50, 100):\n",
    "        img[160:190, j] = 80 + (j - 50) * 2\n",
    "    \n",
    "    # Léger bruit\n",
    "    img += np.random.normal(0, 3, (h, w))\n",
    "    img = np.clip(img, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Définition des noyaux de Sobel\n",
    "    # =========================================================================\n",
    "    \n",
    "    sobel_x = np.array([\n",
    "        [-1, 0, 1],\n",
    "        [-2, 0, 2],\n",
    "        [-1, 0, 1]\n",
    "    ], dtype=np.float64)\n",
    "    \n",
    "    sobel_y = np.array([\n",
    "        [-1, -2, -1],\n",
    "        [ 0,  0,  0],\n",
    "        [ 1,  2,  1]\n",
    "    ], dtype=np.float64)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Fonction de convolution\n",
    "    # =========================================================================\n",
    "    \n",
    "    def convoluer(image, noyau):\n",
    "        \"\"\"Applique une convolution avec padding par réflexion.\"\"\"\n",
    "        h, w = image.shape\n",
    "        kh, kw = noyau.shape\n",
    "        pad = kh // 2\n",
    "        \n",
    "        img_pad = np.pad(image.astype(np.float64), pad, mode='reflect')\n",
    "        resultat = np.zeros((h, w), dtype=np.float64)\n",
    "        \n",
    "        for i in range(h):\n",
    "            for j in range(w):\n",
    "                resultat[i, j] = np.sum(img_pad[i:i+kh, j:j+kw] * noyau)\n",
    "        \n",
    "        return resultat\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Application des filtres de Sobel\n",
    "    # =========================================================================\n",
    "    \n",
    "    # Gradients directionnels\n",
    "    Gx = convoluer(img, sobel_x)\n",
    "    Gy = convoluer(img, sobel_y)\n",
    "    \n",
    "    # Magnitude du gradient\n",
    "    magnitude = np.sqrt(Gx**2 + Gy**2)\n",
    "    \n",
    "    # Normalisation pour affichage\n",
    "    magnitude_norm = (magnitude / magnitude.max() * 255).astype(np.uint8)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Visualisation principale\n",
    "    # =========================================================================\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    \n",
    "    # --- Ligne 1 : Image et noyaux ---\n",
    "    \n",
    "    # Image originale\n",
    "    axes[0, 0].imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "    axes[0, 0].set_title('Image originale', fontsize=12, fontweight='bold')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # Noyau Sobel X\n",
    "    ax_kx = axes[0, 1]\n",
    "    im_kx = ax_kx.imshow(sobel_x, cmap='RdBu_r', vmin=-2, vmax=2)\n",
    "    ax_kx.set_title('Noyau Sobel X\\n(détecte contours verticaux)', fontsize=11, fontweight='bold')\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            val = sobel_x[i, j]\n",
    "            color = 'white' if abs(val) > 1 else 'black'\n",
    "            ax_kx.text(j, i, f'{int(val):+d}', ha='center', va='center',\n",
    "                      fontsize=16, fontweight='bold', color=color)\n",
    "    ax_kx.set_xticks([0, 1, 2])\n",
    "    ax_kx.set_yticks([0, 1, 2])\n",
    "    ax_kx.set_xticklabels(['G', 'C', 'D'])\n",
    "    ax_kx.set_yticklabels(['H', 'C', 'B'])\n",
    "    \n",
    "    # Noyau Sobel Y\n",
    "    ax_ky = axes[0, 2]\n",
    "    im_ky = ax_ky.imshow(sobel_y, cmap='RdBu_r', vmin=-2, vmax=2)\n",
    "    ax_ky.set_title('Noyau Sobel Y\\n(détecte contours horizontaux)', fontsize=11, fontweight='bold')\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            val = sobel_y[i, j]\n",
    "            color = 'white' if abs(val) > 1 else 'black'\n",
    "            ax_ky.text(j, i, f'{int(val):+d}', ha='center', va='center',\n",
    "                      fontsize=16, fontweight='bold', color=color)\n",
    "    ax_ky.set_xticks([0, 1, 2])\n",
    "    ax_ky.set_yticks([0, 1, 2])\n",
    "    ax_ky.set_xticklabels(['G', 'C', 'D'])\n",
    "    ax_ky.set_yticklabels(['H', 'C', 'B'])\n",
    "    \n",
    "    # --- Ligne 2 : Résultats ---\n",
    "    \n",
    "    # Gradient X\n",
    "    ax_gx = axes[1, 0]\n",
    "    vmax_g = max(abs(Gx.min()), abs(Gx.max()))\n",
    "    im_gx = ax_gx.imshow(Gx, cmap='RdBu_r', vmin=-vmax_g, vmax=vmax_g)\n",
    "    ax_gx.set_title('Gradient Gx\\n(positif=transition →, négatif=transition ←)', \n",
    "                    fontsize=11, fontweight='bold')\n",
    "    ax_gx.axis('off')\n",
    "    plt.colorbar(im_gx, ax=ax_gx, fraction=0.046, pad=0.04)\n",
    "    \n",
    "    # Gradient Y\n",
    "    ax_gy = axes[1, 1]\n",
    "    vmax_g = max(abs(Gy.min()), abs(Gy.max()))\n",
    "    im_gy = ax_gy.imshow(Gy, cmap='RdBu_r', vmin=-vmax_g, vmax=vmax_g)\n",
    "    ax_gy.set_title('Gradient Gy\\n(positif=transition ↓, négatif=transition ↑)', \n",
    "                    fontsize=11, fontweight='bold')\n",
    "    ax_gy.axis('off')\n",
    "    plt.colorbar(im_gy, ax=ax_gy, fraction=0.046, pad=0.04)\n",
    "    \n",
    "    # Magnitude\n",
    "    ax_mag = axes[1, 2]\n",
    "    im_mag = ax_mag.imshow(magnitude_norm, cmap='hot')\n",
    "    ax_mag.set_title('Magnitude |G| = √(Gx² + Gy²)\\n(intensité du contour)', \n",
    "                     fontsize=11, fontweight='bold')\n",
    "    ax_mag.axis('off')\n",
    "    plt.colorbar(im_mag, ax=ax_mag, fraction=0.046, pad=0.04)\n",
    "    \n",
    "    plt.suptitle('Filtre de Sobel : détection de contours', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Zoom sur une zone pour expliquer les signes\n",
    "    # =========================================================================\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "    \n",
    "    # Zone du rectangle (contient des contours verticaux et horizontaux nets)\n",
    "    y1, y2 = 20, 90\n",
    "    x1, x2 = 20, 110\n",
    "    \n",
    "    axes[0].imshow(img[y1:y2, x1:x2], cmap='gray', vmin=0, vmax=255)\n",
    "    axes[0].set_title('Zoom : rectangle\\n(contours nets)', fontweight='bold')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(Gx[y1:y2, x1:x2], cmap='RdBu_r', vmin=-400, vmax=400)\n",
    "    axes[1].set_title('Gx : bords gauche (-) et droit (+)\\ndu rectangle détectés', fontweight='bold')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    axes[2].imshow(Gy[y1:y2, x1:x2], cmap='RdBu_r', vmin=-400, vmax=400)\n",
    "    axes[2].set_title('Gy : bords haut (-) et bas (+)\\ndu rectangle détectés', fontweight='bold')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    axes[3].imshow(magnitude[y1:y2, x1:x2], cmap='hot')\n",
    "    axes[3].set_title('Magnitude : tous les\\ncontours combinés', fontweight='bold')\n",
    "    axes[3].axis('off')\n",
    "    \n",
    "    plt.suptitle('Interprétation des signes du gradient', fontsize=13, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "demo_filtre_sobel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fonctionnement du filtre de Sobel\n",
    "\n",
    "* GRADIENT Gx (noyau horizontal)\n",
    "    * Gx > 0 (rouge) : l'intensité AUGMENTE de gauche à droite\n",
    "                       → contour vertical, côté DROIT d'un objet sombre\n",
    "    * Gx < 0 (bleu)  : l'intensité DIMINUE de gauche à droite\n",
    "                       → contour vertical, côté GAUCHE d'un objet sombre\n",
    "    * Gx ≈ 0         : pas de variation horizontale (zone uniforme)\n",
    "    \n",
    "* GRADIENT Gy (noyau vertical)\n",
    "    * Gy > 0 (rouge) : l'intensité AUGMENTE de haut en bas\n",
    "                       → contour horizontal, côté BAS d'un objet sombre\n",
    "    * Gy < 0 (bleu)  : l'intensité DIMINUE de haut en bas\n",
    "                       → contour horizontal, côté HAUT d'un objet sombre\n",
    "    * Gy ≈ 0         : pas de variation verticale (zone uniforme)\n",
    "    \n",
    "* MAGNITUDE |G|\n",
    "    * Combine Gx et Gy : $|G| = \\sqrt{G_x^2 + G_y^2)}$\n",
    "    * Élevée sur TOUS les contours (quelle que soit l'orientation)\n",
    "    * Proche de 0 dans les zones uniformes\n",
    "    * Le dégradé progressif (en bas) produit une magnitude faible\n",
    "      car la transition est lente, pas un contour net\n",
    "    \n",
    "* Notes :\n",
    "    * Le cercle montre des contours dans toutes les directions\n",
    "      → Gx et Gy sont complémentaires\n",
    "    * Le triangle montre des contours diagonaux\n",
    "      → Gx ET Gy sont non-nuls sur les bords obliques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_2d(img, noyau):\n",
    "    \"\"\"Convolution 2D.\"\"\"\n",
    "    h, w = img.shape\n",
    "    kh, kw = noyau.shape\n",
    "    pad_h, pad_w = kh // 2, kw // 2\n",
    "    \n",
    "    img_padded = np.pad(img.astype(float), ((pad_h, pad_h), (pad_w, pad_w)), mode='reflect')\n",
    "    resultat = np.zeros((h, w), dtype=float)\n",
    "    \n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            resultat[i, j] = np.sum(img_padded[i:i+kh, j:j+kw] * noyau)\n",
    "    return resultat\n",
    "\n",
    "# Filtres de Sobel\n",
    "sobel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "sobel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])\n",
    "\n",
    "gx = convolution_2d(img_gris, sobel_x)\n",
    "gy = convolution_2d(img_gris, sobel_y)\n",
    "magnitude = np.sqrt(gx**2 + gy**2)\n",
    "magnitude = (magnitude / magnitude.max() * 255).astype(np.uint8)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "axes[0,0].imshow(img_gris, cmap='gray'); axes[0,0].set_title('Original'); axes[0,0].axis('off')\n",
    "axes[0,1].imshow(np.abs(gx), cmap='gray'); axes[0,1].set_title('Sobel X'); axes[0,1].axis('off')\n",
    "axes[1,0].imshow(np.abs(gy), cmap='gray'); axes[1,0].set_title('Sobel Y'); axes[1,0].axis('off')\n",
    "axes[1,1].imshow(magnitude, cmap='gray'); axes[1,1].set_title('Magnitude'); axes[1,1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Magique !\n",
    "\n",
    "#### 4.1.3 Autres noyaux de convolution notables\n",
    "\n",
    "##### Filtres de lissage (réduction du bruit)\n",
    "\n",
    "###### Filtre moyenneur (box blur)\n",
    "$$\n",
    "K = \\frac{1}{9}\\begin{bmatrix} 1 & 1 & 1 \\\\ 1 & 1 & 1 \\\\ 1 & 1 & 1 \\end{bmatrix}\n",
    "$$\n",
    "Remplace chaque pixel par la moyenne de ses voisins. Simple mais crée du flou sur les contours.\n",
    "\n",
    "###### Filtre gaussien\n",
    "$$\n",
    "K = \\frac{1}{16}\\begin{bmatrix} 1 & 2 & 1 \\\\ 2 & 4 & 2 \\\\ 1 & 2 & 1 \\end{bmatrix}\n",
    "$$\n",
    "Moyenne pondérée où les voisins immédiats comptent plus. Flou plus naturel, préserve mieux les structures que le moyenneur.\n",
    "\n",
    "###### Filtre médian\n",
    "\n",
    "Calculer la médiane des valeurs des pixels dans le masque, remplacer la valeur du pixel central par cette médiane.\n",
    "Cette méthode donne un rendu moins flou que les noyaux précédents, par contre elle a tendance à détruire les angles. Particulièrement efficace contre le bruit type « neige » ou « poivre et sel ».\n",
    "\n",
    "##### Filtres de détection de contours\n",
    "\n",
    "###### Filtre de Prewitt\n",
    "$$\n",
    "K_x = \\begin{bmatrix} -1 & 0 & +1 \\\\ -1 & 0 & +1 \\\\ -1 & 0 & +1 \\end{bmatrix}\n",
    "\\qquad\n",
    "K_y = \\begin{bmatrix} -1 & -1 & -1 \\\\ 0 & 0 & 0 \\\\ +1 & +1 & +1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Similaire à Sobel mais sans pondération centrale. Moins sensible au bruit que Sobel.\n",
    "\n",
    "###### Filtre laplacien\n",
    "$$\n",
    "K_4 = \\begin{bmatrix} 0 & 1 & 0 \\\\ 1 & -4 & 1 \\\\ 0 & 1 & 0 \\end{bmatrix}\n",
    "\\quad \\text{ou} \\quad\n",
    "K_8 = \\begin{bmatrix} 1 & 1 & 1 \\\\ 1 & -8 & 1 \\\\ 1 & 1 & 1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "On peut aussi inverser les signes (positif pour le coefficient central, négatif sur les coefficients en périphérie). Le Laplacien est un opérateur très impoortant en physique et en traitement du signal, notamment pour filtrer. Il est aussi utilisé pour une catégorie de réseau de neurones (cartes auto-organisatrices notamment, et des modèles dits « *winner take all* »). Il repose sur le calcul d’une dérivée seconde :\n",
    "$$\n",
    "\\nabla^2 = \\frac{\\partial^2 }{\\partial x^2}+\\frac{\\partial^2 }{\\partial y^2}\n",
    "$$\n",
    "\n",
    "> **Explications optionnelles** : *si ça fait déjà trop de math pour vous, vous pouvez sauter cette partie et y revenir plus tard*\n",
    "> \n",
    "> Quel est le rapport avec les matrices ci-dessus ? Comment à partir d’une dérivée seconde arrive-t-on à ces valeurs précises ?\n",
    ">\n",
    "> Calculer une dérivée sur la position des pixels dans un écran ne peut se faire que par approximation : il s’agit de valeurs discrètes (et non continues).\n",
    "> En réalité, l’approximation va consister en le calcul d’une simple différence entre des pixels voisins (p. ex. avec le pixel à droite pour une dérivation selon l’axe x, direction horizontale) :\n",
    "> $$ \\frac{\\partial f }{\\partial x}≈f(x+1)−f(x) $$\n",
    "> Calculer une dérivée seconde, c’est dériver deux fois. C’est à dire qu’on va cacluler pour tous les pixels la dérivé première (différence de tous les pixels avec leurs voisins de droite), et ensuite, pour deuxième dérivée, calculer de la même manière la différence entre ces différences (on  va faire deux soustractions imbriquées) :\n",
    "> $$\\frac{\\partial^2 f }{\\partial x^2} = \\frac{\\partial }{\\partial x}(\\frac{\\partial f }{\\partial x}) ≈ [f(x+1)−f(x)]−[f(x)−f(x−1)]$$\n",
    "> $$= f(x+1)−2f(x)+f(x−1)$$\n",
    "> On constate donc que finalement cela revient à faire une somme entre le pixel central affecté d’un coefficient -2 et les pixels immédiatement à gauche et à droite affectés pour leur part d’un coefficient +1.\n",
    "> C’est exactement les mêmes calculs pour la direction horizontale, donc une somme pour laquelle le pixel central aura un coefficient -2 et les pixel immédiatement au dessus ou en dessous un coefficient +1\n",
    "> Si on « assemble » ces opération, on voit que cela correspond à un noyau 3×3 avec un coefficent (-2) + (-2) pour le pixel central, et +1 pour les pixels dans les 4 directions haut, bas, gauche, droite, soit la matrice :\n",
    "> $$\\begin{bmatrix} 0 & 1 & 0 \\\\ 1 & -4 & 1 \\\\ 0 & 1 & 0 \\end{bmatrix}$$\n",
    "> On comprend de la même manière que le noyau\n",
    "> $$\\begin{bmatrix} 1 & 1 & 1 \\\\ 1 & -8 & 1 \\\\ 1 & 1 & 1 \\end{bmatrix}$$\n",
    "> correspond à une dérivée seconde dans les huits directions (avec les diagonales en plus), et dans ce cas comme on ajoute deux directions par rapport à la situation précédente, le pixel central reçoit 4 fois un coefficient -2 soit -8 au total.\n",
    "\n",
    "$K_8$ détecte les contours dans toutes les directions en une seule opération. Les noyaux laplaciens sont néanmoins très sensibles au bruit.\n",
    "\n",
    "Pour mieux appréhender comment fonctionne cette transformation, voici un bout de code qui permet de visualiser un Laplacien qu’on va appliquer à une Gaussienne qu’on va assimiler à un pic de luminosité sur l’image (zone avec des pixels lumineux au centre et qui s’atténuent assez vite, comme sur un contour). On fait une représentation 3D : x et y sont les positions des pixels sur l’image, alors que z va représenter la  valeur (luminosité) d’un pixel de coordonnée (x, y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "#pio.renderers.default = \"iframe\" # définir ce renderer si problème d’affichage avec px\n",
    "# alternative à tester :  installer !pip install jupyterlab-plotly-extension\n",
    "\n",
    "# Grille 2D\n",
    "x = np.linspace(-3, 3, 80)\n",
    "y = np.linspace(-3, 3, 80)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "# Fonction : une gaussienne (bosse)\n",
    "Z = np.exp(-(X**2 + Y**2))\n",
    "\n",
    "# Laplacien analytique\n",
    "laplacien = (4*X**2 + 4*Y**2 - 4) * np.exp(-(X**2 + Y**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1 : La fonction en 3D\n",
    "fig1 = go.Figure(data=[go.Surface(x=X, y=Y, z=Z, colorscale='Viridis')])\n",
    "fig1.update_layout(title=\"Fonction f(x,y) = exp(-(x² + y²))\")\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2 : Son Laplacien en 3D\n",
    "fig2 = go.Figure(data=[go.Surface(x=X, y=Y, z=laplacien, colorscale='RdBu_r', cmid=0)])\n",
    "fig2.update_layout(title=\"Laplacien ∇²f — négatif (bleu) au sommet de la bosse\")\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que pour une fonction Gaussienne (qui représente une bosse ou un pic de luminosité = maximum au centre) le Laplacien devient fortement **négatif** au centre (en bleu sur la figure), et **positif** sur les bords (en rouge sur la figure). Parfois on trouve l’inverse si on calcule l’opposé du Laplacien, selon les usages qu’on veut en faire. On parle aussi de fonction en forme de « chapeau mexicain ».\n",
    "\n",
    "Ce qu’il est important de retenir, c’est que le pixel (ou groupe de pixels) central est détecté car sa transformation est en valeur absolue nettement plus haute que celle de ses voisins, qui eux seront affecté d’un signe inverse avec une valeur absolue nettement plus petite. Le Laplacien amplifie donc (détecte) le pic de luminosité, et inhibe les voisins avec une luminosité plus faible. C’est pour cela que l’on parle de *winner take all* : non seulement le pixel le plus lumineux est sélectionné, mais les piels voisins concurrents, un peu moins lumineux, sont carrément réduits encore plus que des pixels encore moins lumineux mais plus lointains. \n",
    "\n",
    "###### Filtre de Roberts\n",
    "$$\n",
    "K_x = \\begin{bmatrix} 1 & 0 \\\\ 0 & -1 \\end{bmatrix}\n",
    "\\qquad\n",
    "K_y = \\begin{bmatrix} 0 & 1 \\\\ -1 & 0 \\end{bmatrix}\n",
    "$$\n",
    "Noyau 2×2 pour détecter les contours diagonaux. Rapide mais très sensible au bruit.\n",
    "\n",
    "##### Filtres de netteté (sharpening)\n",
    "###### Filtre d'accentuation (sharpen)\n",
    "$$\n",
    "K = \\begin{bmatrix} 0 & -1 & 0 \\\\ -1 & 5 & -1 \\\\ 0 & -1 & 0 \\end{bmatrix}\n",
    "$$\n",
    "Renforce les contours en amplifiant les différences avec les voisins. Le coefficient central > somme des autres.\n",
    "\n",
    "###### Filtre unsharp mask (masque flou)\n",
    "Principe : Image nette = Image originale + k × (Image originale − Image floue)\n",
    "Accentue les détails en ajoutant la différence entre l'image et sa version floutée.\n",
    "\n",
    "##### Filtre de détection de motifs\n",
    "\n",
    "###### Filtre de relief (emboss)\n",
    "$$\n",
    "K = \\begin{bmatrix} -2 & -1 & 0 \\\\ -1 & 1 & 1 \\\\ 0 & 1 & 2 \\end{bmatrix}\n",
    "$$\n",
    "Crée un effet de relief 3D en accentuant les transitions dans une direction diagonale.\n",
    "\n",
    "\n",
    "##### Récapitulatif :\n",
    "| Noyau     | Taille      | Application           | Somme des coefficients | \n",
    "|-----------|-------------|-----------------------|------------------------|\n",
    "| Moyenneur | 3×3 ou plus | Flou, réduction bruit | 1                      |\n",
    "| Gaussien  | 3×3 ou plus | Flou naturel          | 1                      |\n",
    "| Sobel     | 3×3 | Gradient, contours            | 0                      | \n",
    "| Prewitt   | 3×3 | Gradient, contours            | 0                      | \n",
    "| Laplacien | 3×3 | Contours toutes directions    | 0                      |\n",
    "| Sharpen   | 3×3 | Accentuation netteté          | 1                      | \n",
    "| Emboss    | 3×3 | Effet relief                  | ~1                     |\n",
    "\n",
    "Règle pratique :\n",
    "\n",
    "* Somme = 1 → préserve la luminosité moyenne (flou, netteté)\n",
    "* Somme = 0 → extrait les variations (contours, gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.4 Exercice (optionnel – à faire chez vous)\n",
    "\n",
    "À l’image de ce que nous avons fait pour le filtre de Sobel plus haut, écrivez un bout de code qui permet de visualiser les effets et le fonctionnement des différents noyaux vu ci-dessus (vous pouvez aussi expérimenter pour créer vos propres noyaux).\n",
    "Vous pouvez aussi tester sur des images / photo… et créer votre propre appli de traitement d’image :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def demo_tous_les_noyaux():\n",
    "    \"\"\"\n",
    "    Démonstration visuelle de différents noyaux de convolution.\n",
    "    \"\"\"\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Création d'une image test riche en détails\n",
    "    # =========================================================================\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    h, w = 180, 220\n",
    "    img = np.ones((h, w), dtype=np.float64) * 160\n",
    "    \n",
    "    # Rectangle\n",
    "    img[20:70, 20:80] = 60\n",
    "    \n",
    "    # Cercle\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            if (i - 45)**2 + (j - 140)**2 < 30**2:\n",
    "                img[i, j] = 50\n",
    "    \n",
    "    # Dégradé\n",
    "    for j in range(20, 80):\n",
    "        img[90:130, j] = 60 + (j - 20) * 2.5\n",
    "    \n",
    "    # Lignes fines (pour tester la netteté)\n",
    "    img[140:145, 20:200] = 40\n",
    "    img[150:152, 20:200] = 40\n",
    "    img[156:157, 20:200] = 40\n",
    "    \n",
    "    # Texture (damier)\n",
    "    for i in range(90, 130):\n",
    "        for j in range(120, 160):\n",
    "            if (i + j) % 10 < 5:\n",
    "                img[i, j] = 80\n",
    "    \n",
    "    # Bruit léger\n",
    "    img += np.random.normal(0, 5, (h, w))\n",
    "    img = np.clip(img, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Définition de tous les noyaux\n",
    "    # =========================================================================\n",
    "    \n",
    "    noyaux = {\n",
    "        'Identité': np.array([\n",
    "            [0, 0, 0],\n",
    "            [0, 1, 0],\n",
    "            [0, 0, 0]\n",
    "        ], dtype=np.float64),\n",
    "        \n",
    "        'Moyenneur\\n(box blur)': np.array([\n",
    "            [1, 1, 1],\n",
    "            [1, 1, 1],\n",
    "            [1, 1, 1]\n",
    "        ], dtype=np.float64) / 9,\n",
    "        \n",
    "        'Gaussien\\n3×3': np.array([\n",
    "            [1, 2, 1],\n",
    "            [2, 4, 2],\n",
    "            [1, 2, 1]\n",
    "        ], dtype=np.float64) / 16,\n",
    "        \n",
    "        'Gaussien\\n5×5': np.array([\n",
    "            [1,  4,  6,  4, 1],\n",
    "            [4, 16, 24, 16, 4],\n",
    "            [6, 24, 36, 24, 6],\n",
    "            [4, 16, 24, 16, 4],\n",
    "            [1,  4,  6,  4, 1]\n",
    "        ], dtype=np.float64) / 256,\n",
    "        \n",
    "        'Sobel X\\n(contours V)': np.array([\n",
    "            [-1, 0, 1],\n",
    "            [-2, 0, 2],\n",
    "            [-1, 0, 1]\n",
    "        ], dtype=np.float64),\n",
    "        \n",
    "        'Sobel Y\\n(contours H)': np.array([\n",
    "            [-1, -2, -1],\n",
    "            [ 0,  0,  0],\n",
    "            [ 1,  2,  1]\n",
    "        ], dtype=np.float64),\n",
    "        \n",
    "        'Prewitt X': np.array([\n",
    "            [-1, 0, 1],\n",
    "            [-1, 0, 1],\n",
    "            [-1, 0, 1]\n",
    "        ], dtype=np.float64),\n",
    "        \n",
    "        'Prewitt Y': np.array([\n",
    "            [-1, -1, -1],\n",
    "            [ 0,  0,  0],\n",
    "            [ 1,  1,  1]\n",
    "        ], dtype=np.float64),\n",
    "        \n",
    "        'Laplacien\\n(4-connexe)': np.array([\n",
    "            [ 0,  1,  0],\n",
    "            [ 1, -4,  1],\n",
    "            [ 0,  1,  0]\n",
    "        ], dtype=np.float64),\n",
    "        \n",
    "        'Laplacien\\n(8-connexe)': np.array([\n",
    "            [ 1,  1,  1],\n",
    "            [ 1, -8,  1],\n",
    "            [ 1,  1,  1]\n",
    "        ], dtype=np.float64),\n",
    "        \n",
    "        'Sharpen\\n(netteté)': np.array([\n",
    "            [ 0, -1,  0],\n",
    "            [-1,  5, -1],\n",
    "            [ 0, -1,  0]\n",
    "        ], dtype=np.float64),\n",
    "        \n",
    "        'Sharpen\\n(fort)': np.array([\n",
    "            [-1, -1, -1],\n",
    "            [-1,  9, -1],\n",
    "            [-1, -1, -1]\n",
    "        ], dtype=np.float64),\n",
    "        \n",
    "        'Emboss\\n(relief)': np.array([\n",
    "            [-2, -1, 0],\n",
    "            [-1,  1, 1],\n",
    "            [ 0,  1, 2]\n",
    "        ], dtype=np.float64),\n",
    "        \n",
    "        'Emboss\\n(haut)': np.array([\n",
    "            [ 0,  1,  0],\n",
    "            [ 0,  0,  0],\n",
    "            [ 0, -1,  0]\n",
    "        ], dtype=np.float64),\n",
    "        \n",
    "        'Roberts X\\n(diagonal)': np.array([\n",
    "            [1,  0],\n",
    "            [0, -1]\n",
    "        ], dtype=np.float64),\n",
    "        \n",
    "        'Roberts Y\\n(diagonal)': np.array([\n",
    "            [ 0, 1],\n",
    "            [-1, 0]\n",
    "        ], dtype=np.float64),\n",
    "    }\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Fonction de convolution\n",
    "    # =========================================================================\n",
    "    \n",
    "    def convoluer(image, noyau):\n",
    "        \"\"\"Applique une convolution avec padding par réflexion.\"\"\"\n",
    "        h, w = image.shape\n",
    "        kh, kw = noyau.shape\n",
    "        pad_h, pad_w = kh // 2, kw // 2\n",
    "        \n",
    "        img_pad = np.pad(image.astype(np.float64), \n",
    "                         ((pad_h, pad_h), (pad_w, pad_w)), \n",
    "                         mode='reflect')\n",
    "        resultat = np.zeros((h, w), dtype=np.float64)\n",
    "        \n",
    "        for i in range(h):\n",
    "            for j in range(w):\n",
    "                resultat[i, j] = np.sum(img_pad[i:i+kh, j:j+kw] * noyau)\n",
    "        \n",
    "        return resultat\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Application de tous les noyaux\n",
    "    # =========================================================================\n",
    "    \n",
    "    resultats = {}\n",
    "    for nom, noyau in noyaux.items():\n",
    "        resultats[nom] = convoluer(img, noyau)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Figure 1 : Filtres de LISSAGE\n",
    "    # =========================================================================\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    \n",
    "    filtres_lissage = ['Identité', 'Moyenneur\\n(box blur)', 'Gaussien\\n3×3', 'Gaussien\\n5×5']\n",
    "    \n",
    "    # Ligne 1 : Images\n",
    "    for idx, nom in enumerate(filtres_lissage):\n",
    "        ax = axes[0, idx]\n",
    "        res = resultats[nom]\n",
    "        ax.imshow(np.clip(res, 0, 255), cmap='gray', vmin=0, vmax=255)\n",
    "        ax.set_title(nom, fontsize=11, fontweight='bold')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Ligne 2 : Noyaux\n",
    "    for idx, nom in enumerate(filtres_lissage):\n",
    "        ax = axes[1, idx]\n",
    "        noyau = noyaux[nom]\n",
    "        kh, kw = noyau.shape\n",
    "        \n",
    "        ax.imshow(noyau, cmap='Blues', vmin=0, vmax=noyau.max())\n",
    "        for i in range(kh):\n",
    "            for j in range(kw):\n",
    "                val = noyau[i, j]\n",
    "                if val != 0:\n",
    "                    txt = f'{val:.2f}' if val < 1 else f'{val:.0f}'\n",
    "                    ax.text(j, i, txt, ha='center', va='center', fontsize=8)\n",
    "        ax.set_title(f'Σ = {noyau.sum():.2f}', fontsize=10)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    plt.suptitle('FILTRES DE LISSAGE (réduction du bruit, flou)', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Figure 2 : Filtres de CONTOURS (gradient)\n",
    "    # =========================================================================\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    \n",
    "    filtres_contours = ['Sobel X\\n(contours V)', 'Sobel Y\\n(contours H)', \n",
    "                        'Prewitt X', 'Prewitt Y']\n",
    "    \n",
    "    # Ligne 1 : Images\n",
    "    for idx, nom in enumerate(filtres_contours):\n",
    "        ax = axes[0, idx]\n",
    "        res = resultats[nom]\n",
    "        vmax = max(abs(res.min()), abs(res.max()))\n",
    "        ax.imshow(res, cmap='RdBu_r', vmin=-vmax, vmax=vmax)\n",
    "        ax.set_title(nom, fontsize=11, fontweight='bold')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Ligne 2 : Noyaux\n",
    "    for idx, nom in enumerate(filtres_contours):\n",
    "        ax = axes[1, idx]\n",
    "        noyau = noyaux[nom]\n",
    "        kh, kw = noyau.shape\n",
    "        \n",
    "        ax.imshow(noyau, cmap='RdBu_r', vmin=-2, vmax=2)\n",
    "        for i in range(kh):\n",
    "            for j in range(kw):\n",
    "                val = noyau[i, j]\n",
    "                color = 'white' if abs(val) > 1 else 'black'\n",
    "                ax.text(j, i, f'{int(val):+d}', ha='center', va='center', \n",
    "                       fontsize=12, fontweight='bold', color=color)\n",
    "        ax.set_title(f'Σ = {noyau.sum():.0f}', fontsize=10)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    plt.suptitle('FILTRES DE GRADIENT (détection de contours directionnels)', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Figure 3 : Filtres LAPLACIEN (contours toutes directions)\n",
    "    # =========================================================================\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    \n",
    "    filtres_laplacien = ['Laplacien\\n(4-connexe)', 'Laplacien\\n(8-connexe)', \n",
    "                         'Roberts X\\n(diagonal)', 'Roberts Y\\n(diagonal)']\n",
    "    \n",
    "    # Ligne 1 : Images\n",
    "    for idx, nom in enumerate(filtres_laplacien):\n",
    "        ax = axes[0, idx]\n",
    "        res = resultats[nom]\n",
    "        vmax = max(abs(res.min()), abs(res.max()))\n",
    "        ax.imshow(res, cmap='RdBu_r', vmin=-vmax, vmax=vmax)\n",
    "        ax.set_title(nom, fontsize=11, fontweight='bold')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Ligne 2 : Noyaux\n",
    "    for idx, nom in enumerate(filtres_laplacien):\n",
    "        ax = axes[1, idx]\n",
    "        noyau = noyaux[nom]\n",
    "        kh, kw = noyau.shape\n",
    "        \n",
    "        vmax_k = max(abs(noyau.min()), abs(noyau.max()))\n",
    "        ax.imshow(noyau, cmap='RdBu_r', vmin=-vmax_k, vmax=vmax_k)\n",
    "        for i in range(kh):\n",
    "            for j in range(kw):\n",
    "                val = noyau[i, j]\n",
    "                color = 'white' if abs(val) > vmax_k * 0.5 else 'black'\n",
    "                ax.text(j, i, f'{int(val):+d}', ha='center', va='center', \n",
    "                       fontsize=12, fontweight='bold', color=color)\n",
    "        ax.set_title(f'Σ = {noyau.sum():.0f}', fontsize=10)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    plt.suptitle('FILTRES LAPLACIEN et ROBERTS (contours multi-directionnels)', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Figure 4 : Filtres de NETTETÉ et RELIEF\n",
    "    # =========================================================================\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    \n",
    "    filtres_nettete = ['Sharpen\\n(netteté)', 'Sharpen\\n(fort)', \n",
    "                       'Emboss\\n(relief)', 'Emboss\\n(haut)']\n",
    "    \n",
    "    # Ligne 1 : Images\n",
    "    for idx, nom in enumerate(filtres_nettete):\n",
    "        ax = axes[0, idx]\n",
    "        res = resultats[nom]\n",
    "        # Pour emboss, centrer autour de 128\n",
    "        if 'Emboss' in nom:\n",
    "            res_affich = res + 128\n",
    "        else:\n",
    "            res_affich = res\n",
    "        ax.imshow(np.clip(res_affich, 0, 255), cmap='gray', vmin=0, vmax=255)\n",
    "        ax.set_title(nom, fontsize=11, fontweight='bold')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Ligne 2 : Noyaux\n",
    "    for idx, nom in enumerate(filtres_nettete):\n",
    "        ax = axes[1, idx]\n",
    "        noyau = noyaux[nom]\n",
    "        kh, kw = noyau.shape\n",
    "        \n",
    "        vmax_k = max(abs(noyau.min()), abs(noyau.max()))\n",
    "        ax.imshow(noyau, cmap='RdBu_r', vmin=-vmax_k, vmax=vmax_k)\n",
    "        for i in range(kh):\n",
    "            for j in range(kw):\n",
    "                val = noyau[i, j]\n",
    "                color = 'white' if abs(val) > vmax_k * 0.5 else 'black'\n",
    "                ax.text(j, i, f'{int(val):+d}', ha='center', va='center', \n",
    "                       fontsize=12, fontweight='bold', color=color)\n",
    "        ax.set_title(f'Σ = {noyau.sum():.0f}', fontsize=10)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    plt.suptitle('FILTRES DE NETTETÉ et RELIEF (accentuation des détails)', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Figure 5 : Comparaison Sobel vs Magnitude\n",
    "    # =========================================================================\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "    \n",
    "    Gx = resultats['Sobel X\\n(contours V)']\n",
    "    Gy = resultats['Sobel Y\\n(contours H)']\n",
    "    magnitude = np.sqrt(Gx**2 + Gy**2)\n",
    "    \n",
    "    axes[0].imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "    axes[0].set_title('Image originale', fontweight='bold')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(np.abs(Gx), cmap='hot')\n",
    "    axes[1].set_title('|Gx| (contours verticaux)', fontweight='bold')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    axes[2].imshow(np.abs(Gy), cmap='hot')\n",
    "    axes[2].set_title('|Gy| (contours horizontaux)', fontweight='bold')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    axes[3].imshow(magnitude, cmap='hot')\n",
    "    axes[3].set_title('Magnitude √(Gx² + Gy²)\\n(tous les contours)', fontweight='bold')\n",
    "    axes[3].axis('off')\n",
    "    \n",
    "    plt.suptitle('COMBINAISON DES GRADIENTS SOBEL', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "  \n",
    "demo_tous_les_noyaux()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Récapitulatif filtres de convolution\n",
    "\n",
    "| CATÉGORIE          | SOMME    | EFFET                                  |\n",
    "|--------------------|----------|----------------------------------------|\n",
    "|                    |  LISSAGE |                                        |\n",
    "|   Moyenneur        |    1     | Flou simple, réduit le bruit           |\n",
    "|   Gaussien         |    1     | Flou naturel, préserve les structures  |\n",
    "|                    | GRADIENT |                                        |\n",
    "|   Sobel            |    0     | Contours directionnels, robuste        |\n",
    "|   Prewitt          |    0     | Contours directionnels, simple         |\n",
    "|   Roberts          |    0     | Contours diagonaux, rapide (2×2)       |\n",
    "|                    |LAPLACIEN |                                        |\n",
    "|   4-connexe        |    0     | Contours toutes directions (dérivée 2) |\n",
    "|   8-connexe        |    0     | Plus sensible, détecte plus de détails |\n",
    "|                    |  NETTETÉ |                                        |\n",
    "|   Sharpen          |    1     | Accentue les contours                  |\n",
    "|   Sharpen fort     |    1     | Accentuation agressive                 |\n",
    "|                    |   RELIEF |                                        |\n",
    "|   Emboss           |   ~1     | Effet 3D, éclairage directionnel       |\n",
    "    \n",
    "RÈGLE IMPORTANTE :\n",
    "* Σ coefficients = 1  →  préserve la luminosité (flou, netteté)\n",
    "* Σ coefficients = 0  →  extrait les variations (contours, gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 : Limites de la simple convolution\n",
    "\n",
    "Malgré leurs avantages, au nombre duquel la grande variété de traitements qu’ils peuvent réaliser, les noyaux de convolution ne sont pas sans limites.\n",
    "\n",
    "Nous avons vu que cette méthode correspondait à un *filtrage local* de l’image : le traitement d’un pixel dépend des valeurs de ses voisins. Par exemple si l’on souhaite créer un filtre qui réduit le bruit d’un document (cas typique : texte scanné, il y a toujours des poussières sur la vitre du scan), ce qui va résulter en des petits points qui vont apparaître blancs ou noirs en fonction de l’éclairage, de la couleur qu’ils retrouvent, etc., pour « gommer » ces points, on va appliquer un flou qui préservera les structures dans l’ensemble (important pour des lettres), par exemple un flou gaussien. C’est comme si on appliquait une éponge mouillée qui va fondre ou égaliser localement des zones (ensemble de pixels) de valeurs différentes par un effet d’estompage.\n",
    "\n",
    "Malgré les qualités du filtre gaussien, cette approche n’en demeure pas moins destructive. Dans le cas de lettres, où chaque détail compte pour les différencier (cf. `n` vs. `m`, `u` vs. `v` vs `w`, ou encore `r` vs. `t`), cela peut être gênant, ou tout au moins toutes les applications où la préservation des détails est intéressantes.\n",
    "\n",
    "Voici ci-dessous une illustration du phénomène. On simule une situation de texte scanné avec du bruit en créant des rectangles plus ou moins fins, une teinte grise du fond (ce qui arrive souvent dans les scans) et l’ajout d’un bruit aléatoire (pixels blancs et noirs). Pour mesurer l’effet des transformations on décompte le nombre de composantes (formes indépendantes : rectangles, pixels/bruit…) : cela permetra de voir l’efficacité du nettoyage.\n",
    "\n",
    "Nous allons comparer 3 méthodes pour éliminer le bruit :\n",
    "\n",
    "- un seuillage simple qui élimine **indifféremment tous** les pixels en dessous d’une certaine valeur\n",
    "- un seuillage + flou gaussier (convolution) qui calcule une **moyenne pondérée** des pixels voisins\n",
    "- un seuillage + filtre morphologique. Nous n’avons pas encore vu cette dernière méthode, c’est l’objet de la section suivante, mais nous la présentons ici en guise d’introduction, ce qui permet déjà de vous donner une mesure de son efficacité. Sachez simplement que cette méthode consiste simplement à comparer chaque composante de l’image avec un motif (forme) spécifique que l’on appelle un **élément structurant**. À l’issu de la comparaison on décide s’il faut éliminer ou conserver la composante en question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def creer_document_test():\n",
    "    \"\"\"\n",
    "    Crée une image simulant un document scanné :\n",
    "    - Fond blanc (240)\n",
    "    - \"Lettres\" = rectangles noirs de tailles variées\n",
    "    - Bruit = points FINS isolés (1 pixel)\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    h, w = 150, 300\n",
    "    \n",
    "    # Fond légèrement gris (comme un scan)\n",
    "    img = np.ones((h, w), dtype=np.uint8) * 240\n",
    "    \n",
    "    # Ligne 1 : grandes lettres\n",
    "    positions_l1 = [(20, 20), (20, 50), (20, 80), (20, 110), (20, 140)]\n",
    "    for (y, x) in positions_l1:\n",
    "        letter_h, letter_w = np.random.randint(28, 38), np.random.randint(12, 20)\n",
    "        img[y:y+letter_h, x:x+letter_w] = np.random.randint(20, 50)\n",
    "    \n",
    "    # Ligne 2 : lettres moyennes\n",
    "    positions_l2 = [(70, 20), (70, 45), (70, 70), (70, 95), (70, 120), (70, 145)]\n",
    "    for (y, x) in positions_l2:\n",
    "        letter_h, letter_w = np.random.randint(20, 28), np.random.randint(10, 16)\n",
    "        img[y:y+letter_h, x:x+letter_w] = np.random.randint(20, 50)\n",
    "    \n",
    "    # Ligne 3 : petites lettres (mais pas trop petites)\n",
    "    positions_l3 = [(110, 20 + i*18) for i in range(8)]\n",
    "    for (y, x) in positions_l3:\n",
    "        letter_h, letter_w = np.random.randint(15, 22), np.random.randint(8, 14)\n",
    "        img[y:y+letter_h, x:x+letter_w] = np.random.randint(20, 50)\n",
    "    \n",
    "    # Zone avec un rectangle plein (comme un logo ou un cadre)\n",
    "    img[20:90, 200:290] = 30\n",
    "    img[30:80, 210:280] = 240  # Trou au milieu\n",
    "    \n",
    "    # BRUIT FIN : points isolés de 1 pixel uniquement\n",
    "    bruit_coords = []\n",
    "    for _ in range(300):\n",
    "        y, x = np.random.randint(0, h), np.random.randint(0, w)\n",
    "        img[y, x] = np.random.randint(0, 60)  # Point noir isolé\n",
    "        bruit_coords.append((y, x))\n",
    "    \n",
    "    # Quelques points blancs (sel) - aussi 1 pixel\n",
    "    for _ in range(100):\n",
    "        y, x = np.random.randint(0, h), np.random.randint(0, w)\n",
    "        img[y, x] = 255\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "def creer_element_structurant_carre(taille):\n",
    "    return np.ones((taille, taille), dtype=np.uint8)\n",
    "\n",
    "\n",
    "def erosion(img_bin, es):\n",
    "    \"\"\"Érosion : pixel blanc si TOUS les voisins sont blancs.\"\"\"\n",
    "    h, w = img_bin.shape\n",
    "    es_h, es_w = es.shape\n",
    "    pad = es_h // 2\n",
    "    \n",
    "    img_bool = (img_bin > 0)\n",
    "    img_pad = np.pad(img_bool, pad, mode='constant', constant_values=False)\n",
    "    resultat = np.zeros((h, w), dtype=bool)\n",
    "    \n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            region = img_pad[i:i+es_h, j:j+es_w]\n",
    "            resultat[i, j] = np.all(region[es == 1])\n",
    "    \n",
    "    return (resultat * 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def dilatation(img_bin, es):\n",
    "    \"\"\"Dilatation : pixel blanc si AU MOINS UN voisin est blanc.\"\"\"\n",
    "    h, w = img_bin.shape\n",
    "    es_h, es_w = es.shape\n",
    "    pad = es_h // 2\n",
    "    \n",
    "    img_bool = (img_bin > 0)\n",
    "    img_pad = np.pad(img_bool, pad, mode='constant', constant_values=False)\n",
    "    resultat = np.zeros((h, w), dtype=bool)\n",
    "    \n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            region = img_pad[i:i+es_h, j:j+es_w]\n",
    "            resultat[i, j] = np.any(region[es == 1])\n",
    "    \n",
    "    return (resultat * 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def ouverture(img_bin, es):\n",
    "    \"\"\"Ouverture = érosion puis dilatation.\"\"\"\n",
    "    return dilatation(erosion(img_bin, es), es)\n",
    "\n",
    "\n",
    "def fermeture(img_bin, es):\n",
    "    \"\"\"Fermeture = dilatation puis érosion.\"\"\"\n",
    "    return erosion(dilatation(img_bin, es), es)\n",
    "\n",
    "\n",
    "def compter_composantes_connexes(img_bin):\n",
    "    \"\"\"\n",
    "    Compte le nombre de composantes connexes (objets) dans une image binaire.\n",
    "    Utilise un algorithme de flood-fill simplifié.\n",
    "    \"\"\"\n",
    "    img = (img_bin > 0).astype(np.int32)\n",
    "    h, w = img.shape\n",
    "    visited = np.zeros_like(img, dtype=bool)\n",
    "    n_composantes = 0\n",
    "    \n",
    "    def flood_fill(start_i, start_j):\n",
    "        stack = [(start_i, start_j)]\n",
    "        while stack:\n",
    "            i, j = stack.pop()\n",
    "            if i < 0 or i >= h or j < 0 or j >= w:\n",
    "                continue\n",
    "            if visited[i, j] or img[i, j] == 0:\n",
    "                continue\n",
    "            visited[i, j] = True\n",
    "            stack.extend([(i+1, j), (i-1, j), (i, j+1), (i, j-1)])\n",
    "    \n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            if img[i, j] > 0 and not visited[i, j]:\n",
    "                flood_fill(i, j)\n",
    "                n_composantes += 1\n",
    "    \n",
    "    return n_composantes\n",
    "\n",
    "\n",
    "def mesurer_qualite(img_bin, nom=\"\"):\n",
    "    \"\"\"\n",
    "    Mesure la qualité d'une image binarisée.\n",
    "    \n",
    "    Métriques :\n",
    "    - Nombre de composantes connexes (beaucoup = bruit résiduel)\n",
    "    - Ratio pixels noirs / total\n",
    "    \"\"\"\n",
    "    n_composantes = compter_composantes_connexes(255 - img_bin)  # Compter les objets noirs\n",
    "    n_pixels_noirs = np.sum(img_bin == 0)\n",
    "    ratio_noir = n_pixels_noirs / img_bin.size * 100\n",
    "    \n",
    "    return {\n",
    "        'nom': nom,\n",
    "        'composantes': n_composantes,\n",
    "        'pixels_noirs': n_pixels_noirs,\n",
    "        'ratio_noir': ratio_noir\n",
    "    }\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MÉTHODES DE NETTOYAGE\n",
    "# =============================================================================\n",
    "\n",
    "def nettoyer_par_convolution(img, taille_noyau=5):\n",
    "    \"\"\"Nettoyage par flou gaussien + seuillage.\"\"\"\n",
    "    \n",
    "    def noyau_gaussien(taille, sigma=1.0):\n",
    "        ax = np.arange(taille) - taille // 2\n",
    "        xx, yy = np.meshgrid(ax, ax)\n",
    "        kernel = np.exp(-(xx**2 + yy**2) / (2 * sigma**2))\n",
    "        return kernel / kernel.sum()\n",
    "    \n",
    "    def convoluer(img, noyau):\n",
    "        h, w = img.shape\n",
    "        kh, kw = noyau.shape\n",
    "        pad = kh // 2\n",
    "        img_pad = np.pad(img.astype(float), pad, mode='reflect')\n",
    "        resultat = np.zeros_like(img, dtype=float)\n",
    "        for i in range(h):\n",
    "            for j in range(w):\n",
    "                resultat[i, j] = np.sum(img_pad[i:i+kh, j:j+kw] * noyau)\n",
    "        return resultat\n",
    "    \n",
    "    noyau = noyau_gaussien(taille_noyau, sigma=taille_noyau/3)\n",
    "    img_floue = convoluer(img, noyau)\n",
    "    \n",
    "    seuil = 128\n",
    "    img_bin = np.where(img_floue < seuil, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    return img_floue.astype(np.uint8), img_bin\n",
    "\n",
    "\n",
    "def nettoyer_par_morphologie(img, taille_es=3):\n",
    "    \"\"\"Nettoyage par seuillage + ouverture + fermeture.\"\"\"\n",
    "    \n",
    "    seuil = 128\n",
    "    img_bin = np.where(img < seuil, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    # Travailler sur l'image inversée (texte blanc sur fond noir)\n",
    "    img_inv = 255 - img_bin\n",
    "    \n",
    "    es = creer_element_structurant_carre(taille_es)\n",
    "    \n",
    "    # Ouverture : supprime les petits points blancs (bruit)\n",
    "    img_ouv = ouverture(img_inv, es)\n",
    "    \n",
    "    # Fermeture : reconnecte les petites cassures\n",
    "    img_ferm = fermeture(img_ouv, es)\n",
    "    \n",
    "    # Ré-inverser\n",
    "    img_finale = 255 - img_ferm\n",
    "    \n",
    "    return img_bin, img_finale\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# EXÉCUTION ET COMPARAISON\n",
    "# =============================================================================\n",
    "\n",
    "img_originale = creer_document_test()\n",
    "\n",
    "# Méthode 1 : Convolution\n",
    "img_floue, img_conv = nettoyer_par_convolution(img_originale, taille_noyau=5)\n",
    "\n",
    "# Méthode 2 : Morphologie\n",
    "img_seuil, img_morpho = nettoyer_par_morphologie(img_originale, taille_es=3)\n",
    "\n",
    "# =============================================================================\n",
    "# MESURES OBJECTIVES\n",
    "# =============================================================================\n",
    "\n",
    "stats_seuil = mesurer_qualite(img_seuil, \"Seuillage seul\")\n",
    "stats_conv = mesurer_qualite(img_conv, \"Convolution\")\n",
    "stats_morpho = mesurer_qualite(img_morpho, \"Morphologie\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"MESURE OBJECTIVE : NOMBRE DE COMPOSANTES CONNEXES\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\"\"\n",
    "Un document propre devrait avoir peu de composantes connexes (une par lettre/forme).\n",
    "Le bruit ajoute de nombreuses petites composantes parasites.\n",
    "\"\"\")\n",
    "print(f\"{'Méthode':<20} {'Composantes':<15} {'Interprétation'}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Seuillage seul':<20} {stats_seuil['composantes']:<15} ← Beaucoup de bruit résiduel\")\n",
    "print(f\"{'Convolution + seuil':<20} {stats_conv['composantes']:<15} ← Bruit atténué mais texte dégradé\")\n",
    "print(f\"{'Morphologie':<20} {stats_morpho['composantes']:<15} ← Bruit supprimé, texte préservé ✓\")\n",
    "print()\n",
    "\n",
    "# =============================================================================\n",
    "# VISUALISATION\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "# Ligne 1 : Vue globale\n",
    "axes[0, 0].imshow(img_originale, cmap='gray', vmin=0, vmax=255)\n",
    "axes[0, 0].set_title('Original\\n(avec bruit fin)', fontweight='bold')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(img_seuil, cmap='gray', vmin=0, vmax=255)\n",
    "axes[0, 1].set_title(f'Seuillage seul\\n({stats_seuil[\"composantes\"]} composantes)', fontweight='bold')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[0, 2].imshow(img_conv, cmap='gray', vmin=0, vmax=255)\n",
    "axes[0, 2].set_title(f'Convolution\\n({stats_conv[\"composantes\"]} composantes)', fontweight='bold')\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "axes[0, 3].imshow(img_morpho, cmap='gray', vmin=0, vmax=255)\n",
    "axes[0, 3].set_title(f'Morphologie\\n({stats_morpho[\"composantes\"]} composantes)', fontweight='bold', color='green')\n",
    "axes[0, 3].axis('off')\n",
    "\n",
    "# Ligne 2 : Zoom sur les petites lettres\n",
    "y1, y2, x1, x2 = 100, 140, 15, 120\n",
    "\n",
    "axes[1, 0].imshow(img_originale[y1:y2, x1:x2], cmap='gray', vmin=0, vmax=255)\n",
    "axes[1, 0].set_title('Zoom original', fontweight='bold')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(img_seuil[y1:y2, x1:x2], cmap='gray', vmin=0, vmax=255)\n",
    "axes[1, 1].set_title('Zoom seuillage\\n⚠️ Bruit visible', fontweight='bold', color='red')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "axes[1, 2].imshow(img_conv[y1:y2, x1:x2], cmap='gray', vmin=0, vmax=255)\n",
    "axes[1, 2].set_title('Zoom convolution\\n⚠️ Lettres floues', fontweight='bold', color='orange')\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "axes[1, 3].imshow(img_morpho[y1:y2, x1:x2], cmap='gray', vmin=0, vmax=255)\n",
    "axes[1, 3].set_title('Zoom morphologie\\n✓ Propre et net', fontweight='bold', color='green')\n",
    "axes[1, 3].axis('off')\n",
    "\n",
    "plt.suptitle('CONVOLUTION vs MORPHOLOGIE : Nettoyage de document', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "On constate :\n",
    "\n",
    "- le seuillage simple : il n’a aucun effet sur le bruit qui entre dans l’intervalle de valeurs tolérées\n",
    "\n",
    "- Le flou gaussien :\n",
    "    - ici le bruit est supprimé\n",
    "    - ne pas perdre de vue que parfois le bruit – notamment s’il possède des composantes de grandes tailles – est simpleemnt atténué\n",
    "    - limite : les contours fins sont aussi atténués ! (les formes sont rognées)\n",
    "\n",
    "- l’approche  morphologique :\n",
    "    - ici le bruit est supprimé\n",
    "    - les composantes d’intérêt (qui simulent des lettres) sont parfaitement conservées (intactes)\n",
    "    - attention si le bruit contient des composantes de taille suffisantes, elles vont être conservées telles quelles car identifiées comme des composantes à conserver\n",
    "\n",
    "Si un filtre flou par convolution revient à tout estomper comme si on passer une éponge pour « nettoyer » le bruit, l’approce morphologique correspond plus à passer les composantes dans une sorte de tamis ou crible : les composantes seront triées selon leur taille et les plus petites éliminées.\n",
    "\n",
    "Passons à une présentation plus détaillée de la morphologie mathématique, discipline sur laquelle se fonde la méthode des filtres morphologiques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Morphologie Mathématique\n",
    "\n",
    "### 5.1 Introduction\n",
    "\n",
    "On peut distinguer deux manières de traiter les images : soit par une approche de **traitement du signal**, soit par une approche **ensembliste**. C’est à dire qu’on va construire des ensembles particuliers pour analyser ou traiter une image, et on va regarder si un pixel appartient ou pas à un ensemble donné.\n",
    "\n",
    "L’approche morphologique appartient à la seconde famille, l’approche ensembliste. Il s’agit d’un traitement non-linéaire de l’information développée par **Georges Matheron** et **Jean Serra** (années 50/60 pour les bases de la théorie).\n",
    "* elle offre un cadre mathématiquement accessible et très élégant au traitement de l’image sans apprentissage\n",
    "* 1956 : application aux images binaires (améliorer la segmentation)\n",
    "* 1978 : application aux images en niveaux de gris (segmentation + filtrage/suppression du bruit, détection de contour, amélioration du contraste, etc.). Pour traiter une image en couleur, il suffit d’appliquer séparément ces opérations sur chaque canal.\n",
    "\n",
    "Aujourd’hui, quand on parle traitement d’image, le *deep learning* règne en maître. Ça n’interdit pas de s’intéresser à une méthode élégante qui a brillé pendant 40 ans, efficace sans demander d’énormes ressources (sobriété), et qui enrichit dans tous les cas notre boîte à outil. D’autant que les filtres morphologiques sont toujours pertinents pour prétraiter des images qui peuvent ensuite être traitées plus efficacement par des réseaux de neurone (ou vice-versa). On développe également des réseaux de neurones avec des couches morphologiques.\n",
    "\n",
    "Des bibliothèques de traitgement d’image comme OpenCV ou Scikit-Image contiennent des méthodes implémentant des opérations de morphologie. Il s’agit donc d’une méthode à connaître lorsque l’on souhaite utiliser ces bibliothèques.\n",
    "\n",
    "#### 5.1.1 Un peu d’algèbre, encore (mais pas beaucoup !)\n",
    "\n",
    "Quel rapport avec l’algèbre ????\n",
    "Hé bien… revenons à la convolution…\n",
    "\n",
    "* L’opérateur réalisant la convolution par un noyau (kernel) est en fait un opérateur linéaire (par rapport à la translation, cf. [Blusseau & Puybareau, 2023](https://hal.science/hal-04148876/file/ejcim_2023_chap3.pdf))\n",
    "\n",
    "Revenons aux concepts (il s’agit juste de quelques pistes intuitives, cf. la référence précédente pour une approche rigoureuse) : \n",
    "\n",
    "* En algèbre linéaire on a construit toute la théorie sur les espaces vectoriels en s’appuyant sur les opérations « somme » et « produit ». En morphologie on peut tout à fait remplacer la somme par les opération supremum ($>$) ou infimum ($<$) et l’opération $·$ par $+$. Les structures considérées ne seront plus des espaces vectoriels, mais des « treillis complets ».\n",
    "\n",
    "* En algèbre linéaire, nous avons vu que les combinaisons linéaires (= somme de produits) étaient des opérations qui jouent un rôle central. Par ailleurs, dans le cas du filtrage, l’application d’un noyau de convolution à une image consiste à calculer une combinaison linéaire pour chaque pixel. On va créer des opérations qui vont jouer un rôle tout aussi central dans le cadre de la morphologie mathématique, cette fois avec supremum, infinum et $+$. Ces opération seront respectivement la dilation (δ) et l’érosion (ε). Elle seront calculées pour chaque pixel d’une image en déplaçant de la même manière que pour la convolution un masque sur l’image, en regardant cette fois pour chaque pixel si le masque positionné sur ce pixel recouvre pour partie d’autre pixels d’une forme (dilatation) ou du fond (érosion). Si tel est le cas on modifiera la valeur du pixel sur lequel le masque est positionné en la valeur maximale (dilatation) ou minimale (érosion) des pixels appartenant au masque.\n",
    "\n",
    "Pas de panique, comme d’habitude c’est une opération plus difficile à décrire qu’à réaliser, un schéma explicatif ci-dessous devrait vous éclairer. Pour le moment, retenez surtout ce résumé :\n",
    "\n",
    "* Algèbre linéaire -> espace vectoriels, opérations (+, ·) -> combinaisons linéaires \n",
    "\n",
    "* Morphologie -> treillis complets, opérations (infinum, supremum, +) -> dilation ou érosion\n",
    "\n",
    "Dans le cas des filtres morphologiques, la forme du masque va avoir une importance capitale, on va appeler ces formes des **éléments structurants** (ES). \n",
    "\n",
    "Pour l’illustration de ces concepts, on va par soucis de simplicité se positionner dans le cas d’images binaires (un pixel est blanc ou noir), nous indiquerons via des notes les adaptations qu’implique le traitement d’images en niveau de gris.\n",
    "\n",
    "Comme d’habitude encore, on donnera d’abord une définition intuitive, puis une définition plus formelle.\n",
    "\n",
    "##### Éléments structurants, érosion et dilation\n",
    "\n",
    "###### Définition intuitive/pratique\n",
    "\n",
    "On peut se représenter un élément structurant (ES) comme un masque ayant une petite forme géométrique (carré, disque, croix...) que l'on déplace sur l'image pour « sonder » les structures (formes) présentes sur l’image. L’élément structurant est définit par trois caractéristique :\n",
    "- sa taille\n",
    "- sa forme\n",
    "- son origine (que l’on place en général au centre)\n",
    "\n",
    "La taille de l’ES détermine l'échelle des détails affectés : dans le cas de l’érosion par exemple tout objet plus petit que l'élément structurant pourra être supprimé, tandis que les objets plus grands (qui peuvent contenir l’ES) seront préservés.\n",
    "\n",
    "Les ES les plus courants sont :\n",
    "\n",
    "![Exemples d’élements structurants](images/ElementsStructurants.png)\n",
    "\n",
    "Comment on procède : on déplace l’ES sur l’image, et on va modifier ou non le pixel situé à l’origine de l’ES (on place la plupart du temps l’origine au centre mais on pourrait en décider autrement pour certaines applications) en fonction de ce que l’ES recouvre sur l’image :\n",
    "\n",
    "![Exemple recouvrement ES - Formes](images/ES-Formes.png)\n",
    "\n",
    "Opérations :\n",
    "  \n",
    "- **Dilatation :**\n",
    "\n",
    "![schéma érosion](images/Dilatation.png)\n",
    "\n",
    "- **Erosion :**\n",
    "\n",
    "![schéma érosion](images/Erosion.png)\n",
    "\n",
    "Il s’agit des deux opération de base qui nous  permettrons de définir d’autres opérations (ouverture, fermeture, gradient interne, externe, morphologique, etc.) que nous implémenterons dans la suite. \n",
    "\n",
    "###### Définition formelle\n",
    "\n",
    "Un élément structurant $B$ est un ensemble de points (un sous-ensemble de $\\mathbb{Z}^2$ pour une image discrète) défini par rapport à une origine, généralement son centre. Formellement :\n",
    "\n",
    "$$\n",
    "B = \\{b_1, b_2, \\ldots, b_n\\} \\subset \\mathbb{Z}^2\n",
    "$$\n",
    "où chaque $b_i = (x_i, y_i)$ représente un décalage relatif par rapport à l'origine.\n",
    "\n",
    "Lorsqu'on positionne l'élément structurant en un point $p = (x, y)$ de l'image, on obtient le translaté de $B$ en $p$ :\n",
    "\n",
    "$$\n",
    "B_p = \\{p + b \\mid b \\in B\\} = \\{(x + x_i, y + y_i) \\mid (x_i, y_i) \\in B\\}\n",
    "$$\n",
    "\n",
    "Les opérations morphologiques sont alors définies comme des relations ensemblistes entre ce translaté $B_p$ et l'ensemble $X$ des pixels de l'objet dans l'image :\n",
    "\n",
    "* Érosion : $\\varepsilon_B(X) = \\{p \\mid B_p \\subseteq X\\}$ (tous les points où $B$ est entièrement inclus dans $X$)\n",
    "* Dilatation : $\\delta_B(X) = \\{p \\mid B_p \\cap X \\neq \\emptyset\\}$ (tous les points où $B$ touche $X$)\n",
    "\n",
    "Nous allons manipuler des formes constituées de points (pixels) positionnées sur un réseau discret, et déterminer si une forme est à l’intérieur ou non d’une autre forme donnée. C’est l’objet de la [géométrie des nombres](https://fr.wikipedia.org/wiki/G%C3%A9om%C3%A9trie_des_nombres), fondée par [Hermann Minkowski](https://fr.wikipedia.org/wiki/Hermann_Minkowski) - accessoirement aussi celui qui a théorisé le continuum espace/temps. Nous allons d’ailleurs utiliser les opérations de Minkowski pour représenter les opérations auxquelles nous allons procéder :\n",
    "\n",
    "* **Soustraction de Minkowski ⊖**\n",
    "L'opération $A \\ominus B$ est l'ensemble des points $p$ tels que le translaté de (la forme) $B$ en $p$ soit entièrement contenu dans (la forme) $A$ :\n",
    "\n",
    "$$\n",
    "A \\ominus B = \\{p \\mid B_p \\subseteq A\\}\n",
    "$$\n",
    "L'érosion de $A$ par $B$ correspond exactement à cette opération : $\\varepsilon_B(A) = A \\ominus B$, ce qui revient à ne conserver que les pixels où l'élément structurant \"rentre\" entièrement dans l'objet.\n",
    "\n",
    "* **Addition de Minkowski**\n",
    "L'opération $A \\oplus B$ est l'ensemble des points $p$ tels que le translaté de $B$ en $p$ ait une intersection non vide avec $A$ :\n",
    "\n",
    "$$\n",
    "A \\oplus B = \\{p \\mid B_p \\cap A \\neq \\emptyset\\}\n",
    "$$\n",
    "La dilatation de $A$ par $B$ correspond exactement à cette opération : $\\delta_B(A) = A \\oplus B$, ce qui revient à marquer comme \"objet\" tout pixel où l'élément structurant \"touche\" au moins un pixel de l'objet original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Maintenant un peu de code : éléments structurants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le bout de code ci-dessous montre comment créer certains ES de manière procédurale :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creer_element_structurant(forme, taille):\n",
    "    \"\"\"Crée un élément structurant.\"\"\"\n",
    "    if taille % 2 == 0: taille += 1\n",
    "    centre = taille // 2\n",
    "    \n",
    "    if forme == 'carre':\n",
    "        return np.ones((taille, taille), dtype=np.uint8)\n",
    "    elif forme == 'croix':\n",
    "        es = np.zeros((taille, taille), dtype=np.uint8)\n",
    "        es[centre, :] = 1\n",
    "        es[:, centre] = 1\n",
    "        return es\n",
    "    elif forme == 'disque':\n",
    "        y, x = np.ogrid[:taille, :taille]\n",
    "        return ((x - centre)**2 + (y - centre)**2 <= centre**2).astype(np.uint8)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "for ax, forme in zip(axes, ['carre', 'croix', 'disque']):\n",
    "    es = creer_element_structurant(forme, 7)\n",
    "    ax.imshow(es, cmap='gray', vmin=0, vmax=1)\n",
    "    ax.set_title(f'{forme.capitalize()} 7x7')\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Érosion\n",
    "\n",
    "$A \\ominus B$ : Un pixel vaut 1 *seulement si* **TOUS** les pixels sous l'ES valent 1 = un pixel vaut 0 si **au moins** un pixel vaut 0.\n",
    "\n",
    "**Effets** : Amincit les objets, supprime le bruit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erosion(img_binaire, element_structurant):\n",
    "    \"\"\"Érosion morphologique.\"\"\"\n",
    "    h, w = img_binaire.shape\n",
    "    es_h, es_w = element_structurant.shape\n",
    "    pad_h, pad_w = es_h // 2, es_w // 2\n",
    "    \n",
    "    img_bin = (img_binaire > 0).astype(np.uint8)\n",
    "    img_padded = np.pad(img_bin, ((pad_h, pad_h), (pad_w, pad_w)), mode='constant', constant_values=0)\n",
    "    resultat = np.zeros((h, w), dtype=np.uint8)\n",
    "    \n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            region = img_padded[i:i+es_h, j:j+es_w]\n",
    "            if np.all(region[element_structurant == 1] == 1):\n",
    "                resultat[i, j] = 1\n",
    "    return (resultat * 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons appliquer cette transformation à des formes ci-dessous, mais pour comparer avec la dilation implémentons d’abord cette dernière :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Dilatation\n",
    "\n",
    "$A \\oplus B$ : Un pixel vaut 1 si **AU MOINS UN** pixel sous l'ES vaut 1.\n",
    "\n",
    "**Effets** : Épaissit les objets, remplit les trous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilatation(img_binaire, element_structurant):\n",
    "    \"\"\"Dilatation morphologique.\"\"\"\n",
    "    h, w = img_binaire.shape\n",
    "    es_h, es_w = element_structurant.shape\n",
    "    pad_h, pad_w = es_h // 2, es_w // 2\n",
    "    \n",
    "    img_bin = (img_binaire > 0).astype(np.uint8)\n",
    "    img_padded = np.pad(img_bin, ((pad_h, pad_h), (pad_w, pad_w)), mode='constant', constant_values=0)\n",
    "    resultat = np.zeros((h, w), dtype=np.uint8)\n",
    "    \n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            region = img_padded[i:i+es_h, j:j+es_w]\n",
    "            if np.any(region[element_structurant == 1] == 1):\n",
    "                resultat[i, j] = 1\n",
    "    return (resultat * 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que nous avons deux fonctions qui implémentent ces deux opérations de base de la morphologie, testons les sur une image test contenant des formes (dont du bruit) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image test\n",
    "def creer_image_test_morpho():\n",
    "    img = np.zeros((150, 200), dtype=np.uint8)\n",
    "    # Grand rectangle\n",
    "    img[20:60, 20:80] = 255\n",
    "    # Cercle\n",
    "    y, x = np.ogrid[:150, :200]\n",
    "    img[(x - 140)**2 + (y - 40)**2 <= 625] = 255\n",
    "    # Deux petits carrés avec trous au centre\n",
    "    img[80:100, 30:50] = 255\n",
    "    img[87:93, 37:43] = 0  # Trou dans le premier carré\n",
    "    img[80:100, 55:75] = 255\n",
    "    img[88:92, 63:67] = 0  # Trou dans le second carré\n",
    "    # Grand carré avec trou\n",
    "    img[80:130, 110:160] = 255\n",
    "    img[95:115, 125:145] = 0\n",
    "    # Bruit\n",
    "    for _ in range(30):\n",
    "        by, bx = np.random.randint(0, 150), np.random.randint(0, 200)\n",
    "        if img[by, bx] == 0:\n",
    "            img[max(0,by-1):by+2, max(0,bx-1):bx+2] = 255\n",
    "    return img\n",
    "\n",
    "img_test = creer_image_test_morpho()\n",
    "es3 = creer_element_structurant('carre', 5)\n",
    "\n",
    "img_erodee = erosion(img_test, es3)\n",
    "img_dilatee = dilatation(img_test, es3)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "axes[0].imshow(img_test, cmap='gray'); axes[0].set_title('Original'); axes[0].axis('off')\n",
    "axes[1].imshow(img_erodee, cmap='gray'); axes[1].set_title('Érosion'); axes[1].axis('off')\n",
    "axes[2].imshow(img_dilatee, cmap='gray'); axes[2].set_title('Dilatation'); axes[2].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces transformations sont intéressantes, mais si elles suppriment le bruit (dans le cadre de l’érosion) ou l’amplifie (dilatation), elles modifient également les formes qui nous intéressent, ce qui était une limitation des filtres de convolution. Nous allons voir qu’en combinant adroitement ces deux opérations pour créer de nouvelles opérations (ouverture, fermeture, etc.), on peut réaliser des transformations plus précises et ciblées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Combinaisons d’opérations morphologique\n",
    "\n",
    "Nous allons dans cette section passer en revue différentes manières de combiner les opérations morphologiques élémentaires que sont l’érosion et la dilation, et voir quelles peuvent être leurs applications (effets).\n",
    "\n",
    "#### 5.5.1 Ouverture et fermeture\n",
    "\n",
    "##### Ouverture\n",
    "\n",
    "Si l’érosion supprime le bruit en éliminant toutes les composantes (formes) plus petites que l’ES, mais qu’elle érode de la même manière les formes plus grandes, on peut résoudre le problème en faisant plusieurs passes avec des opérations qui s’annulent :\n",
    "\n",
    "- 1. On applique une érosion pour supprimer le bruit\n",
    "  2. On applique ensuite une dilatation pour contrebalancer l’érosion des formes qui seront toujours présentent sur l’image (trop grandes pour avoir été éliminées). Vu que les plus petits éléments auront déjà été supprimés par l’érosion, la dilation ne risque pas d’amplifier le bruit.\n",
    "\n",
    "Cela marche surtout pour le bruit sur le fond.\n",
    "\n",
    "On appelle cette combinaison une ouverture :\n",
    "**Ouverture** : $(A \\ominus B) \\oplus B$ → Supprime le bruit\n",
    "\n",
    "##### Fermeture\n",
    "\n",
    "On peut se demander ce qu’il se passe si on fait l’opération inverse : une dilatation suivie d’une érosion. Pour ce qui est du bruit, celui-ci sera amplifié par la dilatation, et il reviendra à sa valeur de départ si on applique ensuite une érosion : l’effet sera nul. Par contre, si on prend garde au fait que l’érosion ne va s’appliquer que là où le fond apparaît à proximité, si une dilation « bouche un trou » (comme sur un des petits carrés dans notre exemple), dans ce cas une érosion subséquente ne pourra pas le faire réapparaître. Cette opération va donc être appelée une fermeture, car elle va refermer les petits vides ou creux dans les formes. C’est un moyen par exemple de gérer la composante du bruit qui recouvre les formes (et non le fond).\n",
    "\n",
    "On constate par la même occasion que l’ordre dans lequel on applique érosion et dilatation a son importance : pas de commutativité.\n",
    "\n",
    "**Fermeture** : $(A \\oplus B) \\ominus B$ → Remplit les trous\n",
    "\n",
    "##### Exercice  \n",
    "Voyons ce que cela donne sur notre exemple : créez une fonction ouverture et une fonction fermeture à partir des fonctions `dilation()` et `erosion()` déjà créées.\n",
    "\n",
    "Testez ensuite plussieurs ES différents (fomres, tailles…)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ouverture(img, es):\n",
    "    return dilatation(erosion(img, es), es)\n",
    "\n",
    "def fermeture(img, es):\n",
    "    return erosion(dilatation(img, es), es)\n",
    "\n",
    "es_test = creer_element_structurant('carre', 5)\n",
    "\n",
    "img_ouv = ouverture(img_test, es_test)\n",
    "img_ferm = fermeture(img_test, es_test)\n",
    "img_nettoye = fermeture(ouverture(img_test, es3), es3)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes[0,0].imshow(img_test, cmap='gray'); axes[0,0].set_title('Original'); axes[0,0].axis('off')\n",
    "axes[0,1].imshow(img_ouv, cmap='gray'); axes[0,1].set_title('Ouverture'); axes[0,1].axis('off')\n",
    "axes[1,0].imshow(img_ferm, cmap='gray'); axes[1,0].set_title('Fermeture'); axes[1,0].axis('off')\n",
    "axes[1,1].imshow(img_nettoye, cmap='gray'); axes[1,1].set_title('Ouverture + Fermeture'); axes[1,1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.2 Gradient morphologique\n",
    "\n",
    "Pour résumer grossièreemnt, une dilatation dilates les contours, et une érosion les érode. On peut donc isoler ces contours en combinant ces deux opérations en faisant leur différence : Si on procède à une dilatation, on obtient une image avec les contours contours épaissis. Si l’on procède à une érosion, on obtient une image avec les contours réduits. Si on soustrait cette seconde image à la première, ce qui va rester c’est la différence entre les deux images, donc la zone où les contours ont été dilatés/érodés : on aura extrait les contours.\n",
    "\n",
    "**Gradient** = Image dilatée - Image érodée → extraction de contour\n",
    "\n",
    "##### Exercice\n",
    "\n",
    "Réalisez une extraction de contour à l’aide d’un gradient morphologique.\n",
    "Pour normaliser l’image résultante, vous pouvez utiliserla méthode `np.clip()` (cherchez dans la doc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_morphologique(img, es):\n",
    "    return np.clip(dilatation(img, es).astype(int) - erosion(img, es).astype(int), 0, 255).astype(np.uint8)\n",
    "\n",
    "grad = gradient_morphologique(img_test, es3)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes[0].imshow(img_test, cmap='gray'); axes[0].set_title('Original'); axes[0].axis('off')\n",
    "axes[1].imshow(grad, cmap='gray'); axes[1].set_title('Gradient morphologique'); axes[1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.3 Top-Hat et Black-Hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Top-hat\n",
    "Creusant la piste selon laquelle on peut créer des opéarations morphologiques en soustrayans des images entre elles, si réaliser une ouverture supprime le bruit (en fait les petits détails clairs sur le fond), si on fait la différence entre une image non-transformée et la même image après ouverture, on devrait sélectionner spécifiquement ce bruit (vu que les formes de bonne taille seront les éléments communs entre les deux images, qui seront alors supprimé par la soustraction).\n",
    "\n",
    "On désigne par *top-hat* (« chapeau haut-de-forme ») la différence entre l'image originale et son ouverture : \n",
    "\n",
    "$\\text{TopHat}(A) = A - (A \\circ B)$ où $\\circ$ désigne l'ouverture morphologique.\n",
    "\n",
    "Cette opération permet d'extraire les petits éléments clairs (plus petits que l'élément structurant) qui disparaissent lors de l'ouverture, ce qui est particulièrement utile pour détecter des détails fins sur un fond non uniforme ou pour corriger des variations d'éclairage avant une binarisation.\n",
    "\n",
    "##### Exercice\n",
    "\n",
    "Implémentez un *top-hat* et tester l’effet de différents éléments structurant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_hat(img, es):\n",
    "    return np.clip(img.astype(int) - ouverture(img, es).astype(int), 0, 255).astype(np.uint8)\n",
    "\n",
    "es7 = creer_element_structurant('carre', 7)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "axes[0].imshow(img_test, cmap='gray'); axes[0].set_title('Original'); axes[0].axis('off')\n",
    "axes[1].imshow(top_hat(img_test, es7), cmap='gray'); axes[1].set_title('Top-Hat (bruit)'); axes[1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Black-hat\n",
    "Immédiatement on a envie de tester ce que donne la différence entre la fermeture d’une image et l’image originale :\n",
    "\n",
    "$\\text{BlackHat}(A) = (A \\bullet B) - A$ où $\\bullet$ désigne la fermeture morphologique.\n",
    "\n",
    "La fermeture va combler les petits éléments de couleur du fond dont la taille est inférieure à celle de l’ES. Les formes resteront intactes. En faisant la différence, là où la fermeture a comblé la forme, la couleur sera celel de la forme et non du fond, donc ladifférence fera apparaîre ces zones comblées (et donc les défauts).\n",
    "\n",
    "Cette opération permet d'extraire les petits éléments sombres (trous, fissures, cavités plus petits que l'élément structurant) qui sont comblés lors de la fermeture, ce qui est utile pour détecter des défauts, des rayures ou du texte sombre sur un fond clair dans le cas de l’OCR par exemple, mais ça peut être utile dans d’autres domaines : détection de fissures dans du métal (inspection de soudures, corrosion…), défaut d’impression (contrôle qualité), détecter des craquelures dans une peinture (restaurantion, conservation dans des musées, etc.)\n",
    "\n",
    "##### Exercice\n",
    "\n",
    "1. Implémentez un *black-hat* et tester l’effet de différents éléments structurant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_hat(img, es):\n",
    "    return np.clip(fermeture(img, es).astype(int) - img.astype(int), 0, 255).astype(np.uint8)\n",
    "\n",
    "es5 = creer_element_structurant('carre', 4)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "axes[0].imshow(img_test, cmap='gray'); axes[0].set_title('Original'); axes[0].axis('off')\n",
    "axes[1].imshow(black_hat(img_test, es5), cmap='gray'); axes[1].set_title('Black-Hat (trous)'); axes[1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L’image utilisé pour le test est peu adaptée pour mettre en valeur l’opération black-hat : il n‘y a pas vraiment de défauts dans les formes.\n",
    "\n",
    "2. Voici une fonction qui génère des formes qui ressemblent à des lettres, avec des défauts dedans. Appliquer un black-hat pour sélectionner ces défauts :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def creer_image_test_blackhat():\n",
    "    \"\"\"\n",
    "    Crée une image simulant un document ou une surface avec :\n",
    "    - Fond clair\n",
    "    - Grandes formes sombres (lettres/logos)\n",
    "    - Défauts = fissures/rayures CLAIRES (couleur du fond) dans les formes sombres\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    h, w = 180, 280\n",
    "    \n",
    "    # Fond noir\n",
    "    img = np.zeros((h, w), dtype=np.float64)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # GRANDES FORMES SOMBRES (lettres stylisées)\n",
    "    # =========================================================================\n",
    "    \n",
    "    # Lettre \"H\"\n",
    "    img[30:130, 30:50] = 255      # Jambe gauche\n",
    "    img[30:130, 90:110] = 255     # Jambe droite\n",
    "    img[70:85, 30:110] = 255      # Barre horizontale\n",
    "    \n",
    "    # Lettre \"I\"\n",
    "    img[30:45, 130:190] = 255     # Barre du haut\n",
    "    img[115:130, 130:190] = 255   # Barre du bas\n",
    "    img[30:130, 152:168] = 255    # Jambe verticale\n",
    "    \n",
    "    # Carré plein\n",
    "    img[30:130, 210:260] = 255\n",
    "    \n",
    "    # =========================================================================\n",
    "    # DÉFAUTS CLAIRS (fissures, rayures = couleur du fond qui traverse les formes)\n",
    "    # =========================================================================\n",
    "    \n",
    "    # Rayure horizontale à travers le H\n",
    "    img[60:63, 30:110] = 0\n",
    "    \n",
    "    # Rayure verticale à travers la barre du H\n",
    "    img[70:85, 65:68] = 0\n",
    "    \n",
    "    # Fissure horizontale à travers le I\n",
    "    img[80:82, 152:168] = 0\n",
    "    \n",
    "    # Rayure à travers la barre du haut du I\n",
    "    img[36:39, 130:190] = 0\n",
    "    \n",
    "    # Fissure diagonale sur le carré\n",
    "    for i in range(70):\n",
    "        y = 35 + i\n",
    "        x = 215 + int(i * 0.6)\n",
    "        if 30 <= y < 130 and 210 <= x < 258:\n",
    "            img[y, x] = 0\n",
    "            img[y, min(x+1, 259)] = 0\n",
    "    \n",
    "    # Petites fissures/éclats dans le carré\n",
    "    img[50:52, 225:250] = 0\n",
    "    img[90:110, 230:233] = 0\n",
    "    img[70:72, 215:240] = 0\n",
    "    \n",
    "    # Petits trous/éclats dispersés dans les lettres\n",
    "    trous = [(45, 38), (100, 42), (55, 95), (110, 100),  # Dans le H\n",
    "             (38, 158), (120, 162), (70, 155),            # Dans le I\n",
    "             (45, 235), (85, 245), (115, 225)]            # Dans le carré\n",
    "    for (ty, tx) in trous:\n",
    "        rayon = np.random.randint(2, 4)\n",
    "        for dy in range(-rayon, rayon+1):\n",
    "            for dx in range(-rayon, rayon+1):\n",
    "                if dy*dy + dx*dx <= rayon*rayon:\n",
    "                    ny, nx = ty + dy, tx + dx\n",
    "                    if 0 <= ny < h and 0 <= nx < w:\n",
    "                        img[ny, nx] = 0\n",
    "    \n",
    "    return np.clip(img, 0, 255).astype(np.uint8)\n",
    "\n",
    "img_bh = creer_image_test_blackhat()\n",
    "\n",
    "es5 = creer_element_structurant('carre', 5)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "axes[0].imshow(img_bh, cmap='gray'); axes[0].set_title('Original'); axes[0].axis('off')\n",
    "axes[1].imshow(black_hat(img_bh, es5), cmap='gray'); axes[1].set_title('Black-Hat (sélection des défauts)'); axes[1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 : Exercice - Créer un pipeline de nettoyage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous générons une simulation de document bruité :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document bruité\n",
    "def creer_document_bruite():\n",
    "    h, w = 200, 300\n",
    "    doc = np.ones((h, w), dtype=np.uint8) * 240\n",
    "    for y in range(30, 180, 25):\n",
    "        for x in range(20, 280, 8):\n",
    "            if np.random.random() > 0.3:\n",
    "                doc[y:y+np.random.randint(12,18), x:x+np.random.randint(4,7)] = np.random.randint(20, 60)\n",
    "    for _ in range(500):\n",
    "        doc[np.random.randint(0, h), np.random.randint(0, w)] = 0 if np.random.random() > 0.5 else 255\n",
    "    return doc\n",
    "\n",
    "doc = creer_document_bruite()\n",
    "plt.imshow(doc, cmap='gray'); plt.title('Document bruité'); plt.axis('off'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCICE : Complétez le pipeline\n",
    "def nettoyer_document(img):\n",
    "    # 1. Binarisation\n",
    "    # 2. Ouverture\n",
    "    # 3. Fermeture\n",
    "    pass  # À compléter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRIGÉ\n",
    "def nettoyer_document(img):\n",
    "    seuil = seuil_otsu(img)\n",
    "    img_bin = np.where(img < seuil, 255, 0).astype(np.uint8)\n",
    "    es = creer_element_structurant('carre', 3)\n",
    "    return fermeture(ouverture(img_bin, es), es)\n",
    "\n",
    "resultat = nettoyer_document(doc)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "axes[0].imshow(doc, cmap='gray'); axes[0].set_title('Original'); axes[0].axis('off')\n",
    "axes[1].imshow(resultat, cmap='gray'); axes[1].set_title('Nettoyé'); axes[1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Récapitulatif morphologie\n",
    "\n",
    "| Opération | Formule | Effet |\n",
    "|-----------|---------|-------|\n",
    "| **Érosion** | $A \\ominus B$ | Amincit |\n",
    "| **Dilatation** | $A \\oplus B$ | Épaissit |\n",
    "| **Ouverture** | $(A \\ominus B) \\oplus B$ | Supprime bruit |\n",
    "| **Fermeture** | $(A \\oplus B) \\ominus B$ | Remplit trous |\n",
    "| **Gradient** | Dil - Ero | Contours |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suite : TP pour découvrir OpenCV et Scikit-Image\n",
    "\n",
    "```bash\n",
    "pip install opencv-python scikit-image\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pour aller plus loin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notions :\n",
    "* Filtres non-linéaires : filtre médian, filtre bilatéral (lissage préservant les contours)\n",
    "* Segmentation avancée : watershed, region growing, graph cuts\n",
    "* Morphologie mathématique : squelettisation, reconstruction géodésique, ligne de partage des eaux\n",
    "* Détection de contours : algorithme de Canny en détail, contours actifs (snakes)\n",
    "\n",
    "Bibliothèques :\n",
    "* suite au TP : approfondir sa connaissance de OpenCV et Scikit-Image\n",
    "* SimpleITK : traitement d'images médicales (3D, formats DICOM)\n",
    "* Pillow (PIL) : manipulation d'images simple et légère\n",
    "* imageio : lecture/écriture de formats variés (GIF, vidéo)\n",
    "* Mahotas : alternative à scikit-image avec des fonctions de morphologie avancées\n",
    "\n",
    "Données :\n",
    "* traiter des images réelles (médicales, industrielles, de tous les jours…)\n",
    "* [cours complet](https://haesleinhuepf.github.io/BioImageAnalysisNotebooks/intro.html) de traitement d’images biologiques/médicales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
