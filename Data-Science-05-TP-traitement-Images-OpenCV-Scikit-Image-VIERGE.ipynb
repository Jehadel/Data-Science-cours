{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27acf915-b338-4997-86ce-cfb2536d7cfc",
   "metadata": {},
   "source": [
    "# Data Science 5 : TP 5a - Traitement d'Images avec Python et Filtres Morphologiques\n",
    "\n",
    "Enseignant : Jean Delpech\n",
    "\n",
    "Cours : Data Science\n",
    "\n",
    "Classe : M1 Data/IA\n",
    "\n",
    "Année scolaire : 2025/2026\n",
    "\n",
    "Dernière mise à jour : janvier 2026\n",
    "\n",
    "## Module Data Science M1 - Séances 11 & 12\n",
    "\n",
    "**Objectifs du TP :**\n",
    "\n",
    "Ce TP fait suite au cours théorique sur le traitement d'images. Vous allez maintenant utiliser les bibliothèques **OpenCV** et **scikit-image** pour appliquer les concepts vus précédemment :\n",
    "\n",
    "- Seuillage et binarisation\n",
    "- Convolution et filtrage\n",
    "- Morphologie mathématique\n",
    "\n",
    "À l'issue de ce TP, vous saurez :\n",
    "- Choisir la bibliothèque appropriée selon le cas d'usage\n",
    "- Appliquer efficacement les opérations de traitement d'images\n",
    "- Comparer les performances des implémentations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f121c29-b7cc-4c08-96a3-8c5a38297944",
   "metadata": {},
   "source": [
    "## 1. Installation et imports\n",
    "\n",
    "### 1.1 Installation (si nécessaire)\n",
    "\n",
    "```bash\n",
    "pip install opencv-python scikit-image numpy matplotlib\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28972fe-d232-4ca8-8ba3-df97a8218056",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python scikit-image numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95248ec0-266b-4e8f-a30e-911053bdcac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import skimage\n",
    "from skimage import io, filters, morphology, exposure, color, util\n",
    "from skimage.filters import threshold_otsu, gaussian, sobel\n",
    "from skimage.morphology import disk, square, erosion, dilation, opening, closing\n",
    "import time\n",
    "\n",
    "# Vérification des versions\n",
    "print(f\"OpenCV version : {cv2.__version__}\")\n",
    "print(f\"scikit-image version : {skimage.__version__}\")\n",
    "print(f\"NumPy version : {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef138bb8-c8ad-4b05-bfd3-e02f429dfd85",
   "metadata": {},
   "source": [
    "### 1.2 Fonctions utiles\n",
    "\n",
    "Pendant le cours vous aurez remarqué qu’on affiche beaucoup d’image. Créons donc une fonction pour afficher des images (vous pourrez sinon utiliser la fonction, utilisée en cours qui affiche une image et son histogramme, si vous voulez accéder à plus d’information)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fb8ff9-87f4-4664-a3b2-2e33d1b8ba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def afficher_images(images, titres, cmap='gray', figsize=(15, 5)):\n",
    "    \"\"\"\n",
    "    Affiche plusieurs images côte à côte.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    images : list\n",
    "        Liste des images à afficher\n",
    "    titres : list\n",
    "        Liste des titres correspondants\n",
    "    cmap : str\n",
    "        Colormap à utiliser\n",
    "    figsize : tuple\n",
    "        Taille de la figure\n",
    "    \"\"\"\n",
    "    n = len(images)\n",
    "    fig, axes = plt.subplots(1, n, figsize=figsize)\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for ax, img, titre in zip(axes, images, titres):\n",
    "        if len(img.shape) == 3 and img.shape[2] == 3:\n",
    "            ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        else:\n",
    "            ax.imshow(img, cmap=cmap)\n",
    "        ax.set_title(titre, fontweight='bold')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e567c5c-3f6a-476d-a345-d05def92fcf4",
   "metadata": {},
   "source": [
    "Dans ce TP nous allons nous familiariser et comparer deux bibliothèques : OpenCV et Scikit-Images. Il peut être intéressant d’évaluer le temps d’exécution pour voir laquelle est la plus rapide. Voici une fonction pour mesurer le temps d’exécution d’une fonction :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe499a2-9851-47d5-a4ab-72c75cd80ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mesurer_temps(func, *args, n_iterations=10, **kwargs):\n",
    "    \"\"\"\n",
    "    Mesure le temps d'exécution moyen d'une fonction.\n",
    "    \n",
    "    Retourne\n",
    "    --------\n",
    "    tuple : (résultat, temps_moyen_ms)\n",
    "    \"\"\"\n",
    "    times = []\n",
    "    for _ in range(n_iterations):\n",
    "        start = time.perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        end = time.perf_counter()\n",
    "        times.append(end - start)\n",
    "    \n",
    "    return result, np.mean(times) * 1000  # en millisecondes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79514d41-8691-4cc5-9c13-7ddad825037d",
   "metadata": {},
   "source": [
    "Cette fonction est utilisable dans un script. Dans un notebook vous pouvez aussi mesurer le temps d’exécution d’une cellule avec les balises `%%time` sur la première ligne de la cellule. Attention, cela mesure le temps d’exécution de la cellule entière."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4d18ca-8bdb-41ec-aa5f-b324cf1a6d9e",
   "metadata": {},
   "source": [
    "### 1.3 Génération d’images standardisées (mires)\n",
    "\n",
    "Nous allons tester et comparer des fonctions pour le seuillage, pour un filtrage par convolution et pour de opérations morphologiques. Il est intéressant de créer des images contrôlées, qui contiennent des éléments (bruits, détails fins, fond, etc.) qui permettent d’éprouver ces opérations. \n",
    "\n",
    "Créons donc de telles images de manière procédurales.\n",
    "\n",
    "Néanmoins nous vous demanderons aussi de traiter des images de votre choix afin de voir le rendu sur des éléments réels non standardisés aussi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a6438a-e3bb-4eaa-9651-b7656cb88aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creer_image_test_seuillage():\n",
    "    \"\"\"Crée une image avec un histogramme bimodal pour tester le seuillage.\"\"\"\n",
    "    np.random.seed(42)\n",
    "    h, w = 300, 400\n",
    "    img = np.random.normal(180, 20, (h, w))  # Fond clair\n",
    "    \n",
    "    # Formes sombres\n",
    "    img[50:150, 50:150] = np.random.normal(60, 15, (100, 100))  # Carré\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            if (i - 150)**2 + (j - 300)**2 < 60**2:  # Cercle\n",
    "                img[i, j] = np.random.normal(50, 10)\n",
    "    img[200:280, 100:350] = np.random.normal(70, 15, (80, 250))  # Rectangle\n",
    "    \n",
    "    return np.clip(img, 0, 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def creer_image_test_filtrage():\n",
    "    \"\"\"Crée une image avec du bruit pour tester les filtres.\"\"\"\n",
    "    np.random.seed(42)\n",
    "    h, w = 300, 400\n",
    "    \n",
    "    # Image de base avec formes géométriques\n",
    "    img = np.ones((h, w), dtype=np.float64) * 200\n",
    "    img[50:150, 50:150] = 50  # Carré\n",
    "    img[100:250, 200:220] = 60  # Rectangle vertical\n",
    "    img[180:200, 100:350] = 60  # Rectangle horizontal\n",
    "    \n",
    "    # Ajout de bruit gaussien\n",
    "    bruit = np.random.normal(0, 25, (h, w))\n",
    "    img = img + bruit\n",
    "    \n",
    "    # Ajout de bruit sel et poivre\n",
    "    for _ in range(500):\n",
    "        y, x = np.random.randint(0, h), np.random.randint(0, w)\n",
    "        img[y, x] = 255 if np.random.random() > 0.5 else 0\n",
    "    \n",
    "    return np.clip(img, 0, 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def creer_image_test_morphologie():\n",
    "    \"\"\"Crée une image binaire pour tester les opérations morphologiques.\"\"\"\n",
    "    np.random.seed(42)\n",
    "    h, w = 200, 300\n",
    "    img = np.zeros((h, w), dtype=np.uint8)\n",
    "    \n",
    "    # Formes principales\n",
    "    img[30:90, 30:100] = 255  # Rectangle\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            if (i - 60)**2 + (j - 180)**2 < 40**2:  # Cercle\n",
    "                img[i, j] = 255\n",
    "    img[120:180, 50:120] = 255  # Carré avec trou\n",
    "    img[135:165, 65:105] = 0   # Trou\n",
    "    img[130:170, 180:250] = 255  # Rectangle avec petits trous\n",
    "    img[145:155, 200:210] = 0\n",
    "    img[145:155, 220:230] = 0\n",
    "    \n",
    "    # Bruit (petits points)\n",
    "    for _ in range(100):\n",
    "        y, x = np.random.randint(0, h), np.random.randint(0, w)\n",
    "        img[y, x] = 255\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "# Création des images de test\n",
    "img_seuillage = creer_image_test_seuillage()\n",
    "img_filtrage = creer_image_test_filtrage()\n",
    "img_morpho = creer_image_test_morphologie()\n",
    "\n",
    "afficher_images(\n",
    "    [img_seuillage, img_filtrage, img_morpho],\n",
    "    ['Image pour seuillage', 'Image pour filtrage', 'Image pour morphologie']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74ce579-9eba-49e8-a165-2d0d2157aed2",
   "metadata": {},
   "source": [
    "## 2. Présentation des bibliothèques\n",
    "\n",
    "### 2.1 OpenCV\n",
    "\n",
    "**OpenCV** (Open Source Computer Vision Library) est une bibliothèque développée initialement par Intel, aujourd'hui maintenue par la communauté open-source.\n",
    "\n",
    "- Site : https://opencv.org/\n",
    "- Présentation sur Wikipédia : https://fr.wikipedia.org/wiki/OpenCV\n",
    "- Dépôt GitHub : https://github.com/opencv/opencv\n",
    "- Documentation : https://docs.opencv.org/\n",
    "\n",
    "**Points forts :**\n",
    "- Très performant (code optimisé en C++)\n",
    "- Large écosystème (vision par ordinateur, machine learning, GPU)\n",
    "- Standard industriel\n",
    "\n",
    "**Particularités :**\n",
    "- Images en BGR par défaut (pas RGB), mais fourni les outils pour convertir d’un espace colorimétrique à l’autre\n",
    "- Certaines fonctions utilisent des conventions de spécification des dimensions (largeur, hauteur), il faut donc faire attention de ne pas se mélanger les pinceaux quand on appelle des méthodes NumPy avec les dimensions (lignes, colonnes), en se rappelant que le nombre de lignes correspondant à la hauteur et le nombre de colonne à la largeur.\n",
    "- OpenCV travaille principalement en `uint8` (choix intuitif pour des images), donc bien envoyer les bons types au fonctions (si on définit une valeur par `value / 255.0` pour normaliser, le résultat sera un `float64`). Pour ne rien arranger, ce type d’erreur de typage peut-être silencieux (retourne un résulatat incohérent plutôt qu’une erreur).\n",
    "\n",
    "### 2.2 scikit-image\n",
    "\n",
    "**scikit-image** est une bibliothèque Python pure, intégrée à l'écosystème SciPy.\n",
    "- Site : https://scikit-image.org/\n",
    "- Présentation sur Wikipedia : https://fr.wikipedia.org/wiki/Scikit-image\n",
    "- Dépôt GitHub : https://github.com/scikit-image/scikit-image\n",
    "- Documentation : https://scikit-image.org/docs/stable/\n",
    "\n",
    "**Points forts :**\n",
    "- API « pythonique » et intuitive\n",
    "- Excellente documentation et exemples\n",
    "- Intégration native avec NumPy, SciPy, matplotlib\n",
    "\n",
    "**Particularités :**\n",
    "- Images en RGB ou niveaux de gris (convention standard)\n",
    "- Travaille souvent avec des images normalisées [0, 1]\n",
    "- Le type par défaut est (donc) généralement `float64` mais `uint8` est aussi utilisé pour les valeur [0, 255] (vérifier)\n",
    "\n",
    "### 2.3 Tableau comparatif\n",
    "\n",
    "| Critère | OpenCV | scikit-image |\n",
    "|---------|--------|---------------|\n",
    "| Performance | ⭐⭐⭐ Très rapide | ⭐⭐ Correct |\n",
    "| Facilité d'utilisation | ⭐⭐ Moyenne | ⭐⭐⭐ Excellente |\n",
    "| Documentation | ⭐⭐ Variable | ⭐⭐⭐ Excellente |\n",
    "| Intégration Python | ⭐⭐ Wrapper C++ | ⭐⭐⭐ Native |\n",
    "| Format d'image | BGR, uint8 | RGB, float [0,1] ou uint8 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c199bf8c-f957-4bba-9f96-d2d0a4094cab",
   "metadata": {},
   "source": [
    "## 3. Seuillage et binarisation\n",
    "\n",
    "### 3.1 Rappel théorique\n",
    "\n",
    "Le seuillage transforme une image en niveaux de gris en image binaire :\n",
    "\n",
    "$$\n",
    "I'(x,y) = \\begin{cases} 255 & \\text{si } I(x,y) > T \\\\ 0 & \\text{sinon} \\end{cases}\n",
    "$$\n",
    "\n",
    "Le seuil optimal peut être déterminé automatiquement par la méthode d'**Otsu** qui minimise la variance intra-classe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bf7ed3-2c26-4758-a17b-0b2981f71199",
   "metadata": {},
   "source": [
    "### 3.2 Seuillage avec OpenCV\n",
    "\n",
    "Créez une fonction `seuil_cv()` qui réalise un seuillage simple et un seuillage d’Otsu à l’aide de la méthode `cv2.threeshold()` (regardez quels arguments sont nécessaires dans la doc).\n",
    "\n",
    "Testez votre fonction sur l’image de test créée spécifiquement pour le seuillage.\n",
    "Appliquez votre fonction de seuillage sur une image de votre choix.\n",
    "Comparez différentes valeurs du seuil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b4cfaf-2773-4a04-9181-2b393ad035e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4db223-549c-4f0f-aa88-e868dc2230da",
   "metadata": {},
   "source": [
    "### 3.3 Seuillage avec Scikit-Image\n",
    "\n",
    "Inspectez les méthodes de Scikit-Image importées dans ce notebook. Sélectionnez et utilisez celles qui vous semblent utiles pour réaliser une fonction de seuillage similaire à la précédente et que vous testerez de la même manière :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1871ecee-6692-42ce-8553-2f1c2e50a0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad6ce1b-0d06-4609-a541-b37acaa94af0",
   "metadata": {},
   "source": [
    "Scikit-image dispose de plusieurs autres méthodes pour déterminer un seuil :\n",
    "\n",
    "```python\n",
    "from skimage.filters import threshold_mean, threshold_minimum, threshold_triangle\n",
    "\n",
    "seuil_mean = threshold_mean(img_seuillage)\n",
    "seuil_triangle = threshold_triangle(img_seuillage)\n",
    "```\n",
    "\n",
    "Cherchez dans la doc comment elles déterminent les seuil, puis comparez-les :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df73b05c-dfbc-484f-a9d9-d6e8f158874b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf68d8ea-4af6-470e-82f6-3935757e556e",
   "metadata": {},
   "source": [
    "### 3.4 Seuillage adaptatif\n",
    "\n",
    "Le seuillage adaptatif calcule un seuil local pour chaque pixel, utile quand l'éclairage n'est pas uniforme.\n",
    "\n",
    "Le seuillage global (comme Otsu) applique un seuil unique à toute l'image, ce qui fonctionne bien lorsque l'éclairage est uniforme. Cependant, dans de nombreuses situations réelles (documents scannés, photos avec ombres, éclairage naturel), la luminosité varie d'une zone à l'autre. Un seuil global ne peut alors pas séparer correctement les objets du fond sur l'ensemble de l'image.\n",
    "Le seuillage adaptatif résout ce problème en calculant un seuil local pour chaque pixel, basé sur les intensités de son voisinage. Pour un pixel situé en $(x, y)$, on calcule une statistique (moyenne ou moyenne pondérée gaussienne) sur une fenêtre centrée autour de ce pixel, puis on soustrait une constante $C$ :\n",
    "\n",
    "$$\n",
    "T(x,y) = \\text{moyenne}_{voisinage}(x,y) - C$$\n",
    "\n",
    "Le pixel est alors classé blanc si son intensité est supérieure à ce seuil local, noir sinon.\n",
    "\n",
    "Paramètres clés de l’algorithme :\n",
    "\n",
    "- Taille du voisinage (blockSize) : détermine l'échelle des variations prises en compte. Une fenêtre trop petite sera sensible au bruit, une fenêtre trop grande ne s'adaptera pas aux variations locales. En pratique, il s’agit d’une valeur impaire (pour qu’il y ait un pixel centré). La taille du bloc dépend de la taille des objets et de l'échelle des variations d'éclairage. Pour un document scanné en 300 dpi, des valeurs entre 11 et 51 fonctionnent généralement bien. Pour des images plus petites, commencer avec des valeurs entre 7 et 15.\n",
    "- Constante C : permet d'ajuster la sensibilité. Une valeur positive rend le seuillage plus strict (moins de pixels blancs).\n",
    "- Méthode pour évaluer l’intensité du voisinnage : moyenne simple (MEAN) ou moyenne gaussienne (GAUSSIAN), cette dernière donnant plus de poids aux pixels proches du centre.\n",
    "\n",
    "Créez des fonctions qui réalisent un seuillage adaptatif (avec le calcul de la moyenne, et le calcul de la gaussienne) avec les méthodes `cv2.adaptiveThreshold()` d’OpenCV et la méthode `skimage.filters.threeshold_local()` de Scikit-Image.\n",
    "\n",
    "Tester ces fonctions avec l’image `img_seuillage` puis avec une image (« réelle ») de votre choix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3e1e64-8280-47b0-85b0-32e307cd4963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV : seuillage adaptatif\n",
    "def seuil_adapt_cv(img, gauss=False):\n",
    "   \n",
    "    # GOTRE CODE\n",
    "\n",
    "img_adapt_cv_mean = seuil_adapt_cv(img_seuillage)\n",
    "img_adapt_cv_gauss = seuil_adapt_cv(img_seuillage, gauss=True)\n",
    "\n",
    "\n",
    "# scikit-image : seuillage adaptatif\n",
    "from skimage.filters import threshold_local\n",
    "\n",
    "def seuil_adapt_ski(img, gauss=False):\n",
    "   \n",
    "    # VOTRE CODE\n",
    "\n",
    "img_adapt_ski_mean = seuil_adapt_ski(img_seuillage)\n",
    "img_adapt_ski_gauss = seuil_adapt_ski(img_seuillage, gauss=True)\n",
    "\n",
    "afficher_images(\n",
    "    [img_seuillage, img_adapt_cv_mean, img_adapt_cv_gauss, img_adapt_ski_mean, img_adapt_ski_gauss],\n",
    "    ['Originale', 'Adaptatif Mean (CV)', 'Adaptatif Gauss (CV)', 'Adaptatif Mean (skimage)', 'Adaptatif Gauss (skimage)']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157a639b-2e85-48c1-ae98-d54998fc6d68",
   "metadata": {},
   "source": [
    "### 3.5 Exercice : Comparaison des méthodes de seuillage\n",
    "\n",
    "Pour comparer les différentes méthodes de seuillage sur une image à éclairage non uniforme. nous allons d’abord créer une image avec un éclairage non-uniforme : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305f7720-97ff-4e27-8524-9ee172ecd804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'une image avec éclairage non uniforme\n",
    "def creer_image_eclairage_variable():\n",
    "    h, w = 300, 400\n",
    "    # Gradient d'éclairage\n",
    "    y_grad = np.linspace(0.5, 1.5, h).reshape(-1, 1)\n",
    "    x_grad = np.linspace(0.7, 1.3, w).reshape(1, -1)\n",
    "    eclairage = y_grad * x_grad\n",
    "    \n",
    "    # Image de base\n",
    "    img = np.ones((h, w)) * 180\n",
    "    img[50:120, 50:150] = 50   # Rectangle 1\n",
    "    img[180:250, 100:200] = 50  # Rectangle 2\n",
    "    img[80:180, 280:350] = 50   # Rectangle 3\n",
    "    \n",
    "    # Application de l'éclairage\n",
    "    img = img * eclairage\n",
    "    img = np.clip(img, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    return img\n",
    "\n",
    "img_eclairage = creer_image_eclairage_variable()\n",
    "afficher_images([img_eclairage],['Image éclairage variable'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f810d4cd-ac78-4c4b-b761-0a17ff42a5ea",
   "metadata": {},
   "source": [
    "Testez et comparez les différentes méthodes de seuillage sur cette image :\n",
    "\n",
    "- seuil otsu\n",
    "- seuil adaptatif moyen\n",
    "- seuil adaptatif gaussien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf1660f-9bc2-4f5e-b05b-5f26f62e3054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b6751c-93bd-41f8-9b08-3e57904adb2c",
   "metadata": {},
   "source": [
    "Testez différentes valeurs pour le paramètre `block_size` (scikit-image) et `blockSize` (opencv). Que constatez-vous ? Comment l’expliquez vous ?\n",
    "\n",
    "Il semble donc que le filtre adaptatif n’est pas adapté quand on a de grandes plages uniformes.\n",
    "\n",
    "Afin de corriger cela, vous pouvez essayer de modifier le paramètre $C$ (en forçant un seuil plus bas, plus de pixels seront classés noirs). Une autre approche consiste à combiner des approches en appliquer un filtre adaptatif, et de « combler » les trous avec une fermeture morphologique. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49ba4e0-5eaf-47ec-b83a-d10e60339ed9",
   "metadata": {},
   "source": [
    "## 4. Convolution et filtrage\n",
    "\n",
    "### 4.1 Rappel théorique\n",
    "\n",
    "La convolution applique un noyau $K$ à l'image $I$ :\n",
    "\n",
    "$$\n",
    "G(x,y) = \\sum_{i,j} K(i,j) \\cdot I(x+i, y+j)\n",
    "$$\n",
    "\n",
    "Les filtres classiques incluent :\n",
    "- **Lissage** : moyenneur, gaussien (réduction du bruit)\n",
    "- **Détection de contours** : Sobel, Laplacien\n",
    "- **Netteté** : sharpen (pas vraiment un filtre en particulier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2ac916-1114-4837-8b3d-d31f829c495e",
   "metadata": {},
   "source": [
    "### 4.2 Filtres de lissage\n",
    "\n",
    "OpenCV propose les méthodes suivantes : `cv2.blur()`, `cv2.GaussianBlur()`, `cv2.medianBlur()`, `cv2.bilateralFilter()` \n",
    "Lisez la doc correspondante, testez les avec l’image `img_filtrage` que nous avons créé, et une image de votre choix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742a299b-ef32-4b1c-9dc0-41683ef6cbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VOTRE CODE :\n",
    "# === OpenCV ===\n",
    "\n",
    "# Filtre moyenneur (box filter)\n",
    "\n",
    "\n",
    "# Filtre gaussien\n",
    "\n",
    "\n",
    "# Filtre médian (non-linéaire, très efficace contre le bruit sel/poivre)\n",
    "\n",
    "\n",
    "# Filtre bilatéral (préserve les contours)\n",
    "\n",
    "\n",
    "afficher_images(\n",
    "    [img_filtrage, img_blur_cv, img_gauss_cv, img_median_cv, img_bilateral_cv],\n",
    "    ['Originale (bruitée)', 'Moyenneur 5×5', 'Gaussien 5×5 σ=1.5', 'Médian 5×5', 'Bilateral'],\n",
    "    figsize=(16, 4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103e0041-cb03-4546-91fd-02179a7fa5cd",
   "metadata": {},
   "source": [
    "Scikit-image propose des méthodes qui réalisent les mêmes opération (lisez attentivement les imports). Pour le filtre median nous pouvons utiliser un élément structurant (on vous donne le code). Pour les autres filtes, lisez la doc correspondante et testez-les de la même manière que précédemment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368ec99a-d694-43ab-ae3a-74794a6481da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE :\n",
    "# === scikit-image ===\n",
    "\n",
    "from skimage.filters import gaussian, median\n",
    "from skimage.restoration import denoise_bilateral\n",
    "from skimage.morphology import disk\n",
    "\n",
    "# Conversion en float [0, 1] pour scikit-image\n",
    "\n",
    "\n",
    "# Filtre gaussien\n",
    "\n",
    "# Filtre médian (utilise un élément structurant)\n",
    "\n",
    "\n",
    "# Filtre bilatéral\n",
    "\n",
    "afficher_images(\n",
    "    [img_filtrage, (img_gauss_ski * 255).astype(np.uint8), \n",
    "     img_median_ski, (img_bilateral_ski * 255).astype(np.uint8)],\n",
    "    ['Originale', 'Gaussien (skimage)', 'Médian (skimage)', 'Bilatéral (skimage)'],\n",
    "    figsize=(16, 4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7eded3-a139-4f15-ab15-3155ac50551b",
   "metadata": {},
   "source": [
    "Qu’observez-vous lorsque l’on fait intervenir un élément structurant pour le filtre median (comparativement à OpenCV) ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6193e329-8a38-474e-99c1-146ddc7330b9",
   "metadata": {},
   "source": [
    "### 4.3 Détection de contours\n",
    "\n",
    "Vous commencez à prendre le pli : testons les méthodes qui permettent d’extraire les contours de l’image `img_filtrage`.\n",
    "\n",
    "Cette image est bruitée : nettoyons là un peu pour atténuer le bruit, qui pourrait géner la détection.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82482d3e-6f9a-45f1-bf5b-82d21996af58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image nettoyée pour la détection de contours\n",
    "img_clean = cv2.GaussianBlur(img_filtrage, (5, 5), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e6609d-b81c-4e89-a8b7-74199dfb2b12",
   "metadata": {},
   "source": [
    "Pour OpenCV les méthodes à tester devraient avoir des désignations familières : `cv2.Sobel()`, `cv2.Laplacian()`. Vous pouvez tester aussi la méthode `cv2.Canny()`. En fonction des résultat, tester différents traitements pour supprimerle bruit de `img_filtrage`, pour voir si cela a un impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93120a39-8add-43c4-b397-87800d1d9a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE :\n",
    "# === OpenCV ===\n",
    "\n",
    "# Sobel\n",
    "\n",
    "\n",
    "# Laplacien\n",
    "\n",
    "\n",
    "# Canny (détecteur de contours complet)\n",
    "\n",
    "\n",
    "afficher_images(\n",
    "    [img_clean, sobel_mag_cv, np.abs(laplacien_cv), canny_cv],\n",
    "    ['Image lissée', 'Sobel (magnitude)', 'Laplacien', 'Canny'],\n",
    "    figsize=(16, 4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59e3cfc-ce7d-4368-b00b-8fc2a9c01f40",
   "metadata": {},
   "source": [
    "Comme précédemment, en ce qui concerne scikit-image nous vous importons les méthodes à tester :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326b34aa-d580-4422-b7bf-1c19d5af41d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE :\n",
    "# === scikit-image ===\n",
    "\n",
    "from skimage.filters import sobel, sobel_h, sobel_v, laplace\n",
    "from skimage.feature import canny\n",
    "\n",
    "\n",
    "\n",
    "# Sobel\n",
    "\n",
    "\n",
    "# Laplacien\n",
    "\n",
    "\n",
    "# Canny\n",
    "\n",
    "\n",
    "afficher_images(\n",
    "    [img_clean, sobel_ski, np.abs(laplace_ski), canny_ski.astype(np.uint8) * 255],\n",
    "    ['Image lissée', 'Sobel (skimage)', 'Laplacien (skimage)', 'Canny (skimage)'],\n",
    "    figsize=(16, 4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a150eb9a-bf82-42e5-8f4e-2afe0c09017d",
   "metadata": {},
   "source": [
    "### 4.4 Convolution avec noyau personnalisé\n",
    "\n",
    "OpenCV et Scikit-image vous donnent la possibilité de définir vos noyaux.\n",
    "\n",
    "Définissez des noyaux de votre choix, par exemple deux noyaux 3×3, un de netteté (sharpen) et un de type relief (emboss). Vous pouvez bien sûr en définir plus, de toutes taille, etc. Expérimentez !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c2319f-922a-47a1-82b1-e99eee904416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE :\n",
    "# Définition de noyaux personnalisés\n",
    "\n",
    "# Noyau de netteté (sharpen)\n",
    "\n",
    "\n",
    "# Noyau de relief (emboss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf84bd9-fd8d-4869-a923-3862885cd3e4",
   "metadata": {},
   "source": [
    "Pour utiliser ces noyaux avec OpenCV, utilisez la méthode `cv2.filter2D` (ici aussi utilisez plutôt une version débruitée ou lissée de `img_filtrage`) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202b3bf9-8053-453c-ac87-55392e16d5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE :\n",
    "# === OpenCV ===\n",
    "\n",
    "\n",
    "\n",
    "afficher_images(\n",
    "    [img_clean, img_sharpen_cv, img_emboss_cv],\n",
    "    ['Originale', 'Sharpen', 'Emboss'],\n",
    "    figsize=(15, 4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c6a927-7fc8-49c0-b9e8-89d6079db695",
   "metadata": {},
   "source": [
    "Pour scikit-image :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49845536-44d7-4ad9-a845-a8e08c85ad72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === scikit-image ===\n",
    "from scipy.ndimage import convolve\n",
    "\n",
    "\n",
    "# pour « re-normaliser » l’image :\n",
    "\n",
    "\n",
    "\n",
    "# pour « re-normaliser » l’image :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9df078-849c-436d-b15f-5d0516a6f49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "afficher_images(\n",
    "    [img_clean, img_sharpen_ski, img_emboss_ski],\n",
    "    ['Originale', 'Sharpen', 'Emboss'],\n",
    "    figsize=(15, 4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db2c12d-9116-4207-968a-85746f42c9d2",
   "metadata": {},
   "source": [
    "Quelle différence constatez-vous entre les deux bibliothèques ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d46a79-3624-4998-8176-689aa678f072",
   "metadata": {},
   "source": [
    "### 4.5 Exercice : Pipeline de débruitage\n",
    "\n",
    "Trouver la meilleure combinaison de filtres pour nettoyer l'image bruitée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56a3de0-9e87-49c7-851f-f533e130e341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Expérimentez différentes combinaisons\n",
    "# 1. Médian seul\n",
    "# 2. Gaussien seul\n",
    "# 3. Médian puis Gaussien\n",
    "# 4. Bilatéral\n",
    "#\n",
    "# Conseil : Le filtre médian est très efficace contre le bruit sel/poivre\n",
    "#           Le filtre gaussien lisse le bruit gaussien\n",
    "\n",
    "# Votre code ici :\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7f349b-a703-4599-b3cd-8071c927aa63",
   "metadata": {},
   "source": [
    "## 5. Morphologie mathématique\n",
    "\n",
    "### 5.1 Rappel théorique\n",
    "\n",
    "Les opérations morphologiques travaillent sur les **formes** des objets :\n",
    "\n",
    "- **Érosion** : rétrécit les objets, supprime les petits détails\n",
    "- **Dilatation** : agrandit les objets, comble les petits trous\n",
    "- **Ouverture** (érosion → dilatation) : supprime les petits objets\n",
    "- **Fermeture** (dilatation → érosion) : comble les petits trous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3a6671-cc80-4be3-b249-74a3357e84a7",
   "metadata": {},
   "source": [
    "### 5.2 Éléments structurants\n",
    "\n",
    "Voici comment crêéer des éléments structurants avec OpenCV et Scikit-image :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeee273-9f0a-4cdd-b15c-ea46b5c620f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === OpenCV ===\n",
    "# Création d'éléments structurants avec cv2.getStructuringElement\n",
    "\n",
    "es_rect_cv = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "es_ellipse_cv = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "es_cross_cv = cv2.getStructuringElement(cv2.MORPH_CROSS, (5, 5))\n",
    "\n",
    "print(\"OpenCV - Rectangle 5×5 :\")\n",
    "print(es_rect_cv)\n",
    "print(\"\\nOpenCV - Ellipse 5×5 :\")\n",
    "print(es_ellipse_cv)\n",
    "print(\"\\nOpenCV - Croix 5×5 :\")\n",
    "print(es_cross_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feecf151-61f3-46a8-95d3-c829f8bda25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === scikit-image ===\n",
    "# Création d'éléments structurants avec skimage.morphology\n",
    "\n",
    "from skimage.morphology import square, disk, diamond, rectangle\n",
    "\n",
    "es_square_ski = square(5)\n",
    "es_disk_ski = disk(2)  # rayon = 2 donne environ 5×5\n",
    "es_diamond_ski = diamond(2)\n",
    "\n",
    "print(\"scikit-image - Carré 5×5 :\")\n",
    "print(es_square_ski)\n",
    "print(\"\\nscikit-image - Disque (rayon 2) :\")\n",
    "print(es_disk_ski)\n",
    "print(\"\\nscikit-image - Diamant (rayon 2) :\")\n",
    "print(es_diamond_ski)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab201cd2-fe9d-41dd-a7ae-1dcf73710184",
   "metadata": {},
   "source": [
    "### 5.3 Opérations de base\n",
    "\n",
    "- Créez un élément structurant : carré de 5 pixels de côté\n",
    "- Appliquez les opérations suivantes :\n",
    "    - érosion -> `cv2.erode()`\n",
    "    - dilatation -> `cv2.dilate()`\n",
    "    - ouverture -> `cv2.morphologyEx()` avec l’argument `cv2.MORPH_OPEN`\n",
    "    - fermeture -> `cv2.morphologyEx()` avec l’argument `cv2.MORPH_CLOSE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7fc330-5a87-4acd-85c6-32b0544eb6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE :\n",
    "# === OpenCV ===\n",
    "\n",
    "es =\n",
    "\n",
    "img_erosion_cv = \n",
    "img_dilatation_cv = \n",
    "img_ouverture_cv = \n",
    "img_fermeture_cv =\n",
    "\n",
    "afficher_images(\n",
    "    [img_morpho, img_erosion_cv, img_dilatation_cv, img_ouverture_cv, img_fermeture_cv],\n",
    "    ['Originale', 'Érosion', 'Dilatation', 'Ouverture', 'Fermeture'],\n",
    "    figsize=(20, 4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c02594-2ca3-4916-8ed5-5be33202cf42",
   "metadata": {},
   "source": [
    "Avec Scikit-image vous pouvez importer directement les opérations `erosion`, `dilatation`, `opening` et `closing` (ainsique l’élément structurant `square`) depuis `skimage.morphology` : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174f7607-cbda-48aa-91d4-3c4566f9e2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE :\n",
    "# === scikit-image ===\n",
    "\n",
    "from skimage.morphology import erosion, dilation, opening, closing, square\n",
    "\n",
    "es_ski = \n",
    "\n",
    "# scikit-image attend une image binaire (bool ou 0/1)\n",
    "img_morpho_bool =\n",
    "\n",
    "img_erosion_ski =\n",
    "img_dilatation_ski = \n",
    "img_ouverture_ski = \n",
    "img_fermeture_ski = \n",
    "\n",
    "afficher_images(\n",
    "    [img_morpho, img_erosion_ski.astype(np.uint8) * 255, \n",
    "     img_dilatation_ski.astype(np.uint8) * 255,\n",
    "     img_ouverture_ski.astype(np.uint8) * 255, \n",
    "     img_fermeture_ski.astype(np.uint8) * 255],\n",
    "    ['Originale', 'Érosion', 'Dilatation', 'Ouverture', 'Fermeture'],\n",
    "    figsize=(20, 4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5342ab-31ec-4d31-87ee-07c9a8e2cc5e",
   "metadata": {},
   "source": [
    "### 5.4 Opérations avancées\n",
    "\n",
    "Maintenant que vous disposez des opérations de base, vous pouvez créer des opérations plus avancées comme le gradient morphologique, top-hat, black-hat…\n",
    "\n",
    "À ceci près que OpenCV propose également ces opérations : `cv2.MORPH_GRADIENT`, `cv2.MORPH_TOPHAT`, `cv2.MORPH_BLACKHAT`, etc.\n",
    "\n",
    "Avec Scikit-image, il faut implémenter ces opérations (soustraction d’images, etc., cf. cours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf06aea-5a4b-4f86-a614-33926891d06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE :\n",
    "# === Gradient morphologique ===\n",
    "# Gradient = Dilatation - Érosion (détecte les contours)\n",
    "\n",
    "# OpenCV\n",
    "gradient_cv =\n",
    "\n",
    "# scikit-image\n",
    "gradient_ski = \n",
    "\n",
    "# === Top-hat et Black-hat ===\n",
    "# Top-hat = Original - Ouverture (extrait les petits éléments clairs)\n",
    "# Black-hat = Fermeture - Original (extrait les petits éléments sombres)\n",
    "\n",
    "tophat_cv = \n",
    "blackhat_cv = \n",
    "\n",
    "afficher_images(\n",
    "    [img_morpho, gradient_cv, tophat_cv, blackhat_cv],\n",
    "    ['Originale', 'Gradient morphologique', 'Top-hat', 'Black-hat'],\n",
    "    figsize=(16, 4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad0c730-5014-477f-b368-d840828a1620",
   "metadata": {},
   "source": [
    "### 5.5 Morphologie en niveaux de gris\n",
    "\n",
    "Pour le cours, afin de faciliter la compréhension, nous avons surtout présenté l’approche morphologique avec des images binaires. Nous avions indiqué que pour les images en niveau de gris, plutôt que prendre les valeurs 0 (érosion) et 1 (dilation), on prenait respectivement les valeurs min et max des pixels de l’ES. \n",
    "\n",
    "Cette opération est transparente pour l’utilisateur, par exemple définissez un élément structurant (par exemple une ellipse 7×7 – soit un cercle) et appliquez érosion, dilation et gradient sur l’image `img_seuillage`(qui est en niveau de gris) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71db548f-e1d5-4008-a9a0-77ae8908ca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE :\n",
    "# La morphologie fonctionne aussi sur les images en niveaux de gris\n",
    "# Érosion = minimum local, Dilatation = maximum local\n",
    "\n",
    "es_gris = \n",
    "\n",
    "# OpenCV\n",
    "img_erosion_gris_cv =\n",
    "img_dilatation_gris_cv = \n",
    "img_gradient_gris_cv = \n",
    "\n",
    "afficher_images(\n",
    "    [img_seuillage, img_erosion_gris_cv, img_dilatation_gris_cv, img_gradient_gris_cv],\n",
    "    ['Originale', 'Érosion (min local)', 'Dilatation (max local)', 'Gradient'],\n",
    "    figsize=(16, 4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5be0bd-6e0f-4822-bf01-0c40abee567e",
   "metadata": {},
   "source": [
    "### 5.6 Exercice : Nettoyage d'un document scanné\n",
    "\n",
    "Simulons un document scanné bruité, et comme dans le cours définissez un pipeline avec des opérations morphologiques pour nettoyer le document bruité :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85372500-9fff-40aa-9426-9629b680df8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creer_document_bruite():\n",
    "    \"\"\"Crée une image simulant un document scanné avec du bruit.\"\"\"\n",
    "    np.random.seed(42)\n",
    "    h, w = 200, 300\n",
    "    img = np.ones((h, w), dtype=np.uint8) * 240  # Fond clair\n",
    "    \n",
    "    # Simule des \"lettres\" (rectangles noirs)\n",
    "    lettres = [\n",
    "        (30, 30, 60, 15),   # y, x, hauteur, largeur\n",
    "        (30, 55, 60, 15),\n",
    "        (30, 80, 60, 15),\n",
    "        (30, 105, 60, 15),\n",
    "        (110, 30, 50, 12),\n",
    "        (110, 50, 50, 12),\n",
    "        (110, 70, 50, 12),\n",
    "        (110, 90, 50, 12),\n",
    "        (110, 110, 50, 12),\n",
    "    ]\n",
    "    for (y, x, h_l, w_l) in lettres:\n",
    "        img[y:y+h_l, x:x+w_l] = 30\n",
    "    \n",
    "    # Grand rectangle (logo)\n",
    "    img[30:100, 180:280] = 30\n",
    "    img[45:85, 195:265] = 240  # Trou au milieu\n",
    "    \n",
    "    # Ajout de bruit (points isolés)\n",
    "    for _ in range(300):\n",
    "        y, x = np.random.randint(0, h), np.random.randint(0, w)\n",
    "        img[y, x] = np.random.choice([0, 30, 240, 255])\n",
    "    \n",
    "    return img\n",
    "\n",
    "img_document = creer_document_bruite()\n",
    "\n",
    "# TODO : Nettoyez ce document\n",
    "# 1. Binariser l'image (seuillage)\n",
    "# 2. Supprimer le bruit avec une ouverture\n",
    "# 3. Combler les petits trous avec une fermeture\n",
    "# 4. Comparer le résultat avec et sans traitement morphologique\n",
    "\n",
    "# Votre code ici :\n",
    "# ...\n",
    "\n",
    "afficher_images(\n",
    "    [img_document, img_clean],\n",
    "    ['Originale', 'Nettoyée (morphologie)'],\n",
    "    figsize=(16, 4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7fd883-5647-4283-b5cf-1def2b503b3a",
   "metadata": {},
   "source": [
    "## 6. Comparaison des performances\n",
    "\n",
    "Comparons les temps d'exécution entre OpenCV et scikit-image.\n",
    "\n",
    "Complétez le code ci-dessous qui permet de comparer la réalisation des opérations morphologiques indiquées (en commentaire) par les deux bibliothèques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5c384b-d66d-4fe8-a814-a9929664c808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'une grande image pour les tests de performance\n",
    "img_grande = np.random.randint(0, 256, (1000, 1000), dtype=np.uint8)\n",
    "\n",
    "# Test : Flou gaussien\n",
    "_, t_gauss_cv = mesurer_temps(\n",
    "_, t_gauss_ski = mesurer_temps(\n",
    "\n",
    "# Test : Érosion\n",
    "es_cv = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))\n",
    "es_ski = square(7)\n",
    "_, t_erosion_cv = \n",
    "_, t_erosion_ski =\n",
    "\n",
    "# Test : Sobel\n",
    "_, t_sobel_cv = \n",
    "_, t_sobel_ski = \n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Comparaison des performances (image 1000×1000)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"{'Opération':<20} {'OpenCV (ms)':<15} {'scikit-image (ms)':<15} {'Ratio'}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Gaussien 15×15':<20} {t_gauss_cv:<15.2f} {t_gauss_ski:<15.2f} {t_gauss_ski/t_gauss_cv:.1f}x\")\n",
    "print(f\"{'Érosion 7×7':<20} {t_erosion_cv:<15.2f} {t_erosion_ski:<15.2f} {t_erosion_ski/t_erosion_cv:.1f}x\")\n",
    "print(f\"{'Sobel':<20} {t_sobel_cv:<15.2f} {t_sobel_ski:<15.2f} {t_sobel_ski/t_sobel_cv:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c6ef5c-41df-42a0-83ef-26b91773c6ba",
   "metadata": {},
   "source": [
    "Qu’en concluez-vous ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1b9572-261e-4951-b454-d301d759f5ec",
   "metadata": {},
   "source": [
    "## 7. Exercice récapitulatif : Pipeline complet\n",
    "\n",
    "**Objectif** : Créer un pipeline complet de traitement d'image pour détecter et compter des objets.\n",
    "\n",
    "**Étapes** :\n",
    "1. Charger/créer une image avec plusieurs objets\n",
    "2. Prétraitement : conversion en niveaux de gris, filtrage du bruit\n",
    "3. Segmentation : seuillage (Otsu ou adaptatif)\n",
    "4. Nettoyage morphologique : ouverture/fermeture\n",
    "5. Détection de contours\n",
    "6. Comptage des objets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eabcb08-fba5-4641-ba9b-dfd8ca7147e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creer_image_objets():\n",
    "    \"\"\"Crée une image avec plusieurs objets à compter.\"\"\"\n",
    "    np.random.seed(123)\n",
    "    h, w = 400, 500\n",
    "    img = np.ones((h, w), dtype=np.uint8) * 200  # Fond gris clair\n",
    "    \n",
    "    # Ajout de plusieurs cercles (objets à compter)\n",
    "    centres = [\n",
    "        (80, 80), (80, 200), (80, 350), (80, 450),\n",
    "        (200, 120), (200, 280), (200, 420),\n",
    "        (320, 80), (320, 200), (320, 350), (320, 450),\n",
    "    ]\n",
    "    \n",
    "    for (cy, cx) in centres:\n",
    "        rayon = np.random.randint(25, 40)\n",
    "        for i in range(h):\n",
    "            for j in range(w):\n",
    "                if (i - cy)**2 + (j - cx)**2 < rayon**2:\n",
    "                    img[i, j] = np.random.randint(40, 80)\n",
    "    \n",
    "    # Ajout de bruit\n",
    "    bruit = np.random.normal(0, 15, (h, w))\n",
    "    img = np.clip(img + bruit, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    return img, len(centres)\n",
    "\n",
    "img_objets, n_objets_vrai = creer_image_objets()\n",
    "print(f\"Nombre réel d'objets : {n_objets_vrai}\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(img_objets, cmap='gray')\n",
    "plt.title(f'Image avec {n_objets_vrai} objets à détecter')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916b67f9-aafc-493d-9b73-f06b05e2ed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creer_image_objets():\n",
    "    \"\"\"Crée une image avec plusieurs objets à compter, incluant des défauts.\"\"\"\n",
    "    np.random.seed(123)\n",
    "    h, w = 400, 500\n",
    "    img = np.ones((h, w), dtype=np.uint8) * 200  # Fond gris clair\n",
    "    \n",
    "    # Ajout de plusieurs cercles (objets à compter)\n",
    "    centres = [\n",
    "        (80, 80), (80, 200), (80, 350), (80, 450),\n",
    "        (200, 120), (200, 280), (200, 420),\n",
    "        (320, 80), (320, 200), (320, 350), (320, 450),\n",
    "    ]\n",
    "    \n",
    "    for (cy, cx) in centres:\n",
    "        rayon = np.random.randint(25, 40)\n",
    "        for i in range(h):\n",
    "            for j in range(w):\n",
    "                if (i - cy)**2 + (j - cx)**2 < rayon**2:\n",
    "                    img[i, j] = np.random.randint(40, 80)\n",
    "    \n",
    "    # ==========================================================================\n",
    "    # DÉFAUTS : rendent le nettoyage morphologique nécessaire\n",
    "    # ==========================================================================\n",
    "    \n",
    "    # 1. Trous/fissures dans les objets (pixels clairs à l'intérieur)\n",
    "    for (cy, cx) in centres:\n",
    "        # Petits trous aléatoires\n",
    "        n_trous = np.random.randint(3, 7)\n",
    "        for _ in range(n_trous):\n",
    "            ty = cy + np.random.randint(-15, 15)\n",
    "            tx = cx + np.random.randint(-15, 15)\n",
    "            taille = np.random.randint(2, 5)\n",
    "            img[ty-taille:ty+taille, tx-taille:tx+taille] = np.random.randint(180, 220)\n",
    "        \n",
    "        # Fissure horizontale ou verticale\n",
    "        if np.random.random() > 0.5:\n",
    "            # Fissure horizontale\n",
    "            fy = cy + np.random.randint(-10, 10)\n",
    "            img[fy:fy+2, cx-15:cx+15] = np.random.randint(190, 210)\n",
    "        else:\n",
    "            # Fissure verticale\n",
    "            fx = cx + np.random.randint(-10, 10)\n",
    "            img[cy-15:cy+15, fx:fx+2] = np.random.randint(190, 210)\n",
    "    \n",
    "    # 2. Bruit sel (petits points clairs sur les objets)\n",
    "    for _ in range(100):\n",
    "        py, px = np.random.randint(0, h), np.random.randint(0, w)\n",
    "        img[py, px] = np.random.randint(200, 255)\n",
    "    \n",
    "    # 3. Bruit poivre (petits points sombres sur le fond = faux positifs potentiels)\n",
    "    for _ in range(150):\n",
    "        py, px = np.random.randint(0, h), np.random.randint(0, w)\n",
    "        taille = np.random.randint(1, 4)\n",
    "        img[max(0,py-taille):py+taille+1, max(0,px-taille):px+taille+1] = np.random.randint(40, 80)\n",
    "    \n",
    "    # 4. Petits artefacts isolés (petits objets parasites)\n",
    "    for _ in range(20):\n",
    "        ay, ax = np.random.randint(20, h-20), np.random.randint(20, w-20)\n",
    "        rayon_artefact = np.random.randint(3, 8)\n",
    "        for i in range(ay-rayon_artefact, ay+rayon_artefact):\n",
    "            for j in range(ax-rayon_artefact, ax+rayon_artefact):\n",
    "                if (i - ay)**2 + (j - ax)**2 < rayon_artefact**2:\n",
    "                    if 0 <= i < h and 0 <= j < w:\n",
    "                        img[i, j] = np.random.randint(40, 80)\n",
    "    \n",
    "    # Ajout de bruit gaussien global\n",
    "    bruit = np.random.normal(0, 15, (h, w))\n",
    "    img = np.clip(img + bruit, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    return img, len(centres)\n",
    "\n",
    "img_objets, n_objets_vrai = creer_image_objets()\n",
    "print(f\"Nombre réel d'objets : {n_objets_vrai}\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(img_objets, cmap='gray')\n",
    "plt.title(f'Image avec {n_objets_vrai} objets à détecter')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b26a5d-4d66-45fd-877f-b0d4974c965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Implémentez le pipeline complet\n",
    "#\n",
    "# Étape 1 : Filtrage du bruit (gaussien ou médian)\n",
    "# img_filtree = ...\n",
    "#\n",
    "# Étape 2 : Seuillage (Otsu)\n",
    "# img_binaire = ...\n",
    "#\n",
    "# Étape 3 : Nettoyage morphologique\n",
    "# img_clean = ...\n",
    "#\n",
    "# Étape 4 : Détection de contours avec cv2.findContours\n",
    "# contours, _ = cv2.findContours(img_clean, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# n_detectes = \n",
    "#\n",
    "# Étape 5 : Affichage du résultat\n",
    "img_result = cv2.cvtColor(img_objets, cv2.COLOR_GRAY2BGR)\n",
    "cv2.drawContours(img_result, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "# Visualisation du pipeline\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "axes[0, 0].imshow(img_objets, cmap='gray')\n",
    "axes[0, 0].set_title('1. Image originale', fontweight='bold')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(img_filtree, cmap='gray')\n",
    "axes[0, 1].set_title('2. Filtrage médian', fontweight='bold')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[0, 2].imshow(img_binaire, cmap='gray')\n",
    "axes[0, 2].set_title(f'3. Seuillage Otsu (T={seuil_otsu:.0f})', fontweight='bold')\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "axes[1, 0].imshow(img_clean, cmap='gray')\n",
    "axes[1, 0].set_title('4. Nettoyage morphologique', fontweight='bold')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(cv2.cvtColor(img_result, cv2.COLOR_BGR2RGB))\n",
    "axes[1, 1].set_title(f'5. Résultat : {n_detecte} objets', fontweight='bold')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "axes[1, 2].axis('off')\n",
    "statut = \"CORRECT\" if n_detecte == n_objets_vrai else f\"ERREUR ({n_objets_vrai} attendus)\"\n",
    "axes[1, 2].text(0.5, 0.5, f\"Détectés : {n_detecte}\\n\\n{statut}\", \n",
    "                transform=axes[1, 2].transAxes, fontsize=16, ha='center', va='center',\n",
    "                fontweight='bold', color='green' if n_detecte == n_objets_vrai else 'red')\n",
    "\n",
    "plt.suptitle('Pipeline : Détection et comptage d\\'objets', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77e22d5-bfc0-4d2f-bb31-c2a6ee3ee76a",
   "metadata": {},
   "source": [
    "## 8. Résumé et bonnes pratiques\n",
    "\n",
    "### Quand utiliser OpenCV ?\n",
    "\n",
    "- Applications temps réel (vidéo, caméra)\n",
    "- Traitement de grandes images\n",
    "- Besoin de performances maximales\n",
    "- Écosystème vision par ordinateur (détection, tracking...)\n",
    "\n",
    "### Quand utiliser scikit-image ?\n",
    "\n",
    "- Prototypage rapide\n",
    "- Analyse d'images scientifiques\n",
    "- Intégration avec l'écosystème SciPy/NumPy\n",
    "- Code plus lisible et maintenable\n",
    "\n",
    "### Tableau de correspondance des fonctions principales\n",
    "\n",
    "| Opération | OpenCV | scikit-image (à récup dans le bon module)|\n",
    "|-----------|--------|---------------|\n",
    "| Seuillage Otsu | `cv2.threshold(..., cv2.THRESH_OTSU)` | `threshold_otsu()` (filters)|\n",
    "| Seuillage adaptatif | `cv2.adaptiveThreshold()` | `threshold_local()` (filters)|\n",
    "| Flou gaussien | `cv2.GaussianBlur()` | `gaussian()` (filters)|\n",
    "| Filtre médian | `cv2.medianBlur()` | `median()` (filters)|\n",
    "| Sobel | `cv2.Sobel()` | `sobel()` (filters)|\n",
    "| Canny | `cv2.Canny()` | `canny()` (filters)|\n",
    "| Érosion | `cv2.erode()` | `erosion()` (morphology)|\n",
    "| Dilatation | `cv2.dilate()` | `dilation()` (morphology)|\n",
    "| Ouverture | `cv2.morphologyEx(..., MORPH_OPEN)` | `opening()` (morphology)|\n",
    "| Fermeture | `cv2.morphologyEx(..., MORPH_CLOSE)` | `closing()` (morphology)|\n",
    "| Élément structurant | `cv2.getStructuringElement()` | `square()`, `disk()`, `diamond()` (morphology) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba82bd7-f7c6-4957-b19b-7b6cbe6a76cd",
   "metadata": {},
   "source": [
    "**Pour allez plus loin** : \n",
    "\n",
    "* [TP optionnel](Data-Science-05-TP_Detection_Visages_Haar_LFW.ipynb) sur la détection de visage avec OpenCV\n",
    "* [Une collection de Notebooks](https://haesleinhuepf.github.io/BioImageAnalysisNotebooks/intro.html#) de Robert Haase qui montre de nombreuses techniques de traitement d’images biologiques/médicales, de l’affichage au machine learning. Vous pouvez notamment porter attention aux sections « image filtering » et « image segmentation »."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6613b1d2-7da3-4cac-85a7-8f5d40b2d622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
