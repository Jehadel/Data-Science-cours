{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP : Syst√®me de recommandation musicale avec K-means et PCA\n",
    "\n",
    "Dans ce TP, vous allez d√©couvrir comment combiner deux techniques fondamentales du machine learning :\n",
    "- **K-means** : algorithme de clustering pour regrouper des morceaux similaires\n",
    "- **PCA (Analyse en Composantes Principales)** : technique de r√©duction de dimensionnalit√© pour visualiser et am√©liorer le clustering\n",
    "\n",
    "Vous allez construire un syst√®me de recommandation musicale en analysant des caract√©ristiques audio de morceaux Spotify.\n",
    "\n",
    "## Plan du TP\n",
    "\n",
    "1. Exploration des donn√©es\n",
    "2. Premi√®re visualisation 3D de features s√©lectionn√©es\n",
    "3. Premier clustering K-means sur donn√©es brutes\n",
    "4. Am√©lioration avec mise √† l'√©chelle des donn√©es\n",
    "5. Application de la PCA pour r√©duction de dimensionnalit√©\n",
    "6. Clustering optimis√© avec K-means sur les composantes principales\n",
    "7. D√©termination du nombre optimal de clusters\n",
    "8. Cr√©ation de playlists personnalis√©es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import des biblioth√®ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install seaborn==0.13.2\n",
    "#!pip install plotly==6.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Configuration pour de meilleurs graphiques\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement et exploration des donn√©es\n",
    "\n",
    "### 1.1 Chargement du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le dataset - adapter en fonction du dossier o√π vous avez t√©l√©charg√© les donn√©es\n",
    "df = pd.read_csv(os.path.join('data','SpotifyTracksDataset','dataset.csv'))\n",
    "\n",
    "print(f\"Dimensions du dataset : {df.shape}\")\n",
    "print(f\"Nombre de morceaux : {df.shape[0]}\")\n",
    "print(f\"Nombre de colonnes : {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proc√©dez dans un premier temps √† une exploration minimal classique des donn√©es (EDA).\n",
    "Il faudra certainement faire un peu de nettoyage, comme beaucoup de donn√©es t√©l√©charg√©es sur Kaggle, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Aper√ßu des premi√®res lignes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a une colonne `unnamed` qui correspond √† l‚Äôindex visiblement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('Unnamed: 0',drop=True, inplace=True)\n",
    "df.index.name = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Informations sur le dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 V√©rification des valeurs manquantes et doublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Cr√©ation d'un DataFrame avec uniquement les donn√©es num√©riques\n",
    "\n",
    "Pour notre analyse, nous allons nous concentrer sur les features audio quantitatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S√©lection des colonnes num√©riques pertinentes pour l'analyse audio\n",
    "\n",
    "data_num = # VOTRE CODE\n",
    "\n",
    "print(f\"Dimensions des donn√©es num√©riques : {data_num.shape}\")\n",
    "print(f\"\\nFeatures disponibles :\")\n",
    "for i, col in enumerate(data_num.columns, 1):\n",
    "    print(f\"{i}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Statistiques descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Matrice de corr√©lation\n",
    "\n",
    "Analysons les corr√©lations entre les diff√©rentes features audio pour comprendre leurs relations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de la matrice de corr√©lation\n",
    "correlation_matrix = # VOTRE CODE\n",
    "\n",
    "# Visualisation avec une heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Matrice de corr√©lation des features audio Spotify', fontsize=14, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Observations √† noter :\")\n",
    "print(\"- Quelles variables sont fortement corr√©l√©es ?\")\n",
    "print(\"- Y a-t-il des corr√©lations n√©gatives int√©ressantes ?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lisez bien la description de chaque feature sur la page Kaggle pour d‚Äôune part comprendre ces corr√©lations, et d‚Äôautre part s√©lectionnez trois features (pas forc√©ment corr√©l√©es) qu‚Äôil vous semble int√©ressant d‚Äôanalyser de plus pr√®s afin de voir si elles permettraient de regrouper des morceaux ressemblant. Faisons-en une visualisation 3D pour voir comment ces features sont partag√©es.\n",
    "\n",
    "Par exemple danceability, energy, valence ou acousticness, instrumentalness, speechiness ou tout autre combinaison qui vous inspire/interpelle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Premi√®re visualisation 3D avec trois features\n",
    "\n",
    "D√©crivez les 3 features que vous avez choisies :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation 3D des donn√©es brutes\n",
    "fig = px.scatter_3d(data_num, \n",
    "                    x= # VOTRE CODE \n",
    "                    y=# VOTRE CODE\n",
    "                    z=# VOTRE CODE\n",
    "                    opacity=0.7,\n",
    "                    width=800,\n",
    "                    height=700,\n",
    "                    title='Visualisation 3D : Danceability, Energy et Valence (donn√©es brutes)')\n",
    "\n",
    "fig.update_traces(marker=dict(size=3, color='steelblue'))\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nObservation : .\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Premier clustering K-means sur donn√©es brutes\n",
    "\n",
    "### 3.1 Choix du nombre de clusters\n",
    "\n",
    "Utilisons une r√®gle empirique simple : pour N observations, on peut estimer le nombre de clusters optimal √† environ ‚àö(N/2). Mais on va √©viter d‚Äôavoir √† consid√©rer plus de 10 clusters (on se pose une limite dans notre exercice, pour se simplifier la vie, on pourrait aussi limiter le nombre d‚Äôobservations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul du nombre de clusters selon la r√®gle empirique\n",
    "n_samples = len(data_num)\n",
    "k_empirical = int(np.sqrt(n_samples / 2))\n",
    "k_empirical = max(5, min(k_empirical, 10))  # Contraindre entre 5 et 10\n",
    "\n",
    "print(f\"Nombre d'√©chantillons : {n_samples}\")\n",
    "print(f\"Nombre de clusters sugg√©r√© (r√®gle empirique) : {k_empirical}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Application de K-means sur les donn√©es brutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means sur les donn√©es brutes\n",
    "# VOTRE CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Visualisation du clustering sur donn√©es brutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation d'un DataFrame temporaire pour la visualisation\n",
    "df_viz_raw = # VOTRE CODE\n",
    "\n",
    "# Visualisation 3D avec les clusters\n",
    "fig = px.scatter_3d(df_viz_raw,\n",
    "                    x=# VOTRE CODE\n",
    "                    y=# VOTRE CODE\n",
    "                    z=# VOTRE CODE\n",
    "                    color='cluster',\n",
    "                    opacity=0.7,\n",
    "                    width=800,\n",
    "                    height=700,\n",
    "                    title=f'K-means sur donn√©es brutes ({k_empirical} clusters)')\n",
    "\n",
    "fig.update_traces(marker=dict(size=3))\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nConstat : .\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Am√©lioration avec mise √† l'√©chelle des donn√©es\n",
    "\n",
    "### 4.1 Pourquoi scaler les donn√©es ?\n",
    "\n",
    "Les features ont des √©chelles diff√©rentes (ex: duration_ms en millisecondes vs danceability entre 0 et 1). \n",
    "Le K-means utilise la distance euclidienne, donc les features avec de grandes valeurs dominent le calcul.\n",
    "\n",
    "Nous utilisons **RobustScaler** qui est r√©sistant aux outliers (utilise la m√©diane et l'IQR plut√¥t que la moyenne)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mise √† l'√©chelle avec RobustScaler\n",
    "scaler = # VOTRE CODE\n",
    "data_scaled = # VOTRE CODE\n",
    "\n",
    "# Cr√©ation d'un DataFrame pour faciliter l'analyse\n",
    "data_scaled_df = pd.DataFrame(data_scaled, columns=data_num.columns)\n",
    "\n",
    "print(\"Donn√©es mises √† l'√©chelle avec RobustScaler\")\n",
    "print(f\"\\nAper√ßu des donn√©es scal√©es :\")\n",
    "print(data_scaled_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 K-means sur les donn√©es scal√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means sur les donn√©es scal√©es\n",
    "kmeans_scaled = # VOTRE CODE\n",
    "labels_scaled = # VOTRE CODE\n",
    "\n",
    "print(f\"Clustering effectu√© avec {k_empirical} clusters sur donn√©es scal√©es\")\n",
    "print(f\"Inertie : {kmeans_scaled.inertia_:.2f}\")\n",
    "print(f\"\\nR√©partition des morceaux par cluster :\")\n",
    "unique, counts = np.unique(labels_scaled, return_counts=True)\n",
    "for cluster_id, count in zip(unique, counts):\n",
    "    print(f\"  Cluster {cluster_id} : {count} morceaux ({count/len(labels_scaled)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate un gros d√©s√©quilibre dans la taille (nombre de morceaux) des clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Visualisation avec donn√©es scal√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation 3D avec les donn√©es scal√©es\n",
    "\n",
    "# VOTRE CODE\n",
    "\n",
    "print(\"\\nObservation : \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyse en Composantes Principales (PCA)\n",
    "\n",
    "### 5.1 PCA compl√®te pour analyser la variance expliqu√©e\n",
    "\n",
    "Commen√ßons par faire une PCA sur toutes les composantes possibles pour voir combien de variance est captur√©e par chacune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA compl√®te\n",
    "pca_full = # VOTRE CODE\n",
    "# Variance expliqu√©e par chaque composante\n",
    "variance_explained = # VOTRE CODE\n",
    "cumulative_variance = # VOTRE CODE\n",
    "\n",
    "print(\"Variance expliqu√©e par les premi√®res composantes :\")\n",
    "for i in range(min(10, len(variance_explained))):\n",
    "    print(f\"  PC{i+1} : {variance_explained[i]*100:.2f}% (cumul√© : {cumulative_variance[i]*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Graphique de la variance cumul√©e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de la variance expliqu√©e\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Variance par composante (fig ax1)\n",
    "# VOTRE CODE\n",
    "\n",
    "# Variance cumul√©e (fig ax2)\n",
    "# VOTRE CODE\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Trouver le nombre de composantes pour 80% et 90% de variance\n",
    "n_components_80 = # VOTRE CODE\n",
    "n_components_90 = # VOTRE CODE\n",
    "\n",
    "print(f\"\\nR√©sultats :\")\n",
    "print(f\"  ‚Ä¢ Les 3 premi√®res composantes expliquent {cumulative_variance[2]*100:.2f}% de la variance\")\n",
    "print(f\"  ‚Ä¢ Il faut {n_components_80} composantes pour expliquer >80% de la variance\")\n",
    "print(f\"  ‚Ä¢ Il faut {n_components_90} composantes pour expliquer >90% de la variance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 PCA √† 3 composantes pour visualisation\n",
    "\n",
    "Nous allons projeter nos donn√©es sur 3 composantes principales pour pouvoir les visualiser en 3D, de plus elles expliquent quasiment 90% de la variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA √† 3 composantes\n",
    "pca_3d = # VOTRE CODE\n",
    "data_proj = # VOTRE CODE\n",
    "\n",
    "print(f\"PCA effectu√©e : {data_scaled.shape[1]} dimensions ‚Üí 3 composantes principales\")\n",
    "print(f\"\\nVariance expliqu√©e par les 3 composantes :\")\n",
    "for i, var in enumerate(pca_3d.explained_variance_ratio_, 1):\n",
    "    print(f\"  PC{i} : {var*100:.2f}%\")\n",
    "print(f\"\\nVariance totale expliqu√©e : {pca_3d.explained_variance_ratio_.sum()*100:.2f}%\")\n",
    "\n",
    "# Cr√©ation d'un DataFrame pour faciliter l'analyse\n",
    "df_pca = pd.DataFrame(data_proj, columns=['PC1', 'PC2', 'PC3'])\n",
    "print(f\"\\nDimensions des donn√©es projet√©es : {df_pca.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Visualisation des donn√©es dans l'espace PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation 3D dans l'espace PCA\n",
    "fig = # VOTRE CODE\n",
    "fig.update_traces(marker=dict(size=3, color='steelblue'))\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nObservation : La projection PCA r√©v√®le une structure plus √©tal√©e des donn√©es.\")\n",
    "print(\"Les composantes principales capturent les directions de variance maximale.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Analyse des composantes principales\n",
    "\n",
    "Voyons quelles features originales contribuent le plus √† chaque composante principale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation d'un DataFrame des composantes\n",
    "components_df = pd.DataFrame(\n",
    "    pca_3d.components_.T,\n",
    "    columns=['PC1', 'PC2', 'PC3'],\n",
    "    index=data_num.columns\n",
    ")\n",
    "\n",
    "# Visualisation des contributions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for i, pc in enumerate(['PC1', 'PC2', 'PC3']):\n",
    "    # Trier par valeur absolue pour voir les contributions importantes\n",
    "    sorted_features = components_df[pc].abs().sort_values(ascending=True)\n",
    "    colors = ['red' if x < 0 else 'steelblue' for x in components_df.loc[sorted_features.index, pc]]\n",
    "    \n",
    "    axes[i].barh(range(len(sorted_features)), \n",
    "                 components_df.loc[sorted_features.index, pc],\n",
    "                 color=colors, alpha=0.7)\n",
    "    axes[i].set_yticks(range(len(sorted_features)))\n",
    "    axes[i].set_yticklabels(sorted_features.index)\n",
    "    axes[i].set_xlabel('Contribution', fontsize=11)\n",
    "    axes[i].set_title(f'{pc}\\n({pca_3d.explained_variance_ratio_[i]*100:.1f}% variance)', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "    axes[i].axvline(x=0, color='black', linestyle='-', linewidth=0.8)\n",
    "    axes[i].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpr√©tation des composantes principales :\")\n",
    "print(\"\\nPC1 - Principales contributions :\")\n",
    "top_pc1 = components_df['PC1'].abs().sort_values(ascending=False).head(3)\n",
    "for feat, val in top_pc1.items():\n",
    "    print(f\"  ‚Ä¢ {feat}: {components_df.loc[feat, 'PC1']:.3f}\")\n",
    "\n",
    "print(\"\\nPC2 - Principales contributions :\")\n",
    "top_pc2 = components_df['PC2'].abs().sort_values(ascending=False).head(3)\n",
    "for feat, val in top_pc2.items():\n",
    "    print(f\"  ‚Ä¢ {feat}: {components_df.loc[feat, 'PC2']:.3f}\")\n",
    "\n",
    "print(\"\\nPC3 - Principales contributions :\")\n",
    "top_pc3 = components_df['PC3'].abs().sort_values(ascending=False).head(3)\n",
    "for feat, val in top_pc3.items():\n",
    "    print(f\"  ‚Ä¢ {feat}: {components_df.loc[feat, 'PC3']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. K-means optimis√© sur les composantes principales\n",
    "\n",
    "### 6.1 Clustering dans l'espace PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means sur les donn√©es projet√©es PCA\n",
    "\n",
    "# VOTRE CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Visualisation du clustering dans l'espace PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation avec les clusters dans l'espace PCA\n",
    "\n",
    "# VOTRE CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Retour aux features originales\n",
    "\n",
    "Visualisons maintenant ces clusters dans l'espace des features originales que vous avez choisies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des clusters PCA dans l'espace original\n",
    "df_original_clustered = data_num[# les features que vous avez choisies au d√©part ].copy()\n",
    "df_original_clustered['cluster'] = labels_pca.astype(str)\n",
    "\n",
    "# VOTRE CODE (visualisation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. D√©termination du nombre optimal de clusters\n",
    "\n",
    "### 7.1 M√©thode du coude (Elbow method)\n",
    "\n",
    "Testons diff√©rents nombres de clusters et analysons l'inertie (somme des distances au carr√© aux centro√Ødes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de diff√©rents nombres de clusters\n",
    "\n",
    "# VOTRE CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Visualisation de la courbe du coude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphique de l'inertie\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(K_range, inertias, 'o-', linewidth=2, markersize=8, color='steelblue')\n",
    "plt.xlabel('Nombre de clusters (k)', fontsize=12)\n",
    "plt.ylabel('Inertie (somme des distances¬≤)', fontsize=12)\n",
    "plt.title('M√©thode du coude pour d√©terminer le nombre optimal de clusters', fontsize=14, pad=20)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(K_range)\n",
    "\n",
    "# Marquer la position que nous avions choisie arbitrairement\n",
    "plt.axvline(x=k_empirical, color='red', linestyle='--', alpha=0.7, \n",
    "            label=f'Suggestion arbitraire (k={k_empirical})')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nAnalyse de la courbe du coude :\")\n",
    "print(\"Le 'coude' repr√©sente le point o√π ajouter des clusters suppl√©mentaires\")\n",
    "print(\"n'apporte plus d'am√©lioration significative.\")\n",
    "print(\"\\nQuestion : Quel nombre de clusters vous semble optimal ?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Calcul du taux de d√©croissance de l'inertie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Clustering final avec le nombre optimal de clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choisir le nombre final de clusters (vous pouvez modifier cette valeur)\n",
    "k_final = # VOTRE CHOIX\n",
    "\n",
    "print(f\"Nombre final de clusters choisi : {k_final}\")\n",
    "print(\"\\nEntra√Ænement du mod√®le K-means final...\")\n",
    "\n",
    "# K-means final\n",
    "kmeans_final = KMeans(n_clusters=k_final, random_state=42, n_init=10)\n",
    "labels_final = kmeans_final.fit_predict(data_proj)\n",
    "\n",
    "print(f\"\\nClustering final effectu√© avec {k_final} clusters\")\n",
    "print(f\"Inertie finale : {kmeans_final.inertia_:.2f}\")\n",
    "print(f\"\\nR√©partition finale des morceaux par cluster :\")\n",
    "unique, counts = np.unique(labels_final, return_counts=True)\n",
    "for cluster_id, count in zip(unique, counts):\n",
    "    print(f\"  Cluster {cluster_id} : {count} morceaux ({count/len(labels_final)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 Visualisation finale du clustering optimis√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation dans l'espace PCA avec le clustering final\n",
    "\n",
    "# VOTRE CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cr√©ation de playlists personnalis√©es\n",
    "\n",
    "### 8.1 Analyse des caract√©ristiques de chaque cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter les labels de cluster au DataFrame original (nettoy√©)\n",
    "\n",
    "# VOTRE CODE\n",
    "\n",
    "# Calculer les moyennes des features pour chaque cluster (faire un groupby)\n",
    "# VOTRE CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Visualisation des profils de clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S√©lection de features cl√©s pour la visualisation\n",
    "key_features = ['danceability', 'energy', 'valence', 'acousticness', 'instrumentalness', 'tempo']\n",
    "\n",
    "# Normalisation pour la visualisation en radar\n",
    "cluster_profiles_norm = cluster_profiles[key_features].copy()\n",
    "for col in key_features:\n",
    "    if col == 'tempo':\n",
    "        # Normaliser tempo sur [0, 1]\n",
    "        cluster_profiles_norm[col] = (cluster_profiles_norm[col] - cluster_profiles_norm[col].min()) / \\\n",
    "                                      (cluster_profiles_norm[col].max() - cluster_profiles_norm[col].min())\n",
    "\n",
    "# Heatmap des profils de clusters\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(cluster_profiles_norm.T, annot=True, fmt='.2f', cmap='YlOrRd', \n",
    "            cbar_kws={'label': 'Valeur normalis√©e'}, linewidths=0.5)\n",
    "plt.title(f'Profils des {k_final} clusters musicaux', fontsize=14, pad=20)\n",
    "plt.xlabel('Cluster', fontsize=12)\n",
    "plt.ylabel('Features audio', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpr√©tation : Chaque cluster a un profil musical distinct.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Caract√©risation automatique des clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour caract√©riser un cluster\n",
    "def characterize_cluster(cluster_id, profile):\n",
    "    \"\"\"G√©n√®re une description textuelle d'un cluster bas√©e sur ses caract√©ristiques.\"\"\"\n",
    "    characteristics = []\n",
    "    \n",
    "    # Danceability\n",
    "    if profile['danceability'] > 0.7:\n",
    "        characteristics.append(\"tr√®s dansant\")\n",
    "    elif profile['danceability'] > 0.5:\n",
    "        characteristics.append(\"dansant\")\n",
    "    else:\n",
    "        characteristics.append(\"peu dansant\")\n",
    "    \n",
    "    # Energy\n",
    "    if profile['energy'] > 0.7:\n",
    "        characteristics.append(\"√©nergique\")\n",
    "    elif profile['energy'] > 0.5:\n",
    "        characteristics.append(\"mod√©r√©ment √©nergique\")\n",
    "    else:\n",
    "        characteristics.append(\"calme\")\n",
    "    \n",
    "    # Valence\n",
    "    if profile['valence'] > 0.6:\n",
    "        characteristics.append(\"joyeux\")\n",
    "    elif profile['valence'] > 0.4:\n",
    "        characteristics.append(\"neutre\")\n",
    "    else:\n",
    "        characteristics.append(\"m√©lancolique\")\n",
    "    \n",
    "    # Acousticness\n",
    "    if profile['acousticness'] > 0.6:\n",
    "        characteristics.append(\"acoustique\")\n",
    "    elif profile['acousticness'] < 0.3:\n",
    "        characteristics.append(\"√©lectronique\")\n",
    "    \n",
    "    # Instrumentalness\n",
    "    if profile['instrumentalness'] > 0.5:\n",
    "        characteristics.append(\"instrumental\")\n",
    "    \n",
    "    # Tempo\n",
    "    if profile['tempo'] > 140:\n",
    "        characteristics.append(\"rapide\")\n",
    "    elif profile['tempo'] < 90:\n",
    "        characteristics.append(\"lent\")\n",
    "    \n",
    "    return \", \".join(characteristics)\n",
    "\n",
    "# G√©n√©rer les descriptions pour chaque cluster\n",
    "print(\"\\nüéº Caract√©risation des clusters musicaux :\\n\")\n",
    "print(\"=\"*80)\n",
    "for cluster_id in range(k_final):\n",
    "    profile = cluster_profiles.loc[cluster_id]\n",
    "    description = characterize_cluster(cluster_id, profile)\n",
    "    n_songs = (labels_final == cluster_id).sum()\n",
    "    \n",
    "    print(f\"\\nCluster {cluster_id} ({n_songs} morceaux)\")\n",
    "    print(f\"   Style : {description.capitalize()}\")\n",
    "    print(f\"   Caract√©ristiques :\")\n",
    "    print(f\"     ‚Ä¢ Danceability : {profile['danceability']:.2f}\")\n",
    "    print(f\"     ‚Ä¢ Energy       : {profile['energy']:.2f}\")\n",
    "    print(f\"     ‚Ä¢ Valence      : {profile['valence']:.2f}\")\n",
    "    print(f\"     ‚Ä¢ Tempo        : {profile['tempo']:.0f} BPM\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 G√©n√©ration de playlists th√©matiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour cr√©er une playlist √† partir d'un cluster\n",
    "def create_playlist(cluster_id, n_songs=10, seed=None):\n",
    "    \"\"\"Cr√©e une playlist de n_songs morceaux du cluster sp√©cifi√©.\"\"\"\n",
    "    cluster_songs = df_with_clusters[df_with_clusters['cluster'] == cluster_id]\n",
    "    \n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    n_songs = min(n_songs, len(cluster_songs))\n",
    "    playlist = # VOTRE CODE\n",
    "    \n",
    "    return playlist[['track_name', 'artists', 'danceability', 'energy', 'valence', 'tempo']]\n",
    "\n",
    "# Cr√©er des playlists pour quelques clusters\n",
    "print(\"\\nExemples de playlists g√©n√©r√©es :\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for cluster_id in range(min(3, k_final)):  # Afficher les 3 premiers clusters\n",
    "    print(f\"\\nPlaylist du Cluster {cluster_id}\")\n",
    "    playlist = create_playlist(cluster_id, n_songs=5, seed=42)\n",
    "    print(playlist.to_string(index=False))\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5 Syst√®me de recommandation bas√© sur un morceau\n",
    "\n",
    "Cr√©ons une fonction qui recommande des morceaux similaires √† un morceau donn√©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_similar_songs(track_name, n_recommendations=10):\n",
    "    \"\"\"Recommande des morceaux similaires bas√©s sur le m√™me cluster.\"\"\"\n",
    "    # Trouver le morceau\n",
    "    # VOTRE CODE\n",
    "    \n",
    "    # Prendre le premier match\n",
    "    # VOTRE CODE\n",
    "    \n",
    "    # Trouver d'autres morceaux du m√™me cluster\n",
    "    # VOTRE CODE\n",
    "    \n",
    "    # Calculer la distance dans l'espace PCA et les ordonner pour affiner\n",
    "    # VOTRE CODE\n",
    "    \n",
    "    # Retourner les n recommandations\n",
    "    # VOTRE CODE\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Exemple d'utilisation\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Exemple de recommandations\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Choisir un morceau al√©atoire pour la d√©monstration\n",
    "random_track = df['track_name'].sample(1, random_state=42).values[0]\n",
    "recommendations = recommend_similar_songs(random_track, n_recommendations=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.6 Export des playlists\n",
    "\n",
    "Exportons les playlists pour chaque cluster dans des fichiers CSV s√©par√©s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er un r√©pertoire pour les playlists\n",
    "import os\n",
    "os.makedirs('playlists', exist_ok=True)\n",
    "\n",
    "# Exporter chaque cluster dans un fichier CSV\n",
    "for cluster_id in range(k_final):\n",
    "    cluster_songs = df_with_clusters[df_with_clusters['cluster'] == cluster_id]\n",
    "    profile = cluster_profiles.loc[cluster_id]\n",
    "    description = characterize_cluster(cluster_id, profile)\n",
    "    \n",
    "    filename = f'playlists/cluster_{cluster_id}_{description.replace(\",\", \"\").replace(\" \", \"_\")}.csv'\n",
    "    cluster_songs.to_csv(filename, index=False)\n",
    "    print(f\"‚úì Playlist du Cluster {cluster_id} export√©e : {filename}\")\n",
    "\n",
    "print(f\"\\n‚úì {k_final} playlists export√©es dans le dossier 'playlists/'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion et perspectives\n",
    "\n",
    "Bien s√ªr nous ne sommes pas au niveau des √©quipes qui ont con√ßu le syst√®me de recommandation de Spotify, Deezer ou de Youtube. Notre √©chantillon √©tait r√©duit et nous nous sommes volontairement limit√© dans notre clustering etc. mais la logique √©tait l√†.\n",
    "\n",
    "### Ce que vous avez appris\n",
    "\n",
    "1. **K-means sur donn√©es brutes** : Performance limit√©e car les features ont des √©chelles diff√©rentes\n",
    "\n",
    "2. **Mise √† l'√©chelle** : Am√©lioration modeste mais importante pour √©galiser l'influence des features\n",
    "\n",
    "3. **PCA + K-means** : Combinaison puissante qui :\n",
    "   - R√©duit la dimensionnalit√© tout en conservant l'information essentielle\n",
    "   - R√©v√®le la structure sous-jacente des donn√©es\n",
    "   - Am√©liore significativement la qualit√© du clustering\n",
    "\n",
    "4. **M√©thode du coude** : Permet de d√©terminer (plus ou moins) objectivement le nombre optimal de clusters. Notre tentative d‚Äôautomatiser compl√®tement le processus de s√©lection via le taux d‚Äôaccroissement et le calcul de la d√©riv√© seconde ne fonctionnait pas totalement dans ce contexte limit√©, mais elle est √† conna√Ætre.\n",
    "\n",
    "### Applications pratiques\n",
    "\n",
    "Ce syst√®me de recommandation peut √™tre utilis√© pour :\n",
    "- G√©n√©rer des playlists automatiques coh√©rentes\n",
    "- Sugg√©rer de nouveaux morceaux similaires aux go√ªts d'un utilisateur\n",
    "- Organiser une biblioth√®que musicale par style/ambiance\n",
    "- Cr√©er des transitions fluides dans des DJ sets\n",
    "\n",
    "### Pour aller plus loin\n",
    "\n",
    "1. **Tester d'autres algorithmes** : DBSCAN, Hierarchical Clustering, GMM\n",
    "2. **Incorporer des donn√©es suppl√©mentaires** : genre musical, ann√©e de sortie, paroles\n",
    "3. **Utiliser des m√©triques d'√©valuation** : Silhouette Score, Davies-Bouldin Index\n",
    "4. **Cr√©er un syst√®me hybride** : combiner clustering et collaborative filtering\n",
    "5. **Interface utilisateur** : d√©velopper une application web interactive\n",
    "\n",
    "### Exercices compl√©mentaires\n",
    "\n",
    "1. Comparez les r√©sultats avec diff√©rents scalers (StandardScaler, MinMaxScaler)\n",
    "2. Testez la PCA avec un nombre diff√©rent de composantes\n",
    "3. Analysez les morceaux mal class√©s (outliers)\n",
    "4. Cr√©ez des playlists th√©matiques (sport, d√©tente, f√™te, travail)\n",
    "5. Impl√©mentez une fonction de \"d√©couverte\" qui sugg√®re des morceaux de clusters adjacents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. √Ä vous de jouer !\n",
    "\n",
    "Utilisez les cellules ci-dessous pour exp√©rimenter et cr√©er vos propres playlists personnalis√©es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cellule d'exp√©rimentation libre\n",
    "# Testez vos propres recommandations ici !\n",
    "\n",
    "# Exemple : recommander_similar_songs(\"votre_morceau_pr√©f√©r√©\", n_recommendations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ez votre propre playlist personnalis√©e en m√©langeant plusieurs clusters\n",
    "# Exemple : combiner des morceaux √©nergiques et joyeux\n",
    "\n",
    "# custom_playlist = pd.concat([\n",
    "#     create_playlist(cluster_1, n_songs=5),\n",
    "#     create_playlist(cluster_2, n_songs=5)\n",
    "# ])\n",
    "# print(custom_playlist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
