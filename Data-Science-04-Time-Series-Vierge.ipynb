{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb31964c-242c-4aa2-8692-fabd5e60a8ab",
   "metadata": {},
   "source": [
    "# Data Science 4 : Séries temporelles (times series)\n",
    "\n",
    "Enseignant : Jean Delpech\n",
    "\n",
    "Cours : Data Science\n",
    "\n",
    "Classe : M1 Data/IA\n",
    "\n",
    "Année scolaire : 2025/2026\n",
    "\n",
    "Dernière mise à jour : janvier 2026\n",
    "\n",
    "## Module Data Science M1 - Séances 11 & 12\n",
    "\n",
    "**Objectifs du cours :**\n",
    "- Comprendre les concepts fondamentaux des séries temporelles\n",
    "- Maîtriser la stationnarité et ses tests\n",
    "- Implémenter et évaluer des modèles ARIMA\n",
    "- Étendre aux modèles SARIMA pour les séries saisonnières"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36a9c43-b792-4645-b4d6-d29bc317cce3",
   "metadata": {},
   "source": [
    "## Remarques préliminaires\n",
    "\n",
    "Comme les images, les séries temporelles sont des données assez particulières, qui demandent un traitement et une approche spécifique (par rapport à une donnée qualitative ou numérique simple). C’est la raison pourquoi on les aborde dans ce module de data science, afin de vous familiariser avec la méthodologie employée pour manipuler et analyser ce type de données.\n",
    "\n",
    "C’est un type de données avec une logique assez singulière. Elles sont issues de mesures réalisées à intervalle régulier, par exemple un relevé de température prise toutes les heures au même endroit (station météo d’une ville), ou encore le chiffre d’affaire réalisé chaque jour à la fermeture par une enseigne, le débit horaire d’un cours d’eau, ou enfin le cours d’une action en bourse. La caractéristique principale de ces données liée à une temporalité est que leur ordre est important, en fait ces données sont liées les unes aux autres (la valeur d’une mesure à un instant $t$ est lié à la valeur de la même mesure à l’instant $t-1$, $t-2$, etc.). C’est d’ailleurs ce que l’on va chercher à prédire : la température à partir des températures passées, le cours de bourse à partir du cours passé, le débit d’un cours d’eau à partir du débit passé, etc. Mais dans un contexte où les valeurs observées sont fortement corrélées les unes avec les autres – la valeur à $t$ dépend de (= est corrélée) la mesure à $t-1$ – les modèles utilisés classiquement (régression, etc.) ne sont pas suffisants pour être utilisés tels quels et réaliser des prédictions sur ce type de données.\n",
    "\n",
    "Les modèles spécifiques aux séries temporelles reposent sur des opérations de bases et des concept tout aussi spécifiques de ce champ d’analyse : décomposition (tendance, saisonnalité, etc.), sationnarité et enfin auto-corrélation. Ces mots doivent vous faire sentir que nous nous lançons dans l’exploration d’un monde qui a ses propres règles. L’objectif de ce cours est avant tout de vous équiper des concepts qui guident les analyses, le prétraitement et la création de modèles. Nous apprendrons à utiliser la bibliothèque `statsmodels` pour l’analyse des séries temporelles, mais vous aurez tout le loisir dans les autres modules et par votre travail personnel d’approfondir l’usage des bibliothèques python. Profitez donc du cours en présentiel pour poser toutes les questions liées à la compréhension de la démarche plutôt qu’au code !\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d94b0ec-f569-4888-a653-8ae8903af9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des bibliothèques (si nécessaire)\n",
    "# !pip install numpy pandas matplotlib seaborn statsmodels yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bb8945-94e3-4886-a694-e80b07ed6002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Bibliothèques pour les séries temporelles\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.datasets import get_rdataset\n",
    "\n",
    "# pour le calcul de métriques\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924df5ca-8a8e-43f8-b56c-98916ff6e8ad",
   "metadata": {},
   "source": [
    "## 1. Introduction aux Séries Temporelles\n",
    "\n",
    "### 1.1 Qu'est-ce qu'une série temporelle ?\n",
    "\n",
    "Une **série temporelle** est une séquence de données observées à des intervalles de temps réguliers.\n",
    "\n",
    "#### Définition formelle\n",
    "\n",
    "Une série temporelle est une suite d'observations $(y_1, y_2, ..., y_T)$ indexées par le temps $t = 1, 2, ..., T$.\n",
    "\n",
    "#### Caractéristiques principales\n",
    "\n",
    "1. **Ordre temporel** : l'ordre des observations est crucial (contrairement aux données tabulaires classiques)\n",
    "2. **Dépendance temporelle** : les valeurs successives sont souvent corrélées\n",
    "3. **Intervalles réguliers** : les observations sont espacées de manière uniforme\n",
    "\n",
    "#### Exemples d'applications\n",
    "\n",
    "- **Finance** : cours boursiers, taux de change, prix des matières premières\n",
    "- **Météorologie** : températures, précipitations, pression atmosphérique\n",
    "- **Ventes** : chiffre d'affaires mensuel, demande de produits\n",
    "- **Santé** : nombre de patients, épidémiologie\n",
    "- **Transport** : trafic routier, nombre de passagers\n",
    "- **Énergie** : consommation électrique, production renouvelable\n",
    "\n",
    "### 1.2 Les composantes d'une série temporelle\n",
    "\n",
    "Une série temporelle peut être décomposée en plusieurs composantes :\n",
    "\n",
    "#### 1.2.1 **Tendance (Trend)** - $T_t$\n",
    "- Mouvement à long terme de la série\n",
    "- Croissante, décroissante ou stable\n",
    "- Exemple : augmentation progressive des ventes d'une entreprise\n",
    "\n",
    "##### Construction d’un exemple d’illustration :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b049759-265c-4191-9c86-a20e6ffd80d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'une série temporelle simple avec Pandas\n",
    "dates = pd.date_range(start='2020-01-01', end='2023-12-31', freq='D')\n",
    "np.random.seed(42)\n",
    "\n",
    "# Série avec tendance et bruit\n",
    "tendance = np.linspace(100, 200, len(dates))\n",
    "bruit = np.random.normal(0, 10, len(dates))\n",
    "valeurs = tendance + bruit\n",
    "\n",
    "serie_simple = pd.Series(valeurs, index=dates, name='Valeur')\n",
    "\n",
    "# Affichage des premières valeurs\n",
    "print(\"Premières valeurs de la série :\")\n",
    "print(serie_simple.head(10))\n",
    "print(f\"\\nNombre d'observations : {len(serie_simple)}\")\n",
    "print(f\"Période : de {serie_simple.index.min()} à {serie_simple.index.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8d27b7-4f14-4079-a83f-7a4a283ea81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(serie_simple, linewidth=1, alpha=0.8)\n",
    "plt.title('Exemple de Série Temporelle avec Tendance', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Valeur', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a25da0a-ea6b-466e-9df7-e7499d7f2940",
   "metadata": {},
   "source": [
    "##### Exemple (données rééelles) :\n",
    "\n",
    "\n",
    "#### 1.2.2 **Saisonnalité (Seasonality)** - $S_t$\n",
    "- Variations régulières qui se répètent à intervalles fixes\n",
    "- Période : annuelle, trimestrielle, mensuelle, hebdomadaire, journalière\n",
    "- Exemple : pics de ventes en décembre (Noël)\n",
    "\n",
    "##### Construction d’un exemple d’illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da38b6b4-9297-4361-be34-264e0004cd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création de données de température simulées (journalières)\n",
    "np.random.seed(42)\n",
    "dates_temp = pd.date_range(start='2018-01-01', end='2023-12-31', freq='D')\n",
    "\n",
    "# Température avec composantes saisonnières\n",
    "jours = np.arange(len(dates_temp))\n",
    "temperature_moyenne = 15  # Température moyenne\n",
    "amplitude_saisonniere = 10  # Amplitude de variation saisonnière\n",
    "saisonnalite = amplitude_saisonniere * np.sin(2 * np.pi * jours / 365.25)\n",
    "tendance_temp = 0.002 * jours  # Légère tendance au réchauffement\n",
    "bruit_temp = np.random.normal(0, 3, len(dates_temp))\n",
    "\n",
    "temperatures = temperature_moyenne + saisonnalite + tendance_temp + bruit_temp\n",
    "serie_temp = pd.Series(temperatures, index=dates_temp, name='Température (°C)')\n",
    "\n",
    "print(\"Statistiques descriptives :\")\n",
    "print(serie_temp.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ce2e68-ea39-4aea-a528-914566b3db87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des températures\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Série complète\n",
    "axes[0].plot(serie_temp, linewidth=0.8, alpha=0.7)\n",
    "axes[0].set_title('Température Journalière (2018-2023)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Température (°C)', fontsize=12)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Zoom sur une année\n",
    "serie_2022 = serie_temp['2022']\n",
    "axes[1].plot(serie_2022, linewidth=1.5, color='orangered')\n",
    "axes[1].set_title('Zoom sur l\\'année 2022', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Date', fontsize=12)\n",
    "axes[1].set_ylabel('Température (°C)', fontsize=12)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc758027-31b3-403d-8e57-9a9e7a9be8f2",
   "metadata": {},
   "source": [
    "##### Exemple (données rééelles) :\n",
    "\n",
    "\n",
    "#### 1.2.3 **Cycle (Cyclical)** - $C_t$\n",
    "- Fluctuations à long terme sans période fixe\n",
    "- Différent de la saisonnalité (pas de période régulière)\n",
    "- Exemple : cycles économiques (expansion/récession)\n",
    "\n",
    "##### Exemple : cycle économique\n",
    "\n",
    "#### 1.2.4 **Résidu / Bruit (Residual/Noise)** - $\\epsilon_t$\n",
    "- Fluctuations aléatoires inemxpliquées\n",
    "- Ce qui reste après avoir enlevé tendance, saisonnalité et cycle\n",
    "\n",
    "### 1.3 Modèles de décomposition\n",
    "\n",
    "**Modèle additif** : $Y_t = T_t + S_t + \\epsilon_t$\n",
    "- Utilisé quand l'amplitude de la saisonnalité est constante\n",
    "\n",
    "**Modèle multiplicatif** : $Y_t = T_t \\times S_t \\times \\epsilon_t$\n",
    "- Utilisé quand l'amplitude de la saisonnalité varie avec le niveau de la série\n",
    "\n",
    "#### Exemple de création de série avec des composantes identifiables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5532e5-73c0-433a-b3c6-d92683ef7773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'une série temporelle avec composantes distinctes\n",
    "np.random.seed(42)\n",
    "dates_ventes = pd.date_range(start='2018-01-01', end='2023-12-31', freq='MS')  # Début de mois\n",
    "n = len(dates_ventes)\n",
    "\n",
    "# 1. Tendance : croissance linéaire\n",
    "tendance = np.linspace(1000, 2000, n)\n",
    "\n",
    "# 2. Saisonnalité : pic en décembre (Noël), creux en février\n",
    "mois = np.array([date.month for date in dates_ventes])\n",
    "saisonnalite = 200 * np.sin(2 * np.pi * mois / 12) + 150 * (mois == 12)\n",
    "\n",
    "# 3. Résidu : bruit aléatoire\n",
    "residus = np.random.normal(0, 50, n)\n",
    "\n",
    "# Série complète (modèle additif)\n",
    "ventes = tendance + saisonnalite + residus\n",
    "serie_ventes = pd.Series(ventes, index=dates_ventes, name='Ventes mensuelles')\n",
    "\n",
    "print(f\"Série de ventes mensuelles créée : {len(serie_ventes)} observations\")\n",
    "print(f\"Période : {serie_ventes.index.min()} à {serie_ventes.index.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a045099-1752-4957-9fda-1e3ca593ea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de la série et de ses composantes\n",
    "fig, axes = plt.subplots(4, 1, figsize=(14, 12))\n",
    "\n",
    "# Série complète\n",
    "axes[0].plot(serie_ventes, linewidth=2, color='navy')\n",
    "axes[0].set_title('Série Complète (Ventes Mensuelles)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Ventes', fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Tendance\n",
    "axes[1].plot(dates_ventes, tendance, linewidth=2, color='green', label='Tendance')\n",
    "axes[1].set_title('Composante : Tendance', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Tendance', fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Saisonnalité\n",
    "axes[2].plot(dates_ventes, saisonnalite, linewidth=2, color='orange', label='Saisonnalité')\n",
    "axes[2].set_title('Composante : Saisonnalité', fontsize=14, fontweight='bold')\n",
    "axes[2].set_ylabel('Saisonnalité', fontsize=11)\n",
    "axes[2].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "# Résidus\n",
    "axes[3].plot(dates_ventes, residus, linewidth=1, color='red', alpha=0.7, label='Résidus')\n",
    "axes[3].set_title('Composante : Résidus (Bruit)', fontsize=14, fontweight='bold')\n",
    "axes[3].set_xlabel('Date', fontsize=11)\n",
    "axes[3].set_ylabel('Résidus', fontsize=11)\n",
    "axes[3].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[3].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35658c15-ea26-4855-aa41-d59e476c21f4",
   "metadata": {},
   "source": [
    "### 1.4 Décomposition automatique avec statsmodels\n",
    "\n",
    "La bibliothèque `statsmodels` propose une fonction `seasonal_decompose` qui décompose automatiquement une série temporelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a928fc7-e332-44a3-ba16-c61778635163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Décomposition de la série de ventes\n",
    "decomposition = seasonal_decompose(serie_ventes, model='additive', period=12)\n",
    "\n",
    "# Visualisation de la décomposition\n",
    "fig, axes = plt.subplots(4, 1, figsize=(14, 12))\n",
    "\n",
    "# Série observée\n",
    "decomposition.observed.plot(ax=axes[0], color='navy', linewidth=2)\n",
    "axes[0].set_ylabel('Observé', fontsize=11)\n",
    "axes[0].set_title('Décomposition de la Série Temporelle', fontsize=16, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Tendance\n",
    "decomposition.trend.plot(ax=axes[1], color='green', linewidth=2)\n",
    "axes[1].set_ylabel('Tendance', fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Saisonnalité\n",
    "decomposition.seasonal.plot(ax=axes[2], color='orange', linewidth=2)\n",
    "axes[2].set_ylabel('Saisonnalité', fontsize=11)\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "# Résidus\n",
    "decomposition.resid.plot(ax=axes[3], color='red', linewidth=1, alpha=0.7)\n",
    "axes[3].set_ylabel('Résidus', fontsize=11)\n",
    "axes[3].set_xlabel('Date', fontsize=11)\n",
    "axes[3].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951487a4-ee30-430c-b764-800e65a49d92",
   "metadata": {},
   "source": [
    "### Important !!!\n",
    "\n",
    "1. **La décomposition permet de mieux comprendre la structure de la série**\n",
    "2. **Le choix entre modèle additif et multiplicatif dépend des données**\n",
    "3. **Le paramètre `period` doit correspondre à la fréquence de la saisonnalité** (12 pour mensuel avec saisonnalité annuelle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251386cf-2694-4fb5-a44a-48709d2743d2",
   "metadata": {},
   "source": [
    "### EXERCICE 1 : Analyse exploratoire d'une série temporelle\n",
    "\n",
    "**Objectif** : Créer, visualiser et décomposer une série temporelle\n",
    "\n",
    "**Consigne** : \n",
    "1. Créez une série temporelle mensuelle de consommation électrique sur 5 ans (2019-2023)\n",
    "2. La série doit avoir :\n",
    "   - Une tendance croissante (augmentation de 5% par an)\n",
    "   - Une saisonnalité annuelle (pics en été et hiver, creux au printemps/automne)\n",
    "   - Du bruit aléatoire\n",
    "3. Visualisez la série\n",
    "4. Décomposez-la avec `seasonal_decompose`\n",
    "5. Analysez chaque composante (vérifiez qu’on retrouve bien les valeurs qui ont servi à créer la série).\n",
    "6. Testez différentes valeurs du paramètre `period`. Que se passe-t-il ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d4b88d-1279-43a1-bd02-95331add824b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCICE 1 - VPTRE CODE !\n",
    "\n",
    "# 1. Création des dates\n",
    "# dates_elec = ...\n",
    "\n",
    "# 2. Création des composantes\n",
    "# tendance_elec = ...\n",
    "# saisonnalite_elec = ...\n",
    "# bruit_elec = ...\n",
    "\n",
    "# 3. Série complète\n",
    "# serie_elec = ...\n",
    "\n",
    "# 4. Visualisation\n",
    "# ...\n",
    "\n",
    "# 5. Décomposition\n",
    "# decomposition_elec = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01b0b7c-bd0b-475e-aaae-48c9397588e6",
   "metadata": {},
   "source": [
    "## 2. Stationnarité\n",
    "\n",
    "### 2.1 Définition de la stationnarité\n",
    "\n",
    "Une série temporelle est dite **stationnaire** si ses propriétés statistiques ne changent pas au cours du temps.\n",
    "\n",
    "#### Stationnarité faible (ou au second ordre)\n",
    "\n",
    "Une série $\\{Y_t\\}$ est stationnaire au second ordre si :\n",
    "\n",
    "1. **Moyenne constante** : $E[Y_t] = \\mu$ pour tout $t$\n",
    "2. **Variance constante** : $Var(Y_t) = \\sigma^2$ pour tout $t$\n",
    "3. **Covariance dépendant uniquement du décalage** : $Cov(Y_t, Y_{t+h}) = \\gamma(h)$ (ne dépend que de $h$, pas de $t$)\n",
    "\n",
    "#### Pourquoi la stationnarité est-elle importante ?\n",
    "\n",
    "- Une série stationnaire a des propriétés statistiques prévisibles\n",
    "- Cette prévisibilité permet de construire des modèles ARIMA que nous allons utiliser pour analyser une certaine catégorie de séries dont une propriété est d’être **stationnaires** (il faut donc être capable de déterminer si la série remplie cette condition ou non)\n",
    "- Les inférences statistiques sont plus fiables sur des données stationnaires\n",
    "\n",
    "#### Séries non-stationnaires typiques\n",
    "\n",
    "- **Tendance** : moyenne qui évolue dans le temps\n",
    "- **Saisonnalité** : patterns réguliers qui se répètent\n",
    "- **Variance changeante** : hétéroscédasticité (ex : volatilité croissante)\n",
    "- **Marche aléatoire** (Random Walk) : $Y_t = Y_{t-1} + \\epsilon_t$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba223cb5-9c2b-4680-be34-1a5d2e894b51",
   "metadata": {},
   "source": [
    "### 2.2 Exemples de séries stationnaires et non-stationnaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf0c2e7-4ee1-4b0a-ab09-e8dfea9a3b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création de différentes séries pour illustrer la stationnarité\n",
    "np.random.seed(42)\n",
    "n = 500\n",
    "\n",
    "# 1. Bruit blanc (White Noise) - STATIONNAIRE\n",
    "bruit_blanc = np.random.normal(0, 1, n)\n",
    "\n",
    "# 2. Série avec tendance - NON STATIONNAIRE\n",
    "tendance_lineaire = np.linspace(0, 10, n) + np.random.normal(0, 0.5, n)\n",
    "\n",
    "# 3. Marche aléatoire (Random Walk) - NON STATIONNAIRE\n",
    "marche_aleatoire = np.cumsum(np.random.normal(0, 1, n))\n",
    "\n",
    "# 4. Processus AR(1) stationnaire : Y_t = 0.5 * Y_{t-1} + epsilon_t\n",
    "ar1_stationnaire = [0]\n",
    "for i in range(1, n):\n",
    "    ar1_stationnaire.append(0.5 * ar1_stationnaire[-1] + np.random.normal(0, 1))\n",
    "ar1_stationnaire = np.array(ar1_stationnaire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8479af-500a-416e-8a03-72b005b555c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation comparative\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "fig.suptitle('Comparaison : Séries Stationnaires vs Non-Stationnaires', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "\n",
    "# Bruit blanc - Stationnaire\n",
    "axes[0, 0].plot(bruit_blanc, linewidth=1, color='green', alpha=0.7)\n",
    "axes[0, 0].set_title('Bruit Blanc (Stationnaire)', fontsize=13, fontweight='bold', color='green')\n",
    "axes[0, 0].axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "axes[0, 0].set_ylabel('Valeur', fontsize=11)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Tendance - Non stationnaire\n",
    "axes[0, 1].plot(tendance_lineaire, linewidth=1, color='red', alpha=0.7)\n",
    "axes[0, 1].set_title('Série avec Tendance (Non-Stationnaire)', fontsize=13, fontweight='bold', color='red')\n",
    "axes[0, 1].set_ylabel('Valeur', fontsize=11)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Marche aléatoire - Non stationnaire\n",
    "axes[1, 0].plot(marche_aleatoire, linewidth=1, color='red', alpha=0.7)\n",
    "axes[1, 0].set_title('Marche Aléatoire (Non-Stationnaire)', fontsize=13, fontweight='bold', color='red')\n",
    "axes[1, 0].set_xlabel('Temps', fontsize=11)\n",
    "axes[1, 0].set_ylabel('Valeur', fontsize=11)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# AR(1) - Stationnaire\n",
    "axes[1, 1].plot(ar1_stationnaire, linewidth=1, color='green', alpha=0.7)\n",
    "axes[1, 1].set_title('Processus AR(1) avec φ=0.5 (Stationnaire)', fontsize=13, fontweight='bold', color='green')\n",
    "axes[1, 1].axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "axes[1, 1].set_xlabel('Temps', fontsize=11)\n",
    "axes[1, 1].set_ylabel('Valeur', fontsize=11)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d133cbb9-87d8-490b-984c-6fed41195b69",
   "metadata": {},
   "source": [
    "#### Récapitulatif\n",
    "\n",
    "**Séries stationnaires** (bruit blanc, AR(1) avec |φ| < 1) :\n",
    "- Oscillent autour d'une moyenne constante\n",
    "- Variance stable\n",
    "- Pas de tendance visible\n",
    "\n",
    "**Séries non-stationnaires** (tendance, marche aléatoire) :\n",
    "- Moyenne qui évolue dans le temps\n",
    "- Peuvent s'éloigner indéfiniment de leur point de départ\n",
    "- Pattern de \"dérive\" visible\n",
    "\n",
    "Comment teste-t-on l’hypothèse de stationarité ? (on ne peut évidemment pas se contenter de juger « à l’œil »)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdb7b47-d76f-4963-9171-b3272a925756",
   "metadata": {},
   "source": [
    "### 2.3 Test de stationnarité : Test ADF (Augmented Dickey-Fuller)\n",
    "\n",
    "#### Principe du test ADF\n",
    "\n",
    "##### Version courte :\n",
    "\n",
    "Le test ADF teste l'hypothèse nulle de **présence d'une racine unitaire** (série non-stationnaire).\n",
    "\n",
    "**Hypothèses** :\n",
    "- $H_0$ : La série possède une racine unitaire (non-stationnaire)\n",
    "- $H_1$ : La série est stationnaire\n",
    "\n",
    "**Interprétation** :\n",
    "- Si la **p-value < 0.05** : on rejette $H_0$ → la série est **stationnaire**\n",
    "- Si la **p-value ≥ 0.05** : on ne peut pas rejeter $H_0$ → la série est **non-stationnaire**\n",
    "\n",
    "##### Version détaillée (si vous voulez comprendre) :\n",
    "\n",
    "\n",
    "**Qu'est-ce qu'une racine unitaire ?**\n",
    "\n",
    "Avant d'expliquer le test ADF, il est essentiel de comprendre le concept de **racine unitaire**.\n",
    "Mais auparavant, revenons au concept de processus autorégressif.\n",
    "\n",
    "*Définition mathématique*\n",
    "\n",
    "Reprenons la définition d’un [processus autorégressif](https://fr.wikipedia.org/wiki/Processus_autor%C3%A9gressif) d’ordre $p$ :\n",
    "\n",
    "$$\n",
    "AR(p): Y_t = c + \\phi_1 Y_{t-1} + \\phi_2 Y_{t-2}  + … + \\phi_p Y_{t-p} + \\varepsilon_t\n",
    "$$\n",
    "\n",
    "où $\\varepsilon_t$ est un bruit blanc.\n",
    "\n",
    "Considérons un processus autorégressif simple d'ordre 1 (noté AR(1)). Il s’agit d’un processus qui utilise seulement la valeur précédente (t-1) pour prédire la valeur actuelle (t) :\n",
    "\n",
    "$$Y_t = c + \\phi Y_{t-1} + \\varepsilon_t$$\n",
    "\n",
    "La valeur de $\\phi$ est capitale : elle va déterminer le comportement de la série,\n",
    "\n",
    "$$\n",
    "\\begin{cases} \n",
    "|\\rho| <1 & \\text{Processus stationnaire}\\\\\n",
    "|\\rho| =1 &  \\text{Processus non-stationnaire : marche aléatoire}\\\\\n",
    "|\\rho| >1 & \\text{Processus non-stationnaire (explosif)}\\end{cases}\n",
    "$$\n",
    "\n",
    "Pourquoi ?\n",
    "\n",
    "Imaginons la progression de la série après plusieurs séquences :\n",
    "\n",
    "$$\n",
    "Y_t = \\phi Y_{t−1} + \\varepsilon_t \\\\\n",
    "Y_t = \\phi (\\phi Y_{t−2} + \\varepsilon_{t-1}) + \\varepsilon_t \\\\\n",
    "Y_t = \\phi (\\phi (\\phi (Y_{t−3} + \\varepsilon_{t-2}) + \\varepsilon_{t-1}) + \\varepsilon_t \\\\\n",
    "Y_t = \\phi^3 Y_{t−3} + \\phi^2 \\varepsilon_{t-2} + \\phi \\varepsilon_{t-1} + \\varepsilon_t\n",
    "$$\n",
    "\n",
    "On voit le motif qui se dessine et suggère la formule pour toute séquence depuis une origine $t=0$ :\n",
    "$$\n",
    "Y_t = \\phi^t Y_0 \\sum_{i=0}+^{t-1} \\phi^i \\varepsilon_{t-i}\n",
    "$$\n",
    "\n",
    "Qui montre immédiatement la nature exponentielle du phénomène :\n",
    "\n",
    "* Si $\\phi < 1$, on constate que le terme $\\phi^t Y_0\n",
    " \\rightarrow 0$ quand $t \\rightarrow \\infty$ (car $|\\phi| < 1$), donc l'influence de la condition initiale $Y_0$ disparaît avec le temps (c’est ce que l’on appelle la partie transitoire). Il ne reste que l'influence du bruit blanc (ce que l’on appelle la partie permanente). Mais ATTENTION, ça ne veut pas dire que la relation $Y_t = \\phi Y_{t−1} + \\varepsilon_t$ s’arrête, cette loi est toujours valable à chaque instant. Par contre, cela veut dire que l’influence à long terme des séquences passées s’évanouit exponentiellement : seuls le passé (très) récent a réellement une influence. On peut démontre (mais cela demande des caculs et des concepts en probabilité/statistiques un peu plus avancés) que dans ce cas la variance est constante (ne dépend pas de $t$), que la moyenne est aussi constante, et que si la série s’éloigne de cette moyenne, il y aura comme une « force de rappel » qui l’y ramènera. \n",
    "\n",
    "* Si $\\phi$ > 1 on a bien une explosion de la valeur de la série avec le temps. En effet, supposons que $/phi=1,2$ :\n",
    "    * si $t=1, \\phi^1 = 1,2$\n",
    "    * si $t=10, \\phi^10 \\approx 6,2$\n",
    "    * si $t=20, \\phi^20 \\approx 38$\n",
    "    * si $t=50, \\phi^50 \\approx 9100$ \n",
    "    avec une telle évolution, il est évident que cette série ne saurait être stationnaire. De plus, la variance tend aussi très rapidement vers l’infini (évolution proportionnelle à $\\phi^2t$). (Cf. [la page wikipedia](https://fr.wikipedia.org/wiki/Processus_autor%C3%A9gressif) pour la formule de la variance)\n",
    "\n",
    "* Si $\\phi = 1$, on dit que la série possède une **racine unitaire**.\n",
    "\n",
    "    Dans ce cas particulier, le processus devient :\n",
    "\n",
    "    $$Y_t = Y_{t-1} + \\varepsilon_t$$\n",
    "\n",
    "    C'est ce qu'on appelle une **marche aléatoire continue** (*continuous random walk*).\n",
    "    Nous avons vu précédemment qu’un tel processus n’est pas stationnaire non plus.\n",
    "\n",
    ">    *Pourquoi parle-t-on de \"racine unitaire\" ?*\n",
    ">\n",
    ">    Le terme vient de l'analyse de l'équation caractéristique du processus AR(1). On peut écrire l’équation d’un processus autorégressif en faisant appel à un opérateur de retard (*lag operator*) :\n",
    ">$$\n",
    "AR(p): Y_t = c + \\phi_1 Y_{t-1} + \\phi_2 Y_{t-2}  + … + \\phi_p Y_{t-p} + \\varepsilon_t \\\\\n",
    "(1- \\varphi_1 L-\\varphi_2 L^2-\\ldots-\\varphi_p L^p) Y_t = c + \\varepsilon_t \n",
    "$$\n",
    ">\n",
    ">En définissant l’opérateur de retard  ainsi: $L Y_t = Y_{t-1}$ >\n",
    ">\n",
    ">Cet opérateur permet d’écrire simplement :\n",
    ">$$\n",
    "L^2 Y_t = L(L Y_t) = L Y_{t-1} = Y_{t-2} \\\\\n",
    "L^3 Y_t = Y_{t-3}\n",
    "$$\n",
    ">etc.\n",
    ">  \n",
    ">Dans le cas d’un $AR(1)$, on obtient :\n",
    ">\n",
    ">$$\n",
    "Y_t = \\phi Y_{t−1} + \\varepsilon_t \\\\\n",
    "Y_t =\\phi L Y_t + \\varepsilon_t \\\\\n",
    "Y_t - \\phi L Y_t = \\varepsilon_t \\\\\n",
    "(1 - \\phi L) Y_t = \\varepsilon_t\n",
    "$$\n",
    ">\n",
    ">En procédant ainsi, on a écrit le processus sous une forme polynomiale.\n",
    ">Le polynôme caractéristique associé à $(1−\\phi L)$ est $\\Phi(z) = 1 - \\phi z$. L'équation caractéristique qui en découle est : $1 - \\phi z = 0$, soit $z = \\frac{1}{\\phi}$\n",
    ">\n",
    ">Si $\\phi = 1$, alors $z = 1$ : la racine de l'équation caractéristique est égale à 1, d'où le terme **racine unitaire**.\n",
    "\n",
    "#### Conséquences de la présence d'une racine unitaire\n",
    "\n",
    "**1. Non-stationnarité**\n",
    "\n",
    "Si $\\phi = 1$, le processus devient :\n",
    "\n",
    "$$Y_t = Y_{t-1} + \\epsilon_t = Y_0 + \\sum_{i=1}^{t} \\epsilon_i$$\n",
    "\n",
    "C'est la somme cumulée des chocs aléatoires depuis l'origine (on par le de « chocs » dans une marche aléatoire – cf. mouvements browniens – il s’agit des changements de directions aléatoires dans la marche à chaque étape).\n",
    "\n",
    "- **Variance** : $Var(Y_t) = t \\sigma^2$ → elle **augmente avec le temps** (non-stationnaire !)\n",
    "- **Moyenne** : dépend de $Y_0$ et des chocs passés\n",
    "- **Mémoire infinie** : un choc $\\epsilon_t$ affecte **toutes** les valeurs futures de manière permanente\n",
    "\n",
    "**2. \"Dérive\" sans retour à la moyenne**\n",
    "\n",
    "Contrairement à un processus stationnaire qui oscille autour d'une moyenne constante :\n",
    "- Une série avec racine unitaire peut **s'éloigner indéfiniment** de son point de départ\n",
    "- Elle n'a **pas de tendance à revenir** vers une valeur moyenne\n",
    "- Les chocs ont un **effet permanent**\n",
    "\n",
    "**3. Comparaison : avec vs sans racine unitaire**\n",
    "\n",
    "| Caractéristique | $\\phi < 1$ (Stationnaire) | $\\phi = 1$ (Racine unitaire) |\n",
    "|-----------------|---------------------------|------------------------------|\n",
    "| Variance | Constante | Croissante avec t |\n",
    "| Retour à la moyenne | Oui | Non |\n",
    "| Effet d'un choc | Transitoire | Permanent |\n",
    "| Prévisibilité | Bonne à long terme | Dégradée à long terme |\n",
    "| Corrélation | Décroît exponentiellement | Persiste |\n",
    "\n",
    "#### Exemple concret : température vs prix d'actions\n",
    "\n",
    "**Température (stationnaire, $\\phi < 1$)** :\n",
    "- Oscillation autour d'une moyenne saisonnière\n",
    "- Une journée anormalement chaude n'affecte pas la température dans 6 mois\n",
    "- Variance stable\n",
    "\n",
    "**Prix d'actions (racine unitaire, $\\phi \\approx 1$)** :\n",
    "- Pas de retour à un \"prix moyen\"\n",
    "- Une hausse de 10€ aujourd'hui affecte le prix dans 6 mois\n",
    "- Variance augmente avec le temps (incertitude croissante)\n",
    "\n",
    "### 2.4 Principe du test ADF (Augmented Dickey-Fuller)\n",
    "\n",
    "Le test ADF est conçu pour **détecter la présence d'une racine unitaire**.\n",
    "\n",
    "#### Formulation mathématique\n",
    "\n",
    "Au lieu de tester directement $\\phi = 1$ dans $Y_t = \\phi Y_{t-1} + \\epsilon_t$, le test ADF reformule le modèle :\n",
    "\n",
    "$$\\Delta Y_t = \\alpha + \\beta t + \\gamma Y_{t-1} + \\sum_{i=1}^{p} \\delta_i \\Delta Y_{t-i} + \\epsilon_t$$\n",
    "\n",
    "où :\n",
    "- $\\Delta Y_t = Y_t - Y_{t-1}$ (première différence)\n",
    "- $\\gamma = \\phi - 1$\n",
    "- $\\alpha$ = constante (*drift* = dérive)\n",
    "- $\\beta t$ = tendance déterministe\n",
    "- Les termes $\\sum_{i=1}^{p} \\delta_i \\Delta Y_{t-i}$ capturent l'autocorrélation d'ordre supérieur\n",
    "\n",
    "**Le test porte sur le coefficient $\\gamma$** :\n",
    "\n",
    "**Hypothèses** :\n",
    "- $H_0$ : $\\gamma = 0$ (équivalent à $\\phi = 1$) → **racine unitaire** → série **non-stationnaire**\n",
    "- $H_1$ : $\\gamma < 0$ (équivalent à $\\phi < 1$) → **pas de racine unitaire** → série **stationnaire**\n",
    "\n",
    "#### Pourquoi H₀ indique la non-stationnarité ?\n",
    "\n",
    "Si $\\gamma = 0$, alors $\\phi = 1$ et le modèle devient :\n",
    "\n",
    "$$\\Delta Y_t = \\alpha + \\beta t + \\sum_{i=1}^{p} \\delta_i \\Delta Y_{t-i} + \\epsilon_t$$\n",
    "\n",
    "Ce qui équivaut à :\n",
    "\n",
    "$$Y_t = Y_{t-1} + \\alpha + \\beta t + \\sum_{i=1}^{p} \\delta_i \\Delta Y_{t-i} + \\epsilon_t$$\n",
    "\n",
    "C'est une **marche aléatoire avec dérive** : la série s'accumule (non-stationnaire).\n",
    "\n",
    "Si $\\gamma < 0$, alors $\\phi < 1$ et le terme $\\gamma Y_{t-1}$ crée une **force de rappel** vers la moyenne, rendant la série stationnaire.\n",
    "\n",
    "#### Statistique de test\n",
    "\n",
    "Le test calcule la **statistique t** du coefficient $\\gamma$ :\n",
    "\n",
    "$$ADF = \\frac{\\hat{\\gamma}}{SE(\\hat{\\gamma})}$$\n",
    "\n",
    "Cette statistique suit une **distribution de Dickey-Fuller** (non standard), avec des valeurs critiques tabulées.\n",
    "\n",
    "**Interprétation** :\n",
    "- Si la statistique ADF est **très négative** (< valeurs critiques) : on rejette $H_0$ → **stationnaire**\n",
    "- Si la statistique ADF est **proche de 0** : on ne peut pas rejeter $H_0$ → **non-stationnaire**\n",
    "\n",
    "#### Utilisation pratique via la p-value\n",
    "\n",
    "En pratique, on utilise la **p-value** associée au test :\n",
    "\n",
    "- Si **p-value < 0.05** : on rejette $H_0$ → la série est **stationnaire**\n",
    "- Si **p-value ≥ 0.05** : on ne peut pas rejeter $H_0$ → la série est **non-stationnaire**\n",
    "\n",
    "#### Pourquoi \"Augmented\" (Augmenté) ?\n",
    "\n",
    "Le test original de Dickey-Fuller simple ne prend pas en compte les autocorrélations d'ordre supérieur.\n",
    "\n",
    "Le test **ADF** ajoute les termes $\\sum_{i=1}^{p} \\delta_i \\Delta Y_{t-i}$ pour :\n",
    "- Capturer les structures AR(p) plus complexes\n",
    "- S'assurer que les résidus $\\epsilon_t$ sont un bruit blanc\n",
    "- Rendre le test plus robuste\n",
    "\n",
    "Le nombre de lags $p$ est généralement choisi automatiquement par le critère AIC.\n",
    "\n",
    "\n",
    "#### Fonction utilitaire pour le test ADF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d220f9b0-94e2-4ef3-b8eb-12554d0820e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stationnarite(serie, nom='Série'):\n",
    "    \"\"\"\n",
    "    Effectue le test ADF et affiche les résultats de manière claire.\n",
    "    \n",
    "    Paramètres:\n",
    "    -----------\n",
    "    serie : array-like\n",
    "        La série temporelle à tester\n",
    "    nom : str\n",
    "        Nom de la série (pour l'affichage)\n",
    "    \n",
    "    Retour:\n",
    "    -------\n",
    "    dict : Résultats du test\n",
    "    \"\"\"\n",
    "    # Supprimer les valeurs NaN\n",
    "    serie_clean = serie.dropna() if isinstance(serie, pd.Series) else pd.Series(serie).dropna()\n",
    "    \n",
    "    # Test ADF\n",
    "    resultat = adfuller(serie_clean, autolag='AIC')\n",
    "    \n",
    "    # Extraction des résultats\n",
    "    statistic = resultat[0]\n",
    "    pvalue = resultat[1]\n",
    "    n_lags = resultat[2]\n",
    "    n_obs = resultat[3]\n",
    "    valeurs_critiques = resultat[4]\n",
    "    \n",
    "    # Affichage formaté\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Test ADF pour : {nom}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Statistique ADF : {statistic:.6f}\")\n",
    "    print(f\"P-value : {pvalue:.6f}\")\n",
    "    print(f\"Nombre de lags utilisés : {n_lags}\")\n",
    "    print(f\"Nombre d'observations : {n_obs}\")\n",
    "    print(f\"\\nValeurs critiques :\")\n",
    "    for seuil, valeur in valeurs_critiques.items():\n",
    "        print(f\"  {seuil}: {valeur:.3f}\")\n",
    "    \n",
    "    # Conclusion\n",
    "    print(f\"\\n{'─'*60}\")\n",
    "    if pvalue < 0.05:\n",
    "        print(f\"CONCLUSION : La série '{nom}' est STATIONNAIRE\")\n",
    "        print(f\"   (p-value = {pvalue:.6f} < 0.05 → on rejette H0)\")\n",
    "    else:\n",
    "        print(f\"CONCLUSION : La série '{nom}' est NON-STATIONNAIRE\")\n",
    "        print(f\"   (p-value = {pvalue:.6f} ≥ 0.05 → on ne rejette pas H0)\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    return {\n",
    "        'statistic': statistic,\n",
    "        'pvalue': pvalue,\n",
    "        'lags': n_lags,\n",
    "        'nobs': n_obs,\n",
    "        'critical_values': valeurs_critiques,\n",
    "        'stationnaire': pvalue < 0.05\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1750f887-521e-4ba1-b544-3271f665598d",
   "metadata": {},
   "source": [
    "#### EXERCICE 2 : test ADF\n",
    "\n",
    "Appliquez le test ADF aux séries générées précédemment. Les conclusions sont elles correctes ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d83f099-f3b6-48f2-a2d8-e0a183e24862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCICE 2 : VOTRE CODE !\n",
    "\n",
    "# Test sur le bruit blanc (devrait être stationnaire)\n",
    "\n",
    "# Test sur la série avec tendance (devrait être non-stationnaire)\n",
    "\n",
    "# Test sur la marche aléatoire (devrait être non-stationnaire)\n",
    "\n",
    "# Test sur le processus AR(1) (devrait être stationnaire)\n",
    "\n",
    "# Test sur notre série de ventes (devrait être non-stationnaire à cause de la tendance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb21bde-1bdb-43fc-81ad-683b18c57dab",
   "metadata": {},
   "source": [
    "## 3. Différenciation et Processus Stochastiques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43527cbb-276d-4bac-ba1a-2dd3e7507fc8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 3.1 : Rendre une série stationnaire par différenciation\n",
    "\n",
    "#### 3.1.1 Principe de la différenciation\n",
    "\n",
    "La **différenciation** est une transformation qui permet de rendre une série non-stationnaire stationnaire en éliminant la tendance.\n",
    "\n",
    "##### Différenciation d'ordre 1\n",
    "\n",
    "$$\\nabla Y_t = Y_t - Y_{t-1}$$\n",
    "\n",
    "On calcule la différence entre chaque observation et la précédente.\n",
    "\n",
    "##### Différenciation d'ordre 2\n",
    "\n",
    "$$\\nabla^2 Y_t = \\nabla Y_t - \\nabla Y_{t-1} = (Y_t - Y_{t-1}) - (Y_{t-1} - Y_{t-2})$$\n",
    "\n",
    "On applique la différenciation deux fois.\n",
    "\n",
    "#### Quand utiliser la différenciation ?\n",
    "\n",
    "- **Tendance linéaire** → différenciation d'ordre 1 suffit généralement\n",
    "- **Tendance quadratique** → différenciation d'ordre 2 peut être nécessaire\n",
    "- **Marche aléatoire** → différenciation d'ordre 1 rend la série stationnaire\n",
    "\n",
    "**Attention** : ne pas sur-différencier ! Cela peut introduire des corrélations artificielles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6933010-2e16-4a01-ba41-fcbed0a3b510",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### 3.1.2 Exemple : Différenciation d'une série avec tendance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d74396-712f-4fcb-a6aa-ba28cfdaab0f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Création d'une série avec tendance forte\n",
    "np.random.seed(42)\n",
    "n = 200\n",
    "temps = np.arange(n)\n",
    "\n",
    "# Série originale : tendance + bruit\n",
    "tendance = 0.5 * temps\n",
    "bruit = np.random.normal(0, 5, n)\n",
    "serie_tendance = tendance + bruit\n",
    "\n",
    "# Conversion en pandas Series\n",
    "dates = pd.date_range(start='2020-01-01', periods=n, freq='D')\n",
    "serie_originale = pd.Series(serie_tendance, index=dates, name='Série originale')\n",
    "\n",
    "print(\"Série avec tendance créée\")\n",
    "print(f\"Observations : {len(serie_originale)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860fbb7a-032a-403f-b2cb-795bc8f5ffb2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test de stationnarité sur la série originale\n",
    "stationnarite_serie_tendance_forte = test_stationnarite(serie_originale, \"Série Originale (avec tendance)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e74aedc-e5c9-4455-8b7c-dcc07fbf31be",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Appliquez une différenciation d’ordre 1 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cf2f76-4773-459c-9224-c327fcf449f4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# VOTRE CODE\n",
    "# attention, le processus de différenciation va faire apparaître des valeurs nulles, \n",
    "# des observations seront perdues -> .dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096ee90c-01e1-4835-8f61-244d50c62513",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Testons la stationnarité :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ae6bdd-6e3e-46fc-b95b-ffc31c3202dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE \n",
    "# Test de stationnarité sur la série différenciée\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479feca9-8d39-430c-86b2-33b776b4d16e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualisation comparative\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Série originale\n",
    "axes[0].plot(serie_originale, linewidth=1.5, color='red', alpha=0.7)\n",
    "axes[0].set_title('Série Originale (Non-Stationnaire)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Valeur', fontsize=12)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Série différenciée\n",
    "axes[1].plot(serie_diff1, linewidth=1.5, color='green', alpha=0.7)\n",
    "axes[1].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[1].set_title('Série Différenciée d\\'ordre 1 (Stationnaire)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Date', fontsize=12)\n",
    "axes[1].set_ylabel('Différence', fontsize=12)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4684dfa2-7d28-408e-8299-34e3643e372c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Conclusions\n",
    "\n",
    "- La série originale a une **tendance croissante claire** → non-stationnaire\n",
    "- Après différenciation, la série **oscille autour de 0** → stationnaire\n",
    "- La différenciation a **éliminé la tendance** en calculant les changements successifs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16c800d-3422-47f8-a81c-24a1b1b0b2d8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Exercice 3 : Marche aléatoire et différenciation\n",
    "\n",
    "Voici un bout de code qui crée une série en marche aléatoire. Comme précédemment, rendez cette série stationnaire à l’aide de la technique de la différentiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b601057-a596-4dc2-a77d-03bb6dda8dbc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Création d'une marche aléatoire\n",
    "np.random.seed(123)\n",
    "n = 300\n",
    "innovations = np.random.normal(0, 1, n)\n",
    "marche_aleatoire = np.cumsum(innovations)  # Somme cumulative\n",
    "\n",
    "dates_rw = pd.date_range(start='2020-01-01', periods=n, freq='D')\n",
    "serie_rw = pd.Series(marche_aleatoire, index=dates_rw, name='Marche aléatoire')\n",
    "\n",
    "print(\"Marche aléatoire : Y_t = Y_{t-1} + ε_t\")\n",
    "print(f\"où ε_t ~ N(0, 1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e8cc0d-cf01-43b9-92a7-536e211e50e4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXERCICE 3 : VOTRE CODE !\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d41e7e-811c-4148-ba2f-13c61bf35a4a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualisation\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 12))\n",
    "\n",
    "# Marche aléatoire\n",
    "axes[0].plot(serie_rw, linewidth=1.5, color='navy', alpha=0.7)\n",
    "axes[0].set_title('Marche Aléatoire : Y_t = Y_{t-1} + ε_t', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Y_t', fontsize=12)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Série différenciée (= innovations originales)\n",
    "axes[1].plot(serie_rw_diff, linewidth=1, color='green', alpha=0.7)\n",
    "axes[1].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[1].set_title('Différence : ∇Y_t = Y_t - Y_{t-1} = ε_t (Bruit Blanc)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('∇Y_t', fontsize=12)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Innovations originales (pour comparaison)\n",
    "axes[2].plot(dates_rw, innovations, linewidth=1, color='orange', alpha=0.7)\n",
    "axes[2].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[2].set_title('Innovations Originales ε_t (pour vérification)', fontsize=14, fontweight='bold')\n",
    "axes[2].set_xlabel('Date', fontsize=12)\n",
    "axes[2].set_ylabel('ε_t', fontsize=12)\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5e01b8-2f35-4f06-8886-46d9df219cd0",
   "metadata": {},
   "source": [
    "##### Conclusion\n",
    "\n",
    "À quoi est égal le bruit blanc obtenu par différentiation ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af2d0be-85a9-4792-be15-11b417b771ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre réponse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34be7484-599b-4458-a491-c2616a99d7f2",
   "metadata": {},
   "source": [
    "#### Exercice 4 : Différenciation d'une série de prix\n",
    "\n",
    "Les prix d'actions suivent souvent une marche aléatoire, mais les rendements (variations relatives) sont généralement stationnaires. Modélisons le rendement et le prix d’une action imaginaire, puis testons la stationnarité.\n",
    "\n",
    "1. Créez une série de prix d'actions simulée (marche aléatoire avec dérive positive)\n",
    "2. Testez la stationnarité de la série de prix\n",
    "3. Calculez les rendements (différence logarithmique ou différence simple). Affichez les statistique courante des rendements générés (moyenne, dispersion, etc.)\n",
    "    Rappels :\n",
    "    - Rendements simples : $R_t= \\frac{P_t-P_{t−1}}{Pt-1}=\\frac{Pt}{P_{t−1}}−1$\n",
    "    - Taux de croissance continue (log-returns) : $r_t = \\ln \\frac{P_{t−1}}{P_t} = \\ln P_t − \\ln P_{t−1}$\n",
    "5. Testez la stationnarité des rendements\n",
    "6. Après visualisation des deux séries, quelles sont vos conclusions ?\n",
    "\n",
    "**Note :** pandas et numpy proposent des méthodes qui permettent d’écrire simplement les calculs pour des séries : `.diff()`, `.shift()`, `.pct_change()`. N’oubliez pas de supprimer les valeurs manquantes (`.dropna()`) en début ou en fin de série qui ne manquerons pas d’apparaître quand on réalise des opérations entre un élément et le précédent/suivant d’une série."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c4e573-dcba-4adf-b4e4-bc079c374925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCICE 4 - VOTRE CODE \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd710b2-2398-488a-b27e-99f28afa3121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Test de stationnarité sur les prix\n",
    "# VOTRE CODE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d76d76-d9e2-4511-8a6d-0385af3455c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Calculer les rendements (diff simple ou log)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16542d0d-bbfe-4da6-930e-a515f7f5852f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Test de stationnarité sur les rendements\n",
    "# VOTRE CODE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd93a15-a7ff-400c-845d-6b2066335d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation comparative\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 12))\n",
    "\n",
    "# Prix\n",
    "axes[0].plot(serie_prix, linewidth=1.5, color='darkblue')\n",
    "axes[0].set_title('Prix de l\\'Action (Non-Stationnaire)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Prix (€)', fontsize=12)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Rendements logarithmiques\n",
    "axes[1].plot(rendements_log, linewidth=1, color='green', alpha=0.7)\n",
    "axes[1].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[1].set_title('Rendements Logarithmiques (Stationnaire)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Log-return', fontsize=12)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Distribution des rendements\n",
    "axes[2].hist(rendements_log, bins=50, color='green', alpha=0.7, edgecolor='black')\n",
    "axes[2].axvline(x=rendements_log.mean(), color='red', linestyle='--', linewidth=2, label=f'Moyenne = {rendements_log.mean():.4f}')\n",
    "axes[2].set_title('Distribution des Rendements', fontsize=14, fontweight='bold')\n",
    "axes[2].set_xlabel('Log-return', fontsize=12)\n",
    "axes[2].set_ylabel('Fréquence', fontsize=12)\n",
    "axes[2].legend(fontsize=11)\n",
    "axes[2].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01289673-49d2-496b-b509-eca1d706eed1",
   "metadata": {},
   "source": [
    "Vos conclusions ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b46fd93-05b8-4273-b351-d358895a0685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conclusion = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464ba04c-8861-419d-8f78-fa94e6e9b53d",
   "metadata": {},
   "source": [
    "### 3.2 : Résumé des processus Stochastiques de Base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c232c3d-bc8e-4a76-8a6d-4dc5b453a5b9",
   "metadata": {},
   "source": [
    "#### 3.2.1 Bruit Blanc (White Noise)\n",
    "\n",
    "Le **bruit blanc** est le processus stochastique le plus simple.\n",
    "\n",
    "##### Définition\n",
    "\n",
    "Un processus $\\{\\epsilon_t\\}$ est un bruit blanc si :\n",
    "\n",
    "1. $E[\\epsilon_t] = 0$ pour tout $t$ (moyenne nulle)\n",
    "2. $Var(\\epsilon_t) = \\sigma^2$ pour tout $t$ (variance constante)\n",
    "3. $Cov(\\epsilon_t, \\epsilon_s) = 0$ pour tout $t \\neq s$ (pas de corrélation)\n",
    "\n",
    "Notation : $\\epsilon_t \\sim WN(0, \\sigma^2)$\n",
    "\n",
    "##### Propriétés\n",
    "\n",
    "- Le bruit blanc est **stationnaire**\n",
    "- Il est **imprévisible** : la meilleure prévision est la moyenne (0)\n",
    "- C'est le \"building block\" des modèles de séries temporelles\n",
    "\n",
    "##### Exemple : générer un bruit blanc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a681e4fa-20b0-4594-a8ca-b6648cfa719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Génération d'un bruit blanc\n",
    "np.random.seed(42)\n",
    "n = 500\n",
    "bruit_blanc = np.random.normal(0, 1, n)\n",
    "\n",
    "# Visualisation\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Série temporelle\n",
    "axes[0].plot(bruit_blanc, linewidth=1, color='gray', alpha=0.7)\n",
    "axes[0].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[0].set_title('Bruit Blanc : ε_t ~ N(0, 1)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Temps', fontsize=12)\n",
    "axes[0].set_ylabel('Valeur', fontsize=12)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Histogramme\n",
    "axes[1].hist(bruit_blanc, bins=40, color='gray', alpha=0.7, edgecolor='black', density=True)\n",
    "# Courbe normale théorique\n",
    "x = np.linspace(-4, 4, 100)\n",
    "axes[1].plot(x, (1/np.sqrt(2*np.pi)) * np.exp(-x**2/2), 'r-', linewidth=2, label='N(0,1) théorique')\n",
    "axes[1].set_title('Distribution du Bruit Blanc', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Valeur', fontsize=12)\n",
    "axes[1].set_ylabel('Densité', fontsize=12)\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Moyenne empirique : {bruit_blanc.mean():.4f} (théorique : 0)\")\n",
    "print(f\"Écart-type empirique : {bruit_blanc.std():.4f} (théorique : 1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e4f1a5-0cb5-4b78-9ebc-137e98920e1c",
   "metadata": {},
   "source": [
    "#### 3.2.2 Processus AutoRégressif (AR)\n",
    "\n",
    "Un processus **autorégressif d'ordre p**, noté AR(p), utilise les p valeurs passées pour prédire la valeur actuelle.\n",
    "\n",
    "##### AR(1) - AutoRégressif d'ordre 1\n",
    "\n",
    "$$Y_t = c + \\phi Y_{t-1} + \\epsilon_t$$\n",
    "\n",
    "où :\n",
    "- $c$ est une constante\n",
    "- $\\phi$ est le coefficient autorégressif\n",
    "- $\\epsilon_t \\sim WN(0, \\sigma^2)$ est le bruit blanc\n",
    "\n",
    "##### Condition de stationnarité\n",
    "\n",
    "Un processus AR(1) est **stationnaire si et seulement si** : $|\\phi| < 1$\n",
    "\n",
    "- Si $\\phi = 0$ : on retrouve un bruit blanc\n",
    "- Si $\\phi = 1$ : on a une marche aléatoire (non-stationnaire)\n",
    "- Si $\\phi > 0$ : corrélation positive (persistance)\n",
    "- Si $\\phi < 0$ : corrélation négative (oscillations)\n",
    "\n",
    "##### AR(p) - Forme générale\n",
    "\n",
    "$$\n",
    "AR(p): Y_t = c + \\phi_1 Y_{t-1} + \\phi_2 Y_{t-2}  + … + \\phi_p Y_{t-p} + \\varepsilon_t\n",
    "$$\n",
    "\n",
    "##### AR(p) - Forme avec facteur de retard \n",
    "\n",
    "$$\n",
    "AR(p): Y_t = c + \\phi_1 Y_{t-1} + \\phi_2 Y_{t-2}  + … + \\phi_p Y_{t-p} + \\varepsilon_t \\\\\n",
    "(1- \\varphi_1 L-\\varphi_2 L^2-\\ldots-\\varphi_p L^p) Y_t = c + \\varepsilon_t \n",
    "$$\n",
    "\n",
    "En définissant l’opérateur de retard  ainsi: $L Y_t = Y_{t-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262b31a7-4d6a-4206-88fe-11a81a467b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour simuler un processus AR(1)\n",
    "def simuler_ar1(phi, c=0, n=500, sigma=1, y0=0):\n",
    "    \"\"\"\n",
    "    Simule un processus AR(1) : Y_t = c + phi * Y_{t-1} + epsilon_t\n",
    "    \n",
    "    Paramètres:\n",
    "    -----------\n",
    "    phi : float\n",
    "        Coefficient autorégressif\n",
    "    c : float\n",
    "        Constante\n",
    "    n : int\n",
    "        Nombre d'observations\n",
    "    sigma : float\n",
    "        Écart-type du bruit blanc\n",
    "    y0 : float\n",
    "        Valeur initiale\n",
    "    \"\"\"\n",
    "    y = [y0]\n",
    "    epsilon = np.random.normal(0, sigma, n)\n",
    "    \n",
    "    for t in range(n-1):\n",
    "        y_next = c + phi * y[-1] + epsilon[t]\n",
    "        y.append(y_next)\n",
    "    \n",
    "    return np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc2d7f0-b280-4076-9fb7-3909a54f096e",
   "metadata": {},
   "source": [
    "Processus $AR(1)$ simulés avec différents coefficients $\\phi$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a38faf-d753-4f6c-ac98-0701c2b46dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation de différents AR(1)\n",
    "np.random.seed(42)\n",
    "n = 300\n",
    "\n",
    "ar1_phi05 = simuler_ar1(phi=0.5, n=n)    # Stationnaire, corrélation positive\n",
    "ar1_phi09 = simuler_ar1(phi=0.9, n=n)    # Stationnaire, forte persistance\n",
    "ar1_phi_neg = simuler_ar1(phi=-0.7, n=n) # Stationnaire, oscillations\n",
    "ar1_phi1 = simuler_ar1(phi=1.0, n=n)     # Non-stationnaire (marche aléatoire)\n",
    "\n",
    "# Visualisation comparative\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "fig.suptitle('Processus AR(1) avec Différents Coefficients', fontsize=16, fontweight='bold', y=0.995)\n",
    "\n",
    "# φ = 0.5 (stationnaire)\n",
    "axes[0, 0].plot(ar1_phi05, linewidth=1, color='green')\n",
    "axes[0, 0].axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "axes[0, 0].set_title('AR(1) avec φ = 0.5 (Stationnaire)', fontsize=13, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Y_t', fontsize=11)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# φ = 0.9 (stationnaire mais très persistant)\n",
    "axes[0, 1].plot(ar1_phi09, linewidth=1, color='orange')\n",
    "axes[0, 1].axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "axes[0, 1].set_title('AR(1) avec φ = 0.9 (Forte Persistance)', fontsize=13, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Y_t', fontsize=11)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# φ = -0.7 (oscillations)\n",
    "axes[1, 0].plot(ar1_phi_neg, linewidth=1, color='purple')\n",
    "axes[1, 0].axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "axes[1, 0].set_title('AR(1) avec φ = -0.7 (Oscillations)', fontsize=13, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Temps', fontsize=11)\n",
    "axes[1, 0].set_ylabel('Y_t', fontsize=11)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# φ = 1.0 (marche aléatoire - non-stationnaire)\n",
    "axes[1, 1].plot(ar1_phi1, linewidth=1, color='red')\n",
    "axes[1, 1].axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "axes[1, 1].set_title('AR(1) avec φ = 1.0 (Marche Aléatoire)', fontsize=13, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Temps', fontsize=11)\n",
    "axes[1, 1].set_ylabel('Y_t', fontsize=11)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b22db8-4373-47f5-93b2-654691d36083",
   "metadata": {},
   "source": [
    "Visualisation d’un processus explosif :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbdbdbb-466e-47a4-aa00-5f7ebc9a2b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar1_phi12 = simuler_ar1(phi=1.2, n=50) # Non-stationnaire, explosivité\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(16, 10))\n",
    "fig.suptitle('Processus AR(1) explosif', fontsize=16, fontweight='bold', y=0.995)\n",
    "\n",
    "# φ = 1.2 (explosif)\n",
    "axes.plot(ar1_phi12, linewidth=1, color='green')\n",
    "axes.set_ylabel('Y_t', fontsize=11)\n",
    "axes.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fddb37-e994-4999-927b-011e979c263f",
   "metadata": {},
   "source": [
    "Comment interprêtez-vous les différentes valeurs de $\\phi$ sur ces visualisations ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e67a96-83c3-451a-8c4a-09a8bd123454",
   "metadata": {},
   "outputs": [],
   "source": [
    "conclusion = '''\n",
    "- φ = 0.5 : la valeur actuelle dépend modérément de la valeur précédente\n",
    "- φ = 0.9 : forte dépendance → la série a une \"mémoire longue\"\n",
    "- φ = -0.7 : alternance entre valeurs positives et négatives\n",
    "- φ = 1.0 : marche aléatoire → non-stationnaire (racine unitaire)\n",
    "- φ = 1.2 : explosivité → l’influence passée est exponentielle plus le temps passe'''\n",
    "\n",
    "print(conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d26cc9c-0ff5-450d-a5b9-4234f3f06efc",
   "metadata": {},
   "source": [
    "#### 3.2.3 Processus Moyenne Mobile (MA)\n",
    "\n",
    "Un processus **moyenne mobile d'ordre q**, noté MA(q), utilise les q erreurs passées.\n",
    "\n",
    "##### MA(1) - Moyenne Mobile d'ordre 1\n",
    "\n",
    "$$Y_t = \\mu + \\epsilon_t + \\theta \\epsilon_{t-1}$$\n",
    "\n",
    "où :\n",
    "- $\\mu$ est la moyenne\n",
    "- $\\theta$ est le coefficient de moyenne mobile\n",
    "- $\\epsilon_t \\sim WN(0, \\sigma^2)$ est le bruit blanc\n",
    "\n",
    "##### Propriétés\n",
    "\n",
    "- Un processus MA(q) est **toujours stationnaire** (peu importe $\\theta$)\n",
    "- La corrélation est nulle au-delà du lag q (\"mémoire courte\")\n",
    "- Contrairement aux AR, les MA sont toujours inversibles\n",
    "\n",
    "##### MA(q) - Forme générale\n",
    "\n",
    "$$Y_t = \\mu + \\epsilon_t + \\theta_1 \\epsilon_{t-1} + \\theta_2 \\epsilon_{t-2} + ... + \\theta_q \\epsilon_{t-q}$$\n",
    "\n",
    "##### Interprétation physique fondamentale\n",
    "\n",
    "Un processus MA modélise un système où les chocs (perturbations, innovations) ont un effet qui persiste pendant un temps limité. Après q périodes, l'effet du choc disparaît complètement. C'est une \"mémoire courte\" : le système \"oublie\" rapidement. On peut faire une analogie simple sur ce qu’il se passe quand on jette des cailloux dans un étang, on peut imaginer que les ondes formées dans l’étant obéissent à un processus MA(2) :\n",
    "- t=0 : Vous lancez un caillou (choc ε₀)\n",
    "      → Onde à la surface\n",
    "\n",
    "- t=1 : L'onde se propage (effet de ε₀)\n",
    "      + vous lancez un nouveau caillou (choc ε₁)\n",
    "      → Superposition de deux ondes\n",
    "\n",
    "- t=2 : Les deux ondes se propagent encore\n",
    "      + nouveau caillou (choc ε₂)\n",
    "      → 3 ondes actives\n",
    "\n",
    "- t=3 : L'onde de t=0 a disparu (vu que c’est un processus $MA(2)$ mémoire = 2 périodes)\n",
    "      Seules les ondes de t=1 et t=2 restent\n",
    "      + nouveau caillou\n",
    "\n",
    "  \n",
    "Ce que vous observez (niveau de l'eau = $Y_t$) est la superposition des effets des 2 derniers cailloux seulement.\n",
    "\n",
    "##### Exemple réels :\n",
    "\n",
    "-  Gestion des stocks d'un supermarché (inventaire avec délai de livraison)\n",
    "   Le niveau de stock observé aujourd'hui dépend de :\n",
    "    - Les ventes/livraisons aléatoires du jour J\n",
    "    - Les commandes passées à J-1 (délai de livraison)\n",
    "    - Les commandes passées il y a 2 jours (J-2)\n",
    "\n",
    "    $Stock_t = Stock_moyen + choc_t + effet_commande_{t-1} + effet_commande_{t-2}$\n",
    "\n",
    "    Si le délai de livraison maximum est de 2 jours, le système a une mémoire de 2 : on a un processus MA(2)\n",
    "\n",
    "- Modèle météo qui s'auto-corrige (correction d’erreur/de mesure)\n",
    "    Un centre météo fait une prévision, puis observe l'erreur et corrige :\n",
    "    - Jour J : prévision avec erreur ε_t\n",
    "    - J+1 : on corrige partiellement l'erreur de J (θ₁ ε_t)\n",
    "    - J+2 : on corrige l'erreur de J+1 (θ₂ ε_{t-1})\n",
    "\n",
    "    La température prédite reflète $Temp_t = Tendance + ε_t + θ₁ ε_{t-1} + θ₂ ε_{t-2}$\n",
    "\n",
    "- Concentration d'un médicament dans le sang (pharmacodynamique)\n",
    "\n",
    "    Un médicament pris chaque jour a une demi-vie de 2 jours :\n",
    "    - Jour 0 : vous prenez 100mg (choc ε₀)\n",
    "    - Jour 1 : il reste 50mg de hier + 100mg aujourd'hui\n",
    "    - Jour 2 : il reste 25mg de J0 + 50mg de J1 + 100mg de J2\n",
    "    - Jour 3 : J0 est éliminé (< 12.5mg négligeable)\n",
    "    $Concentration_t ≈ ε_t + 0.5 ε_{t-1} + 0.25 ε_{t-2}$\n",
    "\n",
    "##### Importance des processus MA\n",
    "Ces processus sont impliquée dans la modélisation de nombreuses situations :\n",
    "\n",
    "1. Systèmes avec retards/délais\n",
    "    Beaucoup de systèmes réels ont des délais :\n",
    "   * Production → vente (délai logistique)\n",
    "   * Investissement → rendement (délai de construction)\n",
    "   * Politique économique → effet (délai de transmission)\n",
    "   Ces délais créent naturellement des structures MA.\n",
    "2. Agrégation de processus\n",
    "    Même si les processus élémentaires sont AR, leur agrégation peut créer un MA. Exemple :\n",
    "    * 100 magasins avec leurs propres dynamiques AR\n",
    "    * L'agrégation (ventes totales) peut ressembler à un MA !\n",
    "\n",
    "3. Erreurs de mesure dans les données\n",
    "    En pratique, toute série observée contient des erreurs :\n",
    "    * $Y_{observé} = Y_{réel} + erreur_{mesure}$\n",
    "    * Si les erreurs sont corrélées sur quelques périodes → composante MA !\n",
    "\n",
    "##### Processus MA vs. AR\n",
    "\n",
    "Les processus AR sont impactés par les niveaux passés (une inertie), un processus MA par les chocs récents (qui vont finir par s’évanouir).\n",
    "\n",
    "* Processus AR (AutoRégressif)\n",
    "    * Mécanisme : Le système lui-même a de l'inertie. C'est le niveau qui persiste\n",
    "    * Exemple : température (inertie thermique)\n",
    "    * formule : $Y_t = φ Y_{t-1} + ε_t$\n",
    "    * Analogie : Un volant d'inertie qui tourne. Si vous le poussez (choc), il continue à tourner (persistance). Le mouvement actuel dépend du mouvement passé.\n",
    "\n",
    "* Processus MA (Moyenne Mobile)\n",
    "    * Mécanisme : Les perturbations ont un effet qui s'estompe. C'est le choc qui persiste temporairement\n",
    "    * Exemple : onde à la surface de l'eau\n",
    "    * formule : Y_t = ε_t + θ ε_{t-1}\n",
    "    * Analogie : Caillou dans l'étang. L'onde (effet du choc) se propage puis disparaît. Le niveau actuel dépend des chocs récents, pas du niveau passé.\n",
    "* \n",
    "* | Type | Processus AR (stationnaire) | Processus MA |\n",
    "|------|-----------------------------|--------------|\n",
    "| Inertie | Le système lui-même | Les perturbations |\n",
    "| Persistance | Décroît exp. / infinie | Finie (q périodes) |\n",
    "| Mémoire | Longue | Courte |\n",
    "| Exemples | Température, PIB, inflation, prix actions | Erreurs de mesure, stocks avec délais, corrections successives |\n",
    "| Retour à la moyenne | Graduel | Rapide (après q périodes) |\n",
    "| Analogie physique | Système avec masse/inertie | Perturbation impulsionnelle |\n",
    "\n",
    "##### Exemple (simulation/visualisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ec6308-5810-42fb-9bfe-ef7ad8ddf889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour simuler un processus MA(1)\n",
    "def simuler_ma1(theta, mu=0, n=500, sigma=1):\n",
    "    \"\"\"\n",
    "    Simule un processus MA(1) : Y_t = mu + epsilon_t + theta * epsilon_{t-1}\n",
    "    \"\"\"\n",
    "    epsilon = np.random.normal(0, sigma, n+1)\n",
    "    y = np.zeros(n)\n",
    "    \n",
    "    for t in range(n):\n",
    "        y[t] = mu + epsilon[t+1] + theta * epsilon[t]\n",
    "    \n",
    "    return y\n",
    "\n",
    "# Simulation de différents MA(1)\n",
    "np.random.seed(42)\n",
    "n = 300\n",
    "\n",
    "ma1_theta05 = simuler_ma1(theta=0.5, n=n)\n",
    "ma1_theta09 = simuler_ma1(theta=0.9, n=n)\n",
    "ma1_theta_neg = simuler_ma1(theta=-0.7, n=n)\n",
    "\n",
    "print(\"Processus MA(1) simulés\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c417efd-5cd3-4969-b4f1-9180127e1f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 12))\n",
    "fig.suptitle('Processus MA(1) avec Différents Coefficients', fontsize=16, fontweight='bold', y=0.995)\n",
    "\n",
    "# θ = 0.5\n",
    "axes[0].plot(ma1_theta05, linewidth=1, color='steelblue', alpha=0.7)\n",
    "axes[0].axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "axes[0].set_title('MA(1) avec θ = 0.5', fontsize=13, fontweight='bold')\n",
    "axes[0].set_ylabel('Y_t', fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# θ = 0.9\n",
    "axes[1].plot(ma1_theta09, linewidth=1, color='forestgreen', alpha=0.7)\n",
    "axes[1].axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "axes[1].set_title('MA(1) avec θ = 0.9', fontsize=13, fontweight='bold')\n",
    "axes[1].set_ylabel('Y_t', fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# θ = -0.7\n",
    "axes[2].plot(ma1_theta_neg, linewidth=1, color='crimson', alpha=0.7)\n",
    "axes[2].axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "axes[2].set_title('MA(1) avec θ = -0.7', fontsize=13, fontweight='bold')\n",
    "axes[2].set_xlabel('Temps', fontsize=11)\n",
    "axes[2].set_ylabel('Y_t', fontsize=11)\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1f74e7-c3ba-4f64-8b8f-776477a439b0",
   "metadata": {},
   "source": [
    "Les processus MA ont l'air plus « bruités » que les processus AR car ils n'ont pas de composante autorégressive (pas de mémoire longue)\n",
    "\n",
    "Contrairement à AR(1) où φ contrôle la persistance à long terme, θ dans MA(1) ne contrôle que la corrélation sur 1 seule période, puis tout s'arrête ! C'est une \"mémoire flash\" de 1 période. \n",
    "\n",
    "Nous ne faisons pas la démonstration dans ce cours (qui demande de calculer le lien entre θ et la variance), mais retenez :\n",
    "\n",
    "* θ ≈ 0 → Bruit blanc, erratique\n",
    "* θ > 0 élevé → Courbe lisse, vagues douces\n",
    "* θ < 0 élevé → Zigzag, oscillations rapides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e819c5-b202-457e-8fdc-021e96bffa0e",
   "metadata": {},
   "source": [
    "#### 3.2.4 Modèles hybrides ARMA\n",
    "\n",
    "Un processus **ARMA(p,q)** combine les composantes AR et MA.\n",
    "\n",
    "En effet, dans la réalité, la plupart des phénomènes ont à la fois :\n",
    "\n",
    "* de l'inertie (composante AR)\n",
    "* des chocs qui persistent temporairement (composante MA)\n",
    "\n",
    "##### Exemple : les cours boursiers\n",
    "\n",
    "Les rendements boursiers peuvent être modélisés comme un processus hybride ARMA(1,1) :\n",
    "\n",
    "$$r_t = \\phi r_{t-1} + \\varepsilon_t + \\theta \\varepsilon_{t-1}$$\n",
    "\n",
    "* $\\phi r_{t-1}$ -> AR (momentum)\n",
    "* $\\varepsilon_t + \\theta \\varepsilon_{t-1}$ -> AM (sur-réaction puis correction du marché)\n",
    "\n",
    "* AR : le momentum, soit une tendance continue sur quelques temps -> quand une valeur monte ou descends, les autres investisseurs « suivent le mouvement » et achètent pour profiter de la montée ou vendent pour limiter les pertent et amplifient le mouvement : c’est le *momentum* ou inertie.\n",
    "* MA : sur-réaction puis correction sur un temps plus court (le marché surréagit aux nouvelles puis se corrige ou « rebondit » au bout de quelques jours ou dès le lendemain)\n",
    "\n",
    "##### ARMA(p,q) - Forme générale\n",
    "\n",
    "$$Y_t = c + \\phi_1 Y_{t-1} + ... + \\phi_p Y_{t-p} + \\epsilon_t + \\theta_1 \\epsilon_{t-1} + ... + \\theta_q \\epsilon_{t-q}$$\n",
    "\n",
    "##### Exemple : ARMA(1,1)\n",
    "\n",
    "$$Y_t = c + \\phi Y_{t-1} + \\epsilon_t + \\theta \\epsilon_{t-1}$$\n",
    "\n",
    "##### Avantages\n",
    "\n",
    "- Plus **parcimonieux** : ARMA(1,1) peut modéliser ce qu'un AR(∞) modéliserait\n",
    "- Combine la **mémoire longue** (AR) et les **chocs transitoires** (MA)\n",
    "- Souvent meilleur ajustement avec moins de paramètres\n",
    "\n",
    "##### Exemple : simulation d’un processus ARMA(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9712141a-c8d8-465e-ace1-d453a8e83c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation d'un ARMA(1,1)\n",
    "def simuler_arma11(phi, theta, c=0, n=500, sigma=1, y0=0):\n",
    "    \"\"\"\n",
    "    Simule un processus ARMA(1,1) : Y_t = c + phi*Y_{t-1} + epsilon_t + theta*epsilon_{t-1}\n",
    "    \"\"\"\n",
    "    y = [y0]\n",
    "    epsilon = np.random.normal(0, sigma, n+1)\n",
    "    \n",
    "    for t in range(1, n):\n",
    "        y_next = c + phi * y[-1] + epsilon[t] + theta * epsilon[t-1]\n",
    "        y.append(y_next)\n",
    "    \n",
    "    return np.array(y)\n",
    "\n",
    "np.random.seed(42)\n",
    "arma11 = simuler_arma11(phi=0.7, theta=0.4, n=500)\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(arma11, linewidth=1, color='darkviolet', alpha=0.7)\n",
    "plt.axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "plt.title('Processus ARMA(1,1) avec φ=0.7 et θ=0.4', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Temps', fontsize=12)\n",
    "plt.ylabel('Y_t', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Processus ARMA(1,1) simulé\")\n",
    "print(f\"Moyenne : {arma11.mean():.4f}\")\n",
    "print(f\"Écart-type : {arma11.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adad22e8-01f7-404c-a126-59f338887cd2",
   "metadata": {},
   "source": [
    "N’hésitez pas à modifier les valeurs de $\\phi$ et $\\theta$ pour bien comprendre commet ces paramètres affectent la forme de la courbe :\n",
    "- $\\phi = 1$\n",
    "- $\\phi > 1$\n",
    "- $\\theta < 0$\n",
    "- $\\theta = 1$\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c5df3f-dd6d-4ebd-b626-f626f973ad82",
   "metadata": {},
   "source": [
    "##### Exercice : comparer AR, MA et ARMA\n",
    "\n",
    "Comprendre visuellement les différences entre AR, MA et ARMA\n",
    "\n",
    "1. Simulez les processus suivants (n=500) :\n",
    "   - AR(2) : $Y_t = 0.6·Y_{t-1} - 0.3·Y_{t-2} + ε_t$\n",
    "   - MA(2) : $Y_t = ε_t + 0.7·ε_{t-1} + 0.8·ε_{t-2}$\n",
    "   - ARMA(1,1) : $Y_t = 0.8·Y_{t-1} + ε_t + 0.4·ε_{t-1}$\n",
    "2. Visualisez les trois séries\n",
    "3. Testez leur stationnarité\n",
    "4. Identifiez visuellement les différences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd371f3b-ed9f-4c54-936f-a83a18f76c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCICE 3 - VOTRE CODE\n",
    "\n",
    "# 1. Les trois processus\n",
    "# ar2 = ...\n",
    "# ma2 = ...\n",
    "# arma11 = ...\n",
    "\n",
    "# 2. Visualisation et tests\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fff7a9-5aac-4580-8df6-125b0819c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation comparative\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 12))\n",
    "fig.suptitle('Comparaison : AR(2) vs MA(2) vs ARMA(1,1)', fontsize=16, fontweight='bold', y=0.995)\n",
    "\n",
    "# AR(2)\n",
    "axes[0].plot(ar2, linewidth=1, color='royalblue', alpha=0.7)\n",
    "axes[0].axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "axes[0].set_title('AR(2) : Y_t = 0.6·Y_{t-1} - 0.3·Y_{t-2} + ε_t', fontsize=13, fontweight='bold')\n",
    "axes[0].set_ylabel('Y_t', fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# MA(2)\n",
    "axes[1].plot(ma2, linewidth=1, color='forestgreen', alpha=0.7)\n",
    "axes[1].axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "axes[1].set_title('MA(2) : Y_t = ε_t + 0.7·ε_{t-1} + 0.8·ε_{t-2}', fontsize=13, fontweight='bold')\n",
    "axes[1].set_ylabel('Y_t', fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# ARMA(1,1)\n",
    "axes[2].plot(arma11_ex, linewidth=1, color='darkorange', alpha=0.7)\n",
    "axes[2].axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "axes[2].set_title('ARMA(1,1) : Y_t = 0.8·Y_{t-1} + ε_t + 0.4·ε_{t-1}', fontsize=13, fontweight='bold')\n",
    "axes[2].set_xlabel('Temps', fontsize=11)\n",
    "axes[2].set_ylabel('Y_t', fontsize=11)\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0711c66f-5c0f-4375-8df5-d663d5a794b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests de stationnarité ar2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276afc4e-2638-4af0-9a70-f5e133f7e786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests de stationnarité ma2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7864c89-08c1-4748-b788-b6cfe05b55b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests de stationnarité arma11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826a3595-fed9-40cb-920f-cb58795a1623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques comparatives\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STATISTIQUES COMPARATIVES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "stats_df = pd.DataFrame({\n",
    "    'Processus': ['AR(2)', 'MA(2)', 'ARMA(1,1)'],\n",
    "    'Moyenne': [ar2.mean(), ma2.mean(), arma11_ex.mean()],\n",
    "    'Écart-type': [ar2.std(), ma2.std(), arma11_ex.std()],\n",
    "    'Min': [ar2.min(), ma2.min(), arma11_ex.min()],\n",
    "    'Max': [ar2.max(), ma2.max(), arma11_ex.max()]\n",
    "})\n",
    "\n",
    "print(stats_df.to_string(index=False))\n",
    "\n",
    "print(\"\\nObservations :\")\n",
    "print(\"  - AR(2) : oscillations plus régulières/lisses et stables autour de l’axe, (mémoire autorégressive)\")\n",
    "print(\"  - MA(2) : variations plus erratiques, avec des soubressauts/tendances (mémoire courte)\")\n",
    "print(\"  - ARMA(1,1) : comportement intermédiaire\")\n",
    "print(\"  - Tous sont stationnaires !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aaacbe-639f-4c9f-afaa-90e8a6be2751",
   "metadata": {},
   "source": [
    "## 4. ACF/PACF et Modèles ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50165ce5-bfa8-4f58-9853-acad234bf8a4",
   "metadata": {},
   "source": [
    "### 4.1 Autocorrélation et caractérisation des processus\n",
    "\n",
    "#### 4.1.1 Fonction d'Autocorrélation (ACF)\n",
    "\n",
    "##### Définition\n",
    "\n",
    "L'**autocorrélation** mesure la corrélation entre une série et ses valeurs avec un certain décalage (lags).\n",
    "\n",
    "Pour un lag $k$, l'autocorrélation est :\n",
    "\n",
    "$$\\rho_k = \\frac{Cov(Y_t, Y_{t-k})}{\\sqrt{Var(Y_t) \\cdot Var(Y_{t-k})}} = \\frac{Cov(Y_t, Y_{t-k})}{Var(Y_t)}$$\n",
    "\n",
    "Pour une série stationnaire : $\\rho_k = \\frac{\\gamma_k}{\\gamma_0}$\n",
    "\n",
    "##### Interprétation\n",
    "\n",
    "- $\\rho_k$ proche de 1 : forte corrélation positive au lag $k$\n",
    "- $\\rho_k$ proche de -1 : forte corrélation négative au lag $k$\n",
    "- $\\rho_k$ proche de 0 : pas de corrélation au lag $k$\n",
    "\n",
    "##### Patterns typiques de l'ACF\n",
    "\n",
    "- **Bruit blanc** : tous les $\\rho_k \\approx 0$ pour $k > 0$\n",
    "- **AR(p)** : décroissance exponentielle ou sinusoïdale\n",
    "- **MA(q)** : coupure nette après le lag $q$ (tous les $\\rho_k = 0$ pour $k > q$)\n",
    "- **Tendance** : décroissance très lente vers 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe36727-d1d2-42b8-abde-2deaffe8ccc0",
   "metadata": {},
   "source": [
    "#### 4.1.2 Fonction d'Autocorrélation Partielle (PACF)\n",
    "\n",
    "##### Définition\n",
    "\n",
    "La **PACF** mesure la corrélation entre $Y_t$ et $Y_{t-k}$ **après avoir enlevé l'effet des lags intermédiaires** (1, 2, ..., k-1).\n",
    "\n",
    "C'est la corrélation \"directe\" au lag $k$, sans l'influence des lags précédents.\n",
    "\n",
    "##### Interprétation\n",
    "\n",
    "La PACF aide à identifier l'ordre $p$ d'un processus AR.\n",
    "\n",
    "##### Patterns typiques de la PACF\n",
    "\n",
    "- **Bruit blanc** : tous les $\\phi_{kk} \\approx 0$\n",
    "- **AR(p)** : coupure nette après le lag $p$ (tous les $\\phi_{kk} = 0$ pour $k > p$)\n",
    "- **MA(q)** : décroissance exponentielle ou sinusoïdale\n",
    "\n",
    "##### Tableau récapitulatif ACF/PACF\n",
    "\n",
    "| Processus | ACF | PACF |\n",
    "|-----------|-----|------|\n",
    "| **AR(p)** | Décroissance exponentielle | Coupure nette après lag p |\n",
    "| **MA(q)** | Coupure nette après lag q | Décroissance exponentielle |\n",
    "| **ARMA(p,q)** | Décroissance exponentielle | Décroissance exponentielle |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84c2bca-8797-4e7e-b712-6b3387cbd781",
   "metadata": {},
   "source": [
    "#### 4.1.3 Exemples : ACF et PACF de différents processus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6ac5d9-55a7-4051-80a0-832c4a0bb5fa",
   "metadata": {},
   "source": [
    "Simulons différents processus AR(1), AM(1) et ARMA(1,1) avec les fonctions que nous avons créé dans la partie précédente :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a700929-334a-4b5e-bd76-9217bb07485a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation des processus\n",
    "np.random.seed(42)\n",
    "n = 500\n",
    "\n",
    "bruit_blanc = np.random.normal(0, 1, n)\n",
    "ar1 = simuler_ar1(phi=0.7, n=n)\n",
    "ma1 = simuler_ma1(theta=0.7, n=n)\n",
    "arma11 = simuler_arma11(phi=0.6, theta=0.4, n=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2161279-18ee-4adc-9649-a2c6ea7f2438",
   "metadata": {},
   "source": [
    "##### Exemple 1 : ACF et PACF du bruit blanc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6402953-ac0e-476a-8d0a-26532aaea5b9",
   "metadata": {},
   "source": [
    "Pour une représentation graphique de ces analyses, utilisons les méthodes `plot_acf` et `plot_pacf` du module`statsmodels.graphics.tsaplots` pour tracer les autocorrélations et les autocorrélations partielles : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b33071-6834-4f27-a2b7-9c1901b2e88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACF et PACF du bruit blanc\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "fig.suptitle('Bruit Blanc : ACF et PACF', fontsize=16, fontweight='bold')\n",
    "\n",
    "# ACF\n",
    "plot_acf(bruit_blanc, lags=40, ax=axes[0], alpha=0.05)\n",
    "axes[0].set_title('ACF - Bruit Blanc', fontsize=13, fontweight='bold')\n",
    "axes[0].set_xlabel('Lag', fontsize=11)\n",
    "axes[0].set_ylabel('Autocorrélation', fontsize=11)\n",
    "\n",
    "# PACF\n",
    "plot_pacf(bruit_blanc, lags=40, ax=axes[1], alpha=0.05, method='ywm')\n",
    "axes[1].set_title('PACF - Bruit Blanc', fontsize=13, fontweight='bold')\n",
    "axes[1].set_xlabel('Lag', fontsize=11)\n",
    "axes[1].set_ylabel('Autocorrélation Partielle', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0a625d-5f5a-496e-aa01-f6cf7b7e7cbb",
   "metadata": {},
   "source": [
    "- Toutes les valeurs sont dans l'intervalle de confiance (zone bleue)\n",
    "- Donc aucune corrélation n’est significative → confirme que c'est du bruit blanc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783aaebe-ab21-4988-b0af-c00052e0d175",
   "metadata": {},
   "source": [
    "##### Exemple 2 : Processus AR(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fabf60-84c6-4f49-998d-f20aa4a31bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACF et PACF d'un AR(1)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "fig.suptitle('AR(1) avec φ=0.7 : ACF et PACF', fontsize=16, fontweight='bold')\n",
    "\n",
    "# ACF\n",
    "plot_acf(ar1, lags=40, ax=axes[0], alpha=0.05)\n",
    "axes[0].set_title('ACF - AR(1)', fontsize=13, fontweight='bold')\n",
    "axes[0].set_xlabel('Lag', fontsize=11)\n",
    "axes[0].set_ylabel('Autocorrélation', fontsize=11)\n",
    "\n",
    "# PACF\n",
    "plot_pacf(ar1, lags=40, ax=axes[1], alpha=0.05, method='ywm')\n",
    "axes[1].set_title('PACF - AR(1)', fontsize=13, fontweight='bold')\n",
    "axes[1].set_xlabel('Lag', fontsize=11)\n",
    "axes[1].set_ylabel('Autocorrélation Partielle', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73cd20f-a145-4b62-9b97-5f630ce326bf",
   "metadata": {},
   "source": [
    "Observations caractéristiques d'un AR(1) :\n",
    "- ACF : décroissance exponentielle (lente)\n",
    "- PACF : pic significatif au lag 1, puis valeurs non significatives\n",
    "- on conclut que PACF coupe après le lag p=1 → indice que nous avons affaire à un processus AR(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ce1d3e-cf26-4fd7-b89a-c616a01606e1",
   "metadata": {},
   "source": [
    "##### Exemple 3 : Processus MA(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59031c4a-9489-4340-87cd-d6dddbbb2865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACF et PACF d'un MA(1)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "fig.suptitle('MA(1) avec θ=0.7 : ACF et PACF', fontsize=16, fontweight='bold')\n",
    "\n",
    "# ACF\n",
    "plot_acf(ma1, lags=40, ax=axes[0], alpha=0.05)\n",
    "axes[0].set_title('ACF - MA(1)', fontsize=13, fontweight='bold')\n",
    "axes[0].set_xlabel('Lag', fontsize=11)\n",
    "axes[0].set_ylabel('Autocorrélation', fontsize=11)\n",
    "\n",
    "# PACF\n",
    "plot_pacf(ma1, lags=40, ax=axes[1], alpha=0.05, method='ywm')\n",
    "axes[1].set_title('PACF - MA(1)', fontsize=13, fontweight='bold')\n",
    "axes[1].set_xlabel('Lag', fontsize=11)\n",
    "axes[1].set_ylabel('Autocorrélation Partielle', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b34cb95-b18e-40d8-b0dd-e3a1c736e288",
   "metadata": {},
   "source": [
    "Observations caractéristiques d'un MA(1) :\n",
    "- ACF : pic significatif au lag 1, puis valeurs non significatives\n",
    "- PACF : décroissance exponentielle\n",
    "- On conclut que ACF coupe après le lag q=1 → indice que nous avons affaire à un processus MA(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6310e86b-1b24-4eac-b62e-c4762ef80eaa",
   "metadata": {},
   "source": [
    "##### Exemple 4 : Processus ARMA(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f063e6-c99f-4fbf-96ca-35081bdd654a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACF et PACF d'un ARMA(1,1)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "fig.suptitle('ARMA(1,1) avec φ=0.6 et θ=0.4 : ACF et PACF', fontsize=16, fontweight='bold')\n",
    "\n",
    "# ACF\n",
    "plot_acf(arma11, lags=40, ax=axes[0], alpha=0.05)\n",
    "axes[0].set_title('ACF - ARMA(1,1)', fontsize=13, fontweight='bold')\n",
    "axes[0].set_xlabel('Lag', fontsize=11)\n",
    "axes[0].set_ylabel('Autocorrélation', fontsize=11)\n",
    "\n",
    "# PACF\n",
    "plot_pacf(arma11, lags=40, ax=axes[1], alpha=0.05, method='ywm')\n",
    "axes[1].set_title('PACF - ARMA(1,1)', fontsize=13, fontweight='bold')\n",
    "axes[1].set_xlabel('Lag', fontsize=11)\n",
    "axes[1].set_ylabel('Autocorrélation Partielle', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eb365c-f7f1-4193-b89d-f5d3a78c7717",
   "metadata": {},
   "source": [
    "Observations caractéristiques d'un ARMA(1,1) :\n",
    "- ACF : décroissance exponentielle (pas de coupure nette)\n",
    "- PACF : décroissance exponentielle (pas de coupure nette)\n",
    "- on conclut que les deux graphiques montrent une décroissance → Combinaison AR + MA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d9d56a-368e-47f8-bba8-037cdebb7bfa",
   "metadata": {},
   "source": [
    "#### 4.1.4 EXERCICE 5 : Identification de processus avec ACF/PACF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bada7dec-c9b6-4473-96e9-63ca1204df88",
   "metadata": {},
   "source": [
    "Identifier l'ordre d'un processus inconnu en analysant ACF et PACF\n",
    "\n",
    "1. On va générer 3 processus mystères (les paramètres vont être définis aléatoirement)\n",
    "2. Analysez leurs ACF et PACF\n",
    "3. Identifiez le type de processus (AR, MA, ARMA) et leur ordre\n",
    "4. Justifiez votre réponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8c76d1-6957-4e19-9de8-26ef37362198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Génération des processus mystères\n",
    "np.random.seed(123)\n",
    "n = 500\n",
    "\n",
    "# Mystère 1 : AR(2)\n",
    "mystere1 = [0, 0]\n",
    "eps1 = np.random.normal(0, 1, n)\n",
    "for t in range(2, n):\n",
    "    y_next = 0.5 * mystere1[-1] + 0.3 * mystere1[-2] + eps1[t]\n",
    "    mystere1.append(y_next)\n",
    "mystere1 = np.array(mystere1)\n",
    "\n",
    "# Mystère 2 : MA(2)\n",
    "eps2 = np.random.normal(0, 1, n+2)\n",
    "mystere2 = np.zeros(n)\n",
    "for t in range(n):\n",
    "    mystere2[t] = eps2[t+2] + 0.6 * eps2[t+1] + 0.3 * eps2[t]\n",
    "\n",
    "# Mystère 3 : AR(1)\n",
    "mystere3 = [0]\n",
    "eps3 = np.random.normal(0, 1, n)\n",
    "for t in range(n-1):\n",
    "    mystere3.append(0.8 * mystere3[-1] + eps3[t])\n",
    "mystere3 = np.array(mystere3)\n",
    "\n",
    "print(\"3 processus mystères générés\")\n",
    "print(\"Analysez leurs ACF et PACF pour les identifier !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4094f5-d070-4caa-8c3d-25318fd59abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCICE 4 - VOTRE CODE\n",
    "# Tracez les ACF et PACF des 3 processus mystères\n",
    "# Identifiez leur type et ordre\n",
    "\n",
    "# Mystère 1\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "# plot_acf(mystere1, lags=20, ax=axes[0])\n",
    "# plot_pacf(mystere1, lags=20, ax=axes[1], method='ywm')\n",
    "# ...\n",
    "\n",
    "# Votre analyse :\n",
    "# Mystère 1 : ...\n",
    "# Mystère 2 : ...\n",
    "# Mystère 3 : ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed44aed5-9d1f-4d08-8537-9ccb31e158de",
   "metadata": {},
   "source": [
    "### 4.2 : Modèles ARIMA\n",
    "\n",
    "#### 4.2.1 Qu'est-ce qu'un modèle ARIMA ?\n",
    "\n",
    "**ARIMA** = **A**uto**R**egressive **I**ntegrated **M**oving **A**verage\n",
    "\n",
    "##### Structure ARIMA(p, d, q)\n",
    "\n",
    "Un modèle ARIMA combine :\n",
    "\n",
    "1. **AR(p)** : Partie AutoRégressive d'ordre p\n",
    "2. **I(d)** : Intégration (différenciation) d'ordre d\n",
    "3. **MA(q)** : Partie Moyenne Mobile d'ordre q\n",
    "\n",
    "##### Les 3 paramètres\n",
    "\n",
    "- **p** : ordre autorégressif (nombre de lags de Y)\n",
    "- **d** : ordre de différenciation (nombre de fois qu'on différencie)\n",
    "- **q** : ordre moyenne mobile (nombre de lags des erreurs)\n",
    "\n",
    "##### Équation ARIMA(p,d,q)\n",
    "\n",
    "On applique d différenciations à la série, puis :\n",
    "\n",
    "$$\\nabla^d Y_t = c + \\phi_1 \\nabla^d Y_{t-1} + ... + \\phi_p \\nabla^d Y_{t-p} + \\epsilon_t + \\theta_1 \\epsilon_{t-1} + ... + \\theta_q \\epsilon_{t-q}$$\n",
    "\n",
    "##### Cas particuliers\n",
    "\n",
    "- **ARIMA(p, 0, 0)** = AR(p)\n",
    "- **ARIMA(0, 0, q)** = MA(q)\n",
    "- **ARIMA(p, 0, q)** = ARMA(p, q)\n",
    "- **ARIMA(0, 1, 0)** = Marche aléatoire\n",
    "- **ARIMA(0, 1, 1)** = Lissage exponentiel simple\n",
    "\n",
    "Tout réside donc dans la détermination des 3 paramètres p, d et q.\n",
    "\n",
    "#### 4.2.2 Méthodologie d'identification des paramètres (p, d, q)\n",
    "\n",
    "##### Étape 1 : Déterminer d (ordre de différenciation)\n",
    "\n",
    "1. Tester la stationnarité de la série originale (test ADF)\n",
    "2. Si non-stationnaire : appliquer différenciation d'ordre 1\n",
    "3. Tester à nouveau la stationnarité\n",
    "4. Répéter si nécessaire (rarement d > 2)\n",
    "\n",
    "**Règle** : d = nombre de différenciations nécessaires pour obtenir la stationnarité\n",
    "\n",
    "##### Étape 2 : Déterminer p et q\n",
    "\n",
    "Sur la série **différenciée** (stationnaire), analyser ACF et PACF :\n",
    "\n",
    "| Pattern | ACF | PACF | Modèle |\n",
    "|---------|-----|------|--------|\n",
    "| **AR(p)** | Décroissance exp. | Coupure après lag p | ARIMA(p, d, 0) |\n",
    "| **MA(q)** | Coupure après lag q | Décroissance exp. | ARIMA(0, d, q) |\n",
    "| **ARMA(p,q)** | Décroissance exp. | Décroissance exp. | ARIMA(p, d, q) |\n",
    "\n",
    "##### Étape 3 : Validation\n",
    "\n",
    "- Comparer plusieurs modèles candidats\n",
    "- Utiliser les critères AIC (Akaike) et BIC (Bayesian) – cf. section suivante\n",
    "- Le meilleur modèle a le **AIC/BIC le plus faible**\n",
    "- BIC pénalise plus les modèles complexes que AIC\n",
    "- En cas de désaccord : privilégier le modèle le plus parcimonieux\n",
    "\n",
    "Ensuite, une fois que le modèle ARIMA sélectionné a été entraîné sur un ensemble d’entraînement, on peut procéder à un diagnostic du modèle (analyse des résidus…), des prédictions, une évaluation du modèle en calculant des métriques pour mesurer l’écart entre ce qu’il prédit et les valeurs observées (ensemble de test), etc.\n",
    "\n",
    "#### 4.2.3 Détail de fonctionnement du modèle ARIMA (si vous voulez comprendre)\n",
    "\n",
    "Structure mathématique du modèle ARIMA(p,d,q) :\n",
    "Après avoir appliqué d différenciations (∇ᵈYₜ), on modélise :\n",
    "$$\n",
    "\\nabla^d Y_t = c + \\phi_1 \\nabla^d Y_{t-1} + ... + \\phi_p \\nabla^d Y_{t-p} + \\varepsilon_t + \\theta_1 \\varepsilon_{t-1} + ... + \\theta_q \\varepsilon_{t-q}\n",
    "$$\n",
    "\n",
    "Paramètres estimés pendant l’entraînement du modèle :\n",
    "\n",
    "* $\\phi = (\\phi_1, \\ldots , \\phi_p)$ : coefficients autorégressifs (combien chaque valeur passée influence le présent)\n",
    "* $\\theta = (\\theta_1, \\ldots , \\theta_p)$ : coefficients moyenne mobile (combien chaque erreur passée influence le présent)\n",
    "* $c$ : constante (dérive)\n",
    "* $\\sigma^2$ : variance du bruit blanc $\\varepsilon_1$\n",
    "\n",
    "La méthode d'estimation des paramètres est le maximum de vraisemblance :\n",
    "L'algorithme construit la fonction de vraisemblance $L(\\phi, \\theta, c, \\sigma^2 | \\text{ données})$ qui représente la probabilité d'observer les données d'entraînement étant donnés certains paramètres. Sous l'hypothèse que les erreurs $\\varepsilon_t$ suivent une distribution normale $N(0, \\sigma^2)$, on peut écrire cette vraisemblance comme le produit des densités de probabilité de chaque observation conditionnellement aux précédentes. \n",
    "En pratique, on maximise le log-vraisemblance (plus facile numériquement) :\n",
    "$$\n",
    "\\ell(\\phi, \\theta, c, \\sigma^2) = -\\frac{n}{2}\\ln(2\\pi) - \\frac{n}{2}\\ln(\\sigma^2) - \\frac{1}{2\\sigma^2}\\sum_{t=1}^{n}\\varepsilon_t^2(\\phi, \\theta, c)\n",
    "$$\n",
    "L'optimisation se fait avec des algorithmes itératifs (BFGS, Newton-Raphson) qui calculent les gradients et ajustent les paramètres jusqu'à trouver le maximum. Statsmodels utilise des techniques avancées comme le filtre de Kalman pour calculer efficacement la vraisemblance, même avec des paramètres MA.\n",
    "\n",
    "Processus de prévision :\n",
    "Une fois les paramètres estimés $(\\hat{\\phi},\\hat{\\theta}, \\hat{c}, \\hat{\\sigma^2})$ la prévision se fait récursivement :\n",
    "\n",
    "**Horizon h=1** (un pas dans le futur) :\n",
    "\n",
    "$$\n",
    "\\hat{Y}_{T+1} = \\hat{c} + \\hat{\\phi}_1 Y_T + ... + \\hat{\\phi}_p Y_{T-p+1} + \\hat{\\theta}_1 \\varepsilon_T + ... + \\hat{\\theta}_q \\varepsilon_{T-q+1}\n",
    "$$\n",
    "\n",
    "On utilise les vraies valeurs observées jusqu'à T et les vraies erreurs (résidus du modèle).\n",
    "\n",
    "**Horizon h=2** (deux pas dans le futur) :\n",
    "\n",
    "$$\n",
    "\\hat{Y}_{T+2} = \\hat{c} + \\hat{\\phi}_1 \\hat{Y}_{T+1} + \\hat{\\phi}_2 Y_T + ... + \\hat{\\theta}_1 \\varepsilon_{T+1} + \\hat{\\theta}_2 \\varepsilon_T + \\ldots\n",
    "$$\n",
    "\n",
    "**Mais attention :** $\\hat{Y}_{T+1}$ est une prédiction (pas quelque chose d’observé) donc $\\varepsilon_{T+1}$ est inconnu, on le remplace par son espérance = 0\n",
    "\n",
    "**Horizon h=k :** \n",
    "\n",
    "* On remplace toutes les valeurs futures non observées par leurs prédictions\n",
    "* On remplace toutes les erreurs futures par 0 (leur espérance)\n",
    "* Donc l'incertitude augmente car on accumule les erreurs de prédiction\n",
    "\n",
    "**Intervalles de confiance :**\n",
    "La variance de l'erreur de prévision à l'horizon h est :\n",
    "\n",
    "$$Var(\\hat{Y}_{T+h} - Y_{T+h}) = \\sigma^2 \\times f(h, \\phi, \\theta)$$\n",
    "où f(h, φ, θ) est une fonction croissante de h. L'intervalle de confiance à 95% est :\n",
    "\n",
    "$$\\hat{Y}_{T+h} \\pm 1.96 \\times \\sqrt{Var(\\hat{Y}_{T+h} - Y_{T+h})}$$\n",
    "\n",
    "C'est pourquoi les intervalles s'élargissent : plus on va loin dans le futur, plus l'incertitude s'accumule.\n",
    "\n",
    "**Critères de qualité (AIC/BIC) :**\n",
    "Pendant l'entraînement, on évalue aussi :\n",
    "\n",
    "* $AIC = -2 \\log \\hat{L} + 2k$ (pénalise la complexité linéairement)\n",
    "* $BIC = -2 \\log \\hat{L} + k \\log n$ (pénalise plus fortement)\n",
    "\n",
    "où $k = p + q + 1$ (nombre de paramètres) et $\\hat{L}$ est la vraisemblance maximale. Ces critères permettent de comparer différents modèles : le meilleur modèle a le plus petit AIC/BIC.\n",
    "\n",
    "#### 4.2.4 Exemple complet : Modélisation ARIMA d'une série de ventes\n",
    "\n",
    "##### Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf6f4ce-1253-42b2-904f-ba4fe516ed27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d’une série de vente - Marche aléatoire avec AR(1) sur les différences\n",
    "np.random.seed(42)\n",
    "n = 300\n",
    "dates = pd.date_range(start='2019-01-01', periods=n, freq='D')\n",
    "\n",
    "# Créer directement les différences comme un AR(1)\n",
    "diff = [0]\n",
    "bruit = np.random.normal(0, 3, n)\n",
    "for t in range(1, n):\n",
    "    diff.append(0.7 * diff[-1] + bruit[t])\n",
    "\n",
    "# Intégrer pour obtenir la série en niveau (ARIMA au lieu de ARMA)\n",
    "ventes_integrees = np.cumsum(diff) + 100  # Point de départ à 100\n",
    "\n",
    "serie_ventes = pd.Series(ventes_integrees, index=dates, name='Ventes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e099ccb-e470-4c84-bf2b-5bb5088ddcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de la série\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(serie_ventes, linewidth=1.5, color='navy', alpha=0.7)\n",
    "plt.title('Série de Ventes Journalières', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Ventes', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969f2239-531e-4913-a64f-d8003ee0dbca",
   "metadata": {},
   "source": [
    "##### Étape 1 : Déterminer d (ordre de différenciation)\n",
    "\n",
    "On commence par tester si la série est stationnaire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b5c424-025d-4977-a3be-e73e11b8f323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de stationnarité sur la série originale\n",
    "is_stationary = test_stationnarite(serie_ventes, \"Ventes Originales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a132cc-711a-454d-91dc-b4165bed79d8",
   "metadata": {},
   "source": [
    "La série n’est pas stationnaire : il faut donc effectuer une différenciation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50750439-b1a0-4500-95dd-6e465b36a423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Différenciation d'ordre 1\n",
    "serie_diff1 = serie_ventes.diff().dropna()\n",
    "\n",
    "# Test de stationnarité\n",
    "is_stationary_diff1 = test_stationnarite(serie_diff1, \"Ventes Différenciées (d=1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62ab652-46ab-44fe-b620-87e75d2187a2",
   "metadata": {},
   "source": [
    "La série après une première différentiation est stationnaire. Une différenciation d’ordre 1 correspond au paramètre d=1\n",
    "\n",
    "Visualisons ce que cela donne :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f4fd4f-f939-4433-80a8-7f1ef8cd5cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation comparative\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Série originale\n",
    "axes[0].plot(serie_ventes, linewidth=1.5, color='red', alpha=0.7)\n",
    "axes[0].set_title('Série Originale (Non-Stationnaire)', fontsize=13, fontweight='bold')\n",
    "axes[0].set_ylabel('Ventes', fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Série différenciée\n",
    "axes[1].plot(serie_diff1, linewidth=1.5, color='green', alpha=0.7)\n",
    "axes[1].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[1].set_title('Série Différenciée d=1 (Stationnaire)', fontsize=13, fontweight='bold')\n",
    "axes[1].set_xlabel('Date', fontsize=11)\n",
    "axes[1].set_ylabel('Δ Ventes', fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a1f855-964b-4ae9-a7f2-83ac398c4bb0",
   "metadata": {},
   "source": [
    "##### Étape 2 : Déterminer p et q avec ACF/PACF\n",
    "\n",
    "Il faut déterminer à quel type de processus nous avons affaire. Les autocorrélation vont nous aider à décider :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c79909-2636-4351-b52f-76c428f2c07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACF et PACF de la série différenciée\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "fig.suptitle('ACF et PACF de la Série Différenciée (pour identifier p et q)', \n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "# ACF\n",
    "plot_acf(serie_diff1, lags=30, ax=axes[0], alpha=0.05)\n",
    "axes[0].set_title('ACF', fontsize=13, fontweight='bold')\n",
    "axes[0].set_xlabel('Lag', fontsize=11)\n",
    "\n",
    "# PACF\n",
    "plot_pacf(serie_diff1, lags=30, ax=axes[1], alpha=0.05, method='ywm')\n",
    "axes[1].set_title('PACF', fontsize=13, fontweight='bold')\n",
    "axes[1].set_xlabel('Lag', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nAnalyse :\")\n",
    "print(\"  - PACF : pic significatif au lag 1, puis coupure\")\n",
    "print(\"  - ACF : décroissance exponentielle\")\n",
    "print(\"  → Indique un processus AR(1) : p=1 et q=0\")\n",
    "print(\"\\nConclusion : ARIMA(1, 1, 0) semble approprié\")\n",
    "print(\"   On testera aussi ARIMA(1, 1, 1) et ARIMA(2, 1, 0) pour comparaison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c5a10b-1dd7-4693-876e-a2ac62464cd9",
   "metadata": {},
   "source": [
    "##### Étape 3 : Entraînement et comparaison de modèles\n",
    "\n",
    "Comme pour toute méthode de machine learning, il nous faut un ensemble d’entraînement et un ensemble de test. Le problème c’est qu’on ne peut pas mélanger les observations pour constituer les ensembles car l’ordre est important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53180a4d-713d-4111-9ca8-17be066e3ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division train/test (80/20)\n",
    "split_index = int(len(serie_ventes) * 0.8)\n",
    "train = serie_ventes[:split_index]\n",
    "test = serie_ventes[split_index:]\n",
    "\n",
    "print(f\"Ensemble d'entraînement : {len(train)} observations\")\n",
    "print(f\"Ensemble de test : {len(test)} observations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048a5b38-5d6a-401d-9604-c760145b3171",
   "metadata": {},
   "source": [
    "Entraînons différents modèles ARIMA en testant plusieurs valeurs pour les paramètres, et utilisons les critères AIC/BIC pour sélectionner le meilleur modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b1f36d-8cc6-4157-b4dd-84a71275f203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de plusieurs modèles candidats\n",
    "modeles_candidats = [\n",
    "    (1, 1, 0),\n",
    "    (1, 1, 1),\n",
    "    (2, 1, 0),\n",
    "    (0, 1, 1),\n",
    "    (2, 1, 1)\n",
    "]\n",
    "\n",
    "resultats = []\n",
    "\n",
    "for ordre in modeles_candidats:\n",
    "    try:\n",
    "        # Entraînement du modèle\n",
    "        modele = ARIMA(train, order=ordre)\n",
    "        modele_fit = modele.fit()\n",
    "        \n",
    "        # Stockage des résultats\n",
    "        resultats.append({\n",
    "            'Ordre (p,d,q)': f\"ARIMA{ordre}\",\n",
    "            'AIC': modele_fit.aic,\n",
    "            'BIC': modele_fit.bic,\n",
    "            'modele': modele_fit\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur pour ARIMA{ordre}: {e}\")\n",
    "\n",
    "# Tableau comparatif\n",
    "df_resultats = pd.DataFrame(resultats)[['Ordre (p,d,q)', 'AIC', 'BIC']]\n",
    "df_resultats = df_resultats.sort_values('AIC')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARAISON DES MODÈLES CANDIDATS\")\n",
    "print(\"=\"*60)\n",
    "print(df_resultats.to_string(index=False))\n",
    "print(\"\\nLe meilleur modèle a le AIC/BIC le plus faible\")\n",
    "\n",
    "# Sélection du meilleur modèle\n",
    "meilleur_idx = df_resultats.index[0]\n",
    "meilleur_modele = resultats[meilleur_idx]['modele']\n",
    "meilleur_ordre = resultats[meilleur_idx]['Ordre (p,d,q)']\n",
    "\n",
    "print(f\"\\nMeilleur modèle : {meilleur_ordre}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9dfb09-fafb-4bf4-88c8-488ae17b00dc",
   "metadata": {},
   "source": [
    "On dispose classiquement d’une methode `.summary()` qui permet d’obtenir un petit compte rendu de l’entraînement du modèle : paramètres, statistiques, tests, qualité…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70146e2-6924-46f9-95be-744acbd806db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Résumé du modèle\n",
    "print(meilleur_modele.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d7926b-13a3-454c-9dad-413bae8ff2d1",
   "metadata": {},
   "source": [
    "##### Étape 4 : analyse des résidus\n",
    "\n",
    "On peut aussi procéder à un diagnostic « visuel » en traçant des graphes pour analyser les résidus. Ceux-ci doivent :\n",
    "* avoir une distribution normale (tracer histogram + KDE ou un QQ-plot)\n",
    "* avoir une moyenne à 0 (tracer les résidus et voir s’ils oscillent autour de la moyenne)\n",
    "* avoir une variance uniforme (idem)\n",
    "* ne pas montrer de pattern autoregressif (plot_acf / correlogramme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a04fbf-d2dd-4b22-b344-e5faec15b428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic visuel du modèle\n",
    "meilleur_modele.plot_diagnostics(figsize=(16, 12))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3467e2fd-7fc2-424d-b2fa-2a4de38ef116",
   "metadata": {},
   "source": [
    "1. Residus (standardisés) : doivent ressembler à du bruit blanc (moyenne 0, variance constante)\n",
    "2. Histogram + KDE : les résidus doivent suivre une distribution normale\n",
    "3. Q-Q Plot : les points doivent être alignés sur la diagonale (normalité)\n",
    "4. Correlogramme (ACF) : pas de corrélation significative au sein des résidus\n",
    "\n",
    "Il existe aussi un test pour l’autocorrélation des résidus :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e27b43-4dfa-442c-8c27-c8b6a6b04ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de Ljung-Box sur les résidus (test d'autocorrélation)\n",
    "residus = meilleur_modele.resid\n",
    "ljung_box = acorr_ljungbox(residus, lags=10, return_df=True)\n",
    "\n",
    "print(\"\\nTest de Ljung-Box (autocorrélation des résidus) :\")\n",
    "print(ljung_box)\n",
    "print(\"\\nSi p-value > 0.05 : pas d'autocorrélation → résidus = bruit blanc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109c15d1-9cc7-4aae-9ba4-fe9c91d197a6",
   "metadata": {},
   "source": [
    "##### Étape 5 : Prévisions (Forecast)\n",
    "\n",
    "L’objectif de tout modèle de machine learning est de faire des prédictions. Le modèle va réaliser des prédictions de nouveaux point en prédisant à chaque fois le point suivant puis en prédisant un nouveau point à partir du précédent etc. \n",
    "Plus on prédit de point, plus l’erreur/incertitude augmente… On trace donc un intervalle de confiance des prédictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a0355d-b621-461b-b0a6-7c9210be3b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prévisions sur l'ensemble de test\n",
    "n_prev = len(test)\n",
    "previsions = meilleur_modele.forecast(steps=n_prev)\n",
    "\n",
    "# Calcul des intervalles de confiance\n",
    "forecast_obj = meilleur_modele.get_forecast(steps=n_prev)\n",
    "intervalle_confiance = forecast_obj.conf_int()\n",
    "\n",
    "print(f\"Prévisions calculées : {len(previsions)} valeurs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ad3632-35ff-4777-a30f-5515a376d55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des prévisions\n",
    "plt.figure(figsize=(16, 7))\n",
    "\n",
    "# Ensemble d'entraînement\n",
    "plt.plot(train.index, train.values, label='Entraînement', linewidth=2, color='navy')\n",
    "\n",
    "# Ensemble de test (valeurs réelles)\n",
    "plt.plot(test.index, test.values, label='Test (Valeurs Réelles)', \n",
    "         linewidth=2, color='green', marker='o', markersize=4)\n",
    "\n",
    "# Prévisions\n",
    "plt.plot(test.index, previsions, label='Prévisions', \n",
    "         linewidth=2, color='red', linestyle='--', marker='x', markersize=6)\n",
    "\n",
    "# Intervalle de confiance à 95%\n",
    "plt.fill_between(test.index, \n",
    "                 intervalle_confiance.iloc[:, 0], \n",
    "                 intervalle_confiance.iloc[:, 1],\n",
    "                 color='red', alpha=0.2, label='Intervalle de confiance 95%')\n",
    "\n",
    "plt.title(f'Prévisions avec {meilleur_ordre}', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Ventes', fontsize=12)\n",
    "plt.legend(fontsize=11, loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf6e2a7-9f61-4409-9794-59b0d67d6e7f",
   "metadata": {},
   "source": [
    "Notre prédiction est très moyenne (reporte en fait la dernière valeur observée). On verrra si on fait mieux avec des données réelles (exercice 6 suivant)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2787e9c7-516f-4534-9db6-007f29d10c9d",
   "metadata": {},
   "source": [
    "##### Étape 6 : Évaluation des performances (métriques)\n",
    "\n",
    "Vu qu’il s’agit de valeurs numériques, les métriques usuelles dans ce cas pourront être convoquées : RMSE, MAE, MAPE…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7135efd-69f8-43a6-ace7-9e9422638629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculer_metriques(y_true, y_pred):\n",
    "    \"\"\"Calcule les métriques d'évaluation\"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    \n",
    "    return {'RMSE': rmse, 'MAE': mae, 'MAPE': mape}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a56f0d3-0c60-436c-9806-6f851fee2b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des métriques\n",
    "metriques = calculer_metriques(test.values, previsions)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MÉTRIQUES DE PERFORMANCE SUR L'ENSEMBLE DE TEST\")\n",
    "print(\"=\"*60)\n",
    "print(f\"RMSE (Root Mean Squared Error) : {metriques['RMSE']:.4f}\")\n",
    "print(f\"MAE (Mean Absolute Error)      : {metriques['MAE']:.4f}\")\n",
    "print(f\"MAPE (Mean Absolute % Error)   : {metriques['MAPE']:.2f}%\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n💡 Interprétation :\")\n",
    "print(f\"  - En moyenne, les prévisions s'écartent de {metriques['MAE']:.2f} unités des valeurs réelles\")\n",
    "print(f\"  - Erreur relative moyenne : {metriques['MAPE']:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fb9110-8e56-403e-ba80-35a356f99ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des erreurs de prévision\n",
    "erreurs = test.values - previsions\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Distribution des erreurs\n",
    "axes[0].hist(erreurs, bins=20, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "axes[0].axvline(x=0, color='red', linestyle='--', linewidth=2, label='Erreur nulle')\n",
    "axes[0].axvline(x=erreurs.mean(), color='orange', linestyle='--', linewidth=2, \n",
    "                label=f'Moyenne = {erreurs.mean():.2f}')\n",
    "axes[0].set_title('Distribution des Erreurs de Prévision', fontsize=13, fontweight='bold')\n",
    "axes[0].set_xlabel('Erreur', fontsize=11)\n",
    "axes[0].set_ylabel('Fréquence', fontsize=11)\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Erreurs au fil du temps\n",
    "axes[1].plot(test.index, erreurs, marker='o', linewidth=1.5, color='crimson', alpha=0.7)\n",
    "axes[1].axhline(y=0, color='black', linestyle='--', linewidth=2)\n",
    "axes[1].set_title('Erreurs de Prévision au Fil du Temps', fontsize=13, fontweight='bold')\n",
    "axes[1].set_xlabel('Date', fontsize=11)\n",
    "axes[1].set_ylabel('Erreur', fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nStatistiques des erreurs :\")\n",
    "print(f\"  Moyenne : {erreurs.mean():.4f}\")\n",
    "print(f\"  Écart-type : {erreurs.std():.4f}\")\n",
    "print(f\"  Min : {erreurs.min():.4f}\")\n",
    "print(f\"  Max : {erreurs.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eeb780-2b24-4ac9-b4ea-a8778b4cee69",
   "metadata": {},
   "source": [
    "##### Résumé pour se rappeler de la procédure :\n",
    "\n",
    "1. **Visualisation** : Observer tendance, saisonnalité, comportement général (variance, etc.)\n",
    "2. **Test de stationnarité** : ADF sur série originale\n",
    "3. **Différenciation** : Jusqu'à obtenir stationnarité → détermine **d**\n",
    "4. **ACF/PACF** : Sur série stationnaire → identifier **p** et **q**\n",
    "5. **Modèles candidats** : Tester plusieurs combinaisons (p, d, q)\n",
    "6. **Sélection** : Comparer AIC/BIC → choisir le meilleur\n",
    "7. **Diagnostic** : Vérifier que résidus = bruit blanc (Ljung-Box, ACF résidus)\n",
    "8. **Prévision** : Forecast avec intervalles de confiance + évaluation\n",
    "\n",
    "Note :\n",
    "- **d** rarement > 2\n",
    "- Commencer simple : ARIMA(1,1,0), ARIMA(0,1,1)\n",
    "- AIC favorise la prédiction, BIC la parcimonie. Une différence est à prendre en compte si elle est supérieure à 15/20. \n",
    "- Résidus doivent être du bruit blanc (moyenne à 0, variance constante, pas de pattern)\n",
    "- Intervalles de confiance s'élargissent immanquablement avec l'horizon de prévision -> rôle de l’échantillonage. Si vous voulez une prédiction à un mois : mesures mensuelles, si vous voulez une prédiction à un jour : mesures quotidiennes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a16ba73-acc1-4b74-a075-d68aa359894d",
   "metadata": {},
   "source": [
    "#### 4.2.5 Exercice 6 : récapitulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33ceba5-f1eb-4b99-ae62-aacc30e70c2b",
   "metadata": {},
   "source": [
    "Nous allons utiliser des données réelles : le dataset « Lynx » qui contient le nombre annuel de lynx piégés au Canada de 1821 à 1934 (114 observations). C'est un dataset classique en analyse de séries temporelles, notamment utilisé pour illustrer les cycles naturels de populations animales.\n",
    "\n",
    "1. Chargez et visualisez la série, qu’observez-vous ?\n",
    "2. Testez la stationnarité et différenciez si nécessaire. Comparez la série originale avec sa transformée logarithmique. Quelle est l’intérêt d’une telle transformation ? (cf. cours de l’année dernière et les problème d’hétéroscédasticité)\n",
    "4. Analysez ACF et PACF pour identifier p et q\n",
    "5. Entraînez plusieurs modèles ARIMA candidats\n",
    "6. Comparez avec AIC/BIC et sélectionnez le meilleur\n",
    "7. Diagnostiquez le modèle (résidus)\n",
    "8. Réalisez des prévisions et évaluez les performances\n",
    "9. Visualisez les résultats\n",
    "\n",
    "**Modèles attendus** : ARIMA(2,1,0), ARIMA(2,1,1) ou (parfois) ARIMA(11,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd13f6c-f4c3-4b8f-a691-367cb5e669e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du dataset Lynx\n",
    "\n",
    "lynx_data = get_rdataset(\"lynx\", \"datasets\").data\n",
    "dates_lynx = pd.date_range(start='1821', periods=len(lynx_data), freq='YS')\n",
    "serie_lynx = pd.Series(lynx_data['value'].values, index=dates_lynx, name='Lynx piégés')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3278014-bebe-44eb-9de6-617b9aa5eb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCICE 5 - VOTRE CODE\n",
    "\n",
    "# 1. Visualisation\n",
    "# plt.figure(figsize=(14, 6))\n",
    "# plt.plot(serie_lynx, ...)\n",
    "# ...\n",
    "\n",
    "# 2. Test de stationnarité\n",
    "# test_stationnarite(serie_lynx, \"Série Lynx\")\n",
    "# ...\n",
    "\n",
    "# 3. Transformation et différenciation si nécessaire\n",
    "# Indice : variance croissante → transformation ... \n",
    "# serie_lynx_transformed = ...\n",
    "# serie_lynx_diff = ...\n",
    "# ...\n",
    "\n",
    "# 4. ACF et PACF\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "# plot_acf(...)\n",
    "# plot_pacf(...)\n",
    "# ...\n",
    "\n",
    "# 5. Entraînement de plusieurs modèles\n",
    "# modeles = [(2,1,0), (1,1,0), (2,1,1), (11,1,0), (12,1,0)]\n",
    "# ...\n",
    "\n",
    "# 6. Sélection du meilleur modèle\n",
    "# ...\n",
    "\n",
    "# 7. Diagnostic\n",
    "# meilleur_modele.plot_diagnostics(...)\n",
    "# ...\n",
    "\n",
    "# 8. Prévisions et évaluation\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaeb7e4-4b2a-4b08-a310-9d20fdf6f676",
   "metadata": {},
   "source": [
    "## 5. Saisonnalité et modèles SARIMA (optionnel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ed60a1-0706-485b-861c-35e35ba27846",
   "metadata": {},
   "source": [
    "Pour introduire le concept de saisonnalité, déjà observé dans l’exercice précédent, un autre exercice (que nous finirons à la fin de cette section).\n",
    "\n",
    "### 5.1 Exercice 7 : Air Passengers\n",
    "\n",
    "Nous allons récupérer le dataset Air Passengers, qui contient le nombre de passagers aériens mensuels à l’international sur la période (1949-1960). C’est un dataset très classique, présenté par Box & Jenkins (1976) dans leur ouvrage *Time Series Analysis*. Il fait partie des dataset disponibles dans `statsmodels`.\n",
    "\n",
    "Analysez ce dataset :\n",
    "\n",
    "1. Charger le dataset et exploration\n",
    "2. Test de stationnarité et saisonalité :\n",
    "    * tenter une différenctiation d=1\n",
    "    * si cela ne fonctionne pas, appliquez une transformation logarithmique et une différenciation\n",
    "    * si cela ne fonctionne toujours pas, appliquez encore une différenciation (différenciation de degré 2)\n",
    "3. ACF et PACF\n",
    "4. Entraînement de plusieurs modèles\n",
    "5. Sélection du meilleur modèle\n",
    "6. Diagnostic\n",
    "7. Prévisions et évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1688ee-cfb3-4d80-816f-eea20b9223dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du dataset Air Passengers\n",
    "\n",
    "air_data = get_rdataset(\"AirPassengers\", \"datasets\")\n",
    "serie_airpassengers = air_data.data['value']\n",
    "dates = pd.date_range(start='1949-01-01', periods=len(serie_airpassengers), freq='MS')\n",
    "serie_airpassengers.index = dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c713ffc6-5bdb-470b-becc-fff29e2bb9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCICE 7 - VOTRE CODE\n",
    "\n",
    "# 1. Visualisation\n",
    "# ...\n",
    "\n",
    "# 2. Test de stationnarité\n",
    "# ...\n",
    "\n",
    "# 3. Différenciation d=2 si nécessaire\n",
    "# ...\n",
    "\n",
    "# 4. ACF et PACF\n",
    "# ...\n",
    "\n",
    "# 5. Entraînement de plusieurs modèles\n",
    "# modeles = [(1,1,0), (2,1,0), (1,1,1), (2,1,1)]\n",
    "# ...\n",
    "\n",
    "# 6. Sélection du meilleur modèle\n",
    "# ...\n",
    "\n",
    "# 7. Diagnostic\n",
    "# ...\n",
    "\n",
    "# 8. Prévisions et évaluation\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36132c2b-3471-494b-a843-88399d7e4b5a",
   "metadata": {},
   "source": [
    "Que s’est-il passé ? En fait en faisant une double différenciation alors que la période de la saisonnalité est suppérieur à 2, on n’a pas réglé le problème de la saisonnalité.\n",
    "\n",
    "En fait la différenciation d=2 va éliminer une tendance linéaire résiduelle dans les différences. Si après d=1 il reste une légère dérive (tendance dans la variance), d=2 peut l'enlever. Mais ce n’est pas le problème ici ! Au contraire, cette différenciation supplémentaire induit les problèmes typiques d’une sur-différenciation :\n",
    "\n",
    "- d=2 ajoute du bruit au lieu de clarifier\n",
    "- la variance des résidus va augmenter\n",
    "- d=2 conduit à un modèle MA induit artificiellement : différencier deux fois transforme mathématiquement un processus stationnaire en MA(1) : si $Y_t$ est un bruit blanc, alors $\\nabla^2 Y_t = Y_t - 2Y_{t-1} + Y_{t-2} = \\varepsilon_t - 2\\varepsilon_{t-1} + \\varepsilon_{t-2}$ , ce qui crée artificiellement une structure de moyenne mobile qui n'existait pas dans le processus original.\n",
    "- donc les prévisions seront moins bonnes\n",
    "\n",
    "Pour gérer les problème de saisonnalité on va mettre en œuvre un modèle SARIMA (Seasonal ARIMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090e9593-c0a1-4c6e-8aeb-4ee93d44e57e",
   "metadata": {},
   "source": [
    "### 5.2 Saisonnalité\n",
    "\n",
    "#### 5.1.1 Qu'est-ce que la saisonnalité ?\n",
    "\n",
    "La **saisonnalité** désigne des patterns réguliers qui se répètent à intervalles fixes dans une série temporelle. On la découvre généralement à l’aide d’une simple inspection visuelle des données.\n",
    "\n",
    "##### Caractéristiques\n",
    "\n",
    "- **Régularité** : le pattern se répète de manière prévisible\n",
    "- **Période fixe** : intervalle constant (S)\n",
    "- **Amplitude** : peut être constante (additive) ou variable (multiplicative)\n",
    "\n",
    "##### Exemples de saisonnalité\n",
    "\n",
    "| Domaine | Période | Exemple |\n",
    "|---------|---------|----------|\n",
    "| **Retail** | Annuelle (S=12) | Pics de ventes en décembre |\n",
    "| **Tourisme** | Annuelle (S=4) | Haute saison été/hiver |\n",
    "| **Énergie** | Annuelle (S=12) | Consommation chauffage/climatisation |\n",
    "| **Trafic web** | Hebdomadaire (S=7) | Baisse le week-end |\n",
    "| **Température** | Annuelle (S=365) | Cycles saisonniers |\n",
    "\n",
    "##### Limites d'ARIMA classique\n",
    "\n",
    "- ARIMA gère la **tendance** et les **corrélations à court terme**\n",
    "- Mais **ne capture pas les patterns saisonniers** de manière efficace\n",
    "- Il faudrait des ordres p et q très élevés → modèle complexe et peu parcimonieux (p. ex. dans l’exercice sur les Lynx nous sommes monté à ARIMA(11,0,0)\n",
    "\n",
    "**Solution** : SARIMA, qui ajoute des composantes saisonnières spécifiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91219de9-d196-4e8d-91f9-4a81f620272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'une série avec forte saisonnalité\n",
    "np.random.seed(42)\n",
    "n_mois = 60  # 5 ans de données mensuelles\n",
    "dates = pd.date_range(start='2019-01-01', periods=n_mois, freq='MS')\n",
    "\n",
    "# Composantes\n",
    "temps = np.arange(n_mois)\n",
    "tendance = 1000 + 5 * temps  # Croissance linéaire\n",
    "\n",
    "# Saisonnalité annuelle (période = 12 mois)\n",
    "mois = np.array([d.month for d in dates])\n",
    "saisonnalite = 200 * np.sin(2 * np.pi * mois / 12) + 150 * (mois == 12)  # Pic en décembre\n",
    "\n",
    "# Bruit\n",
    "bruit = np.random.normal(0, 30, n_mois)\n",
    "\n",
    "# Série complète\n",
    "ventes_saisonnieres = tendance + saisonnalite + bruit\n",
    "serie_saisonniere = pd.Series(ventes_saisonnieres, index=dates, name='Ventes Mensuelles')\n",
    "\n",
    "print(f\"Série saisonnière créée : {len(serie_saisonniere)} observations\")\n",
    "print(f\"Période : {serie_saisonniere.index[0].strftime('%Y-%m')} à {serie_saisonniere.index[-1].strftime('%Y-%m')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb26a1b-5beb-4c21-a273-d82b828e48f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de la série saisonnière\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.plot(serie_saisonniere, linewidth=2, marker='o', markersize=5, color='steelblue')\n",
    "plt.title('Série de Ventes avec Saisonnalité Annuelle', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Ventes', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3182636a-f2f9-4f95-9043-ad6645fde5e7",
   "metadata": {},
   "source": [
    "- Tendance croissante claire\n",
    "- Patterns qui se répètent chaque année (pics réguliers)\n",
    "- Saisonnalité visible à l'œil nu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c15a09-3135-44ab-b8a3-02e18cc51e88",
   "metadata": {},
   "source": [
    "#### 5.1.3 Décomposition saisonnière\n",
    "\n",
    "La méthode `seasonal_decompose()` du module `statsmodels.tsa.seasonal` nous permet de séparer la composante saisonnière d’une série de sa composante tendancielle et du bruit. Il faut indiquer la péridode de la saison, qu’ici nous estimons annuelle, soit une période de 12 pour des données mensuelles. L’objet retourné nous permet d’accéder à ces différentes composantes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5f3323-cdbc-408a-807e-9fdc655cf9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Décomposition de la série (période = 12 pour saisonnalité annuelle)\n",
    "decomposition = seasonal_decompose(serie_saisonniere, model='additive', period=12)\n",
    "\n",
    "# Visualisation\n",
    "fig, axes = plt.subplots(4, 1, figsize=(16, 14))\n",
    "fig.suptitle('Décomposition Saisonnière (Période = 12 mois)', fontsize=16, fontweight='bold', y=0.995)\n",
    "\n",
    "# Série observée\n",
    "decomposition.observed.plot(ax=axes[0], color='steelblue', linewidth=2)\n",
    "axes[0].set_ylabel('Observé', fontsize=11)\n",
    "axes[0].set_title('Série Originale', fontsize=13, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Tendance\n",
    "decomposition.trend.plot(ax=axes[1], color='green', linewidth=2)\n",
    "axes[1].set_ylabel('Tendance', fontsize=11)\n",
    "axes[1].set_title('Composante Tendance', fontsize=13, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Saisonnalité\n",
    "decomposition.seasonal.plot(ax=axes[2], color='orange', linewidth=2)\n",
    "axes[2].set_ylabel('Saisonnalité', fontsize=11)\n",
    "axes[2].set_title('Composante Saisonnière (Période = 12)', fontsize=13, fontweight='bold')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "# Résidus\n",
    "decomposition.resid.plot(ax=axes[3], color='red', linewidth=1, alpha=0.7)\n",
    "axes[3].set_ylabel('Résidus', fontsize=11)\n",
    "axes[3].set_xlabel('Date', fontsize=11)\n",
    "axes[3].set_title('Résidus', fontsize=13, fontweight='bold')\n",
    "axes[3].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[3].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nAnalyse de la décomposition :\")\n",
    "print(f\"  - Tendance : croissance régulière de {decomposition.trend.dropna().iloc[0]:.0f} à {decomposition.trend.dropna().iloc[-1]:.0f}\")\n",
    "print(f\"  - Saisonnalité : pattern répété chaque année (période = 12 mois)\")\n",
    "print(f\"  - Amplitude saisonnière : ~{decomposition.seasonal.std():.0f} unités\")\n",
    "print(f\"  - Résidus : variance résiduelle = {decomposition.resid.dropna().std():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9711ca63-9f14-46c4-991b-32d398bafb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation du pattern saisonnier isolé (sur une année)\n",
    "pattern_saisonnier = decomposition.seasonal.iloc[:12]\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(range(1, 13), pattern_saisonnier, marker='o', markersize=10, \n",
    "         linewidth=3, color='orange', label='Pattern saisonnier')\n",
    "plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "plt.xticks(range(1, 13), ['Jan', 'Fév', 'Mar', 'Avr', 'Mai', 'Jun', \n",
    "                           'Jul', 'Aoû', 'Sep', 'Oct', 'Nov', 'Déc'])\n",
    "plt.title('Pattern Saisonnier (Effet de chaque mois)', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Mois', fontsize=12)\n",
    "plt.ylabel('Effet Saisonnier', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164939e6-15a2-456f-870c-fbd1706749ba",
   "metadata": {},
   "source": [
    "On constate à la lecture de ce graphique que :\n",
    "- Décembre a l'effet saisonnier le plus élevé (pic de ventes)\n",
    "- Février-Mars ont les valeurs les plus basses\n",
    "\n",
    "En raison de la saisonnalité de cette observation, on observe ce pattern chaque année (répétition)\n",
    "\n",
    "Voilà ce qu’il en est du point de vue descriptif et exploratoire, mais il nous faut établir un modèle, voyons en détail en quoi consiste un modèle SARIMA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71fc94d-bdbf-4196-b175-2cad356366a1",
   "metadata": {},
   "source": [
    "### 5.2 : Modèles SARIMA\n",
    "\n",
    "#### 5.2.1 Structure SARIMA(p,d,q)(P,D,Q)[S]\n",
    "\n",
    "**SARIMA** = **S**easonal **ARIMA**\n",
    "\n",
    "##### Les 7 hyperparamètres\n",
    "\n",
    "Un modèle SARIMA est noté : **SARIMA(p, d, q)(P, D, Q)[S]**\n",
    "\n",
    "##### Partie non-saisonnière (comme ARIMA)\n",
    "- **p** : ordre autorégressif\n",
    "- **d** : ordre de différenciation\n",
    "- **q** : ordre moyenne mobile\n",
    "\n",
    "##### Partie saisonnière (nouvelle)\n",
    "- **P** : ordre autorégressif saisonnier\n",
    "- **D** : ordre de différenciation saisonnière\n",
    "- **Q** : ordre moyenne mobile saisonnier\n",
    "- **S** : période de la saisonnalité (12 pour mensuel annuel, 4 pour trimestriel, 7 pour hebdomadaire)\n",
    "\n",
    "##### Équation SARIMA\n",
    "\n",
    "La série est d'abord différenciée :\n",
    "- **d** fois de manière ordinaire : $\\nabla^d$\n",
    "- **D** fois de manière saisonnière : $\\nabla_S^D$ où $\\nabla_S Y_t = Y_t - Y_{t-S}$\n",
    "\n",
    "Ensuite, on applique les parties AR et MA (ordinaires et saisonnières) sur la série différenciée.\n",
    "\n",
    "##### Exemples de modèles SARIMA\n",
    "\n",
    "- **SARIMA(1,1,1)(1,1,1)[12]** : modèle complet pour données mensuelles\n",
    "- **SARIMA(0,1,1)(0,1,1)[12]** : double lissage exponentiel de Holt-Winters\n",
    "- **SARIMA(1,0,0)(1,0,0)[7]** : AR saisonnier pour données hebdomadaires\n",
    "\n",
    "#### 4.2.2 Différenciation saisonnière\n",
    "\n",
    "##### Différenciation ordinaire vs saisonnière\n",
    "\n",
    "**Différenciation ordinaire (d)** : $\\nabla Y_t = Y_t - Y_{t-1}$\n",
    "- Élimine la tendance\n",
    "\n",
    "**Différenciation saisonnière (D)** : $\\nabla_S Y_t = Y_t - Y_{t-S}$\n",
    "- Élimine la saisonnalité\n",
    "- S = période (12 pour mensuel, 4 pour trimestriel, etc.)\n",
    "\n",
    "On peut **combiner les deux** : $\\nabla \\nabla_S Y_t$ (d=1, D=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b60471b-a1d1-4a57-ad7e-b1921ce5158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Illustration des différenciations\n",
    "\n",
    "# Série originale\n",
    "serie_orig = serie_saisonniere.copy()\n",
    "\n",
    "# Différenciation ordinaire (d=1)\n",
    "serie_diff_ord = serie_orig.diff().dropna()\n",
    "\n",
    "# Différenciation saisonnière (D=1, S=12)\n",
    "serie_diff_sais = serie_orig.diff(12).dropna()\n",
    "\n",
    "# Différenciation combinée (d=1, D=1)\n",
    "serie_diff_combi = serie_orig.diff(12).diff().dropna()\n",
    "\n",
    "print(\"Différenciations appliquées :\")\n",
    "print(f\"  - Série originale : {len(serie_orig)} obs\")\n",
    "print(f\"  - Diff ordinaire (d=1) : {len(serie_diff_ord)} obs\")\n",
    "print(f\"  - Diff saisonnière (D=1, S=12) : {len(serie_diff_sais)} obs\")\n",
    "print(f\"  - Diff combinée (d=1, D=1) : {len(serie_diff_combi)} obs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef2de36-aaa9-4b10-8a12-f841ec1f6d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation comparative\n",
    "fig, axes = plt.subplots(4, 1, figsize=(16, 16))\n",
    "fig.suptitle('Effet des Différentes Différenciations', fontsize=16, fontweight='bold', y=0.995)\n",
    "\n",
    "# Série originale\n",
    "axes[0].plot(serie_orig, linewidth=1.5, color='navy', alpha=0.7)\n",
    "axes[0].set_title('Série Originale (Tendance + Saisonnalité)', fontsize=13, fontweight='bold')\n",
    "axes[0].set_ylabel('Valeur', fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Diff ordinaire\n",
    "axes[1].plot(serie_diff_ord, linewidth=1.5, color='green', alpha=0.7)\n",
    "axes[1].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[1].set_title('Différenciation Ordinaire (d=1) - Élimine la tendance mais garde la saisonnalité', \n",
    "                  fontsize=13, fontweight='bold')\n",
    "axes[1].set_ylabel('Δ Valeur', fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Diff saisonnière\n",
    "axes[2].plot(serie_diff_sais, linewidth=1.5, color='orange', alpha=0.7)\n",
    "axes[2].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[2].set_title('Différenciation Saisonnière (D=1, S=12) - Élimine la saisonnalité mais garde la tendance', \n",
    "                  fontsize=13, fontweight='bold')\n",
    "axes[2].set_ylabel('Δ₁₂ Valeur', fontsize=11)\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "# Diff combinée\n",
    "axes[3].plot(serie_diff_combi, linewidth=1.5, color='red', alpha=0.7)\n",
    "axes[3].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[3].set_title('Différenciation Combinée (d=1, D=1) - Élimine tendance ET saisonnalité', \n",
    "                  fontsize=13, fontweight='bold')\n",
    "axes[3].set_xlabel('Date', fontsize=11)\n",
    "axes[3].set_ylabel('ΔΔ₁₂ Valeur', fontsize=11)\n",
    "axes[3].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518b9786-ca13-4607-88f5-0ce58403da94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests de stationnarité sur les différentes séries\n",
    "test_stationnarite(serie_orig, \"Série Originale\")\n",
    "test_stationnarite(serie_diff_ord, \"Diff Ordinaire (d=1)\")\n",
    "test_stationnarite(serie_diff_sais, \"Diff Saisonnière (D=1)\")\n",
    "test_stationnarite(serie_diff_combi, \"Diff Combinée (d=1, D=1)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4d53cf-d2af-42d9-b5ce-55ffc182c31e",
   "metadata": {},
   "source": [
    "On constate que la différenciation combinée aboutie à une série non-stationnaire sur nos données synthétiques (simulées). C’est un cas typique de **sur-différenciation**.\n",
    "\n",
    "Ça reste une observation surprenante :\n",
    "- d=1 seul → STATIONNAIRE\n",
    "- D=1 seul → STATIONNAIRE\n",
    "- d=1 + D=1 → NON STATIONNAIRE\n",
    "\n",
    "Sur des données SYNTHÉTIQUES avec tendance + saisonnalité ADDITIVE, une seule différenciation suffit souvent, car la combinaison d=1 + D=1 peut CRÉER une structure artificielle :\n",
    "- Augmentation de la variance du bruit\n",
    "- Introduction d'une composante MA non désirée\n",
    "- Test ADF perturbé par la sur-différenciation\n",
    "\n",
    "D’où les conseils suivants quand on mène une analyse saisonnière :\n",
    "1. Tester d=1 seul et D=1 seul SÉPARÉMENT\n",
    "2. Si l'un des deux rend stationnaire → s'arrêter là\n",
    "3. Ne combiner d=1 + D=1 QUE si nécessaire (échec à la différenciation, cf. les données Air Passengers)\n",
    "4. Toujours vérifier la variance avant/après différenciation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731c3f7d-39af-4b0a-a390-6e7058976ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification de la variance\n",
    "print(\"\\nVérification de la variance :\")\n",
    "print(f\"  Variance série originale : {serie_orig.var():.2f}\")\n",
    "print(f\"  Variance après d=1 : {serie_diff_ord.var():.2f}\")\n",
    "print(f\"  Variance après D=1 : {serie_diff_sais.var():.2f}\")\n",
    "print(f\"  Variance après d=1+D=1 : {serie_diff_combi.var():.2f}\")\n",
    "print(\"\\n  → La variance AUGMENTE à nouveau avec la double différenciation !\")\n",
    "print(\"  → Signe typique de sur-différenciation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7166c8-d16d-42f2-946b-c01ced604860",
   "metadata": {},
   "source": [
    "#### 5.2.3 Identification des paramètres saisonniers (P, D, Q)\n",
    "\n",
    "De la même manière que pour ARIMA on peut utiliser `plot_acf()` et `plot_pacf()` pour inspecter et nous guider.\n",
    "\n",
    "##### Méthodologie\n",
    "\n",
    "1. **Déterminer S** : identifier la période de saisonnalité\n",
    "   - Observation visuelle\n",
    "   - Décomposition saisonnière\n",
    "   - ACF : pics significatifs aux multiples de S\n",
    "\n",
    "2. **Déterminer D** : différenciation saisonnière\n",
    "   - Test ADF sur série brute\n",
    "   - Appliquer différenciation saisonnière si nécessaire\n",
    "   - Généralement D = 0 ou D = 1\n",
    "\n",
    "3. **Déterminer d** : différenciation ordinaire (comme pour ARIMA)\n",
    "\n",
    "4. **Déterminer P et Q** : analyser ACF et PACF aux **lags saisonniers** (S, 2S, 3S...)\n",
    "   - Pics aux multiples de S sur ACF → suggère Q\n",
    "   - Pics aux multiples de S sur PACF → suggère P\n",
    "\n",
    "5. **Déterminer p et q** : analyser ACF et PACF aux **lags courts** (comme ARIMA)\n",
    "\n",
    "#### 5.2.4 Entraînement d'un modèle SARIMA\n",
    "\n",
    "Comme on ne peut pas utiliser nos données synthétiques, le code suivant est donné à titre de référence (inutile de l’exécuter). \n",
    "Vous pourrez le tester dans le dernier exercice de ce notebook, où nous reprendrons les données Air Passengers\n",
    "\n",
    "##### Détermination des ensembles de tests/entrainements\n",
    "\n",
    "```python\n",
    "# Division train/test\n",
    "split_idx = int(len(serie_saisonniere) * 0.8)\n",
    "train_sais = serie_saisonniere[:split_idx]\n",
    "test_sais = serie_saisonniere[split_idx:]\n",
    "```\n",
    "\n",
    "##### Entraînement du modèles (en fait plusieurs modèles candidats)\n",
    "\n",
    "```python\n",
    "# Entraînement de plusieurs modèles SARIMA candidats\n",
    "modeles_sarima = [\n",
    "    # (p,d,q), (P,D,Q,S)\n",
    "    ((1,1,1), (1,1,1,12)),\n",
    "    ((0,1,1), (0,1,1,12)),\n",
    "    ((1,1,0), (1,1,0,12)),\n",
    "    ((0,1,0), (1,1,1,12)),\n",
    "    ((1,1,1), (1,1,0,12)),\n",
    "]\n",
    "\n",
    "resultats_sarima = []\n",
    "\n",
    "print(\"Entraînement des modèles SARIMA...\\n\")\n",
    "\n",
    "for ordre, ordre_sais in modeles_sarima:\n",
    "    try:\n",
    "        # Entraînement\n",
    "        modele = SARIMAX(train_sais, order=ordre, seasonal_order=ordre_sais, \n",
    "                        enforce_stationarity=False, enforce_invertibility=False)\n",
    "        modele_fit = modele.fit(disp=False)\n",
    "        \n",
    "        # Stockage\n",
    "        resultats_sarima.append({\n",
    "            'Ordre': f\"SARIMA{ordre}{ordre_sais}\",\n",
    "            'AIC': modele_fit.aic,\n",
    "            'BIC': modele_fit.bic,\n",
    "            'modele': modele_fit\n",
    "        })\n",
    "        print(f\"SARIMA{ordre}{ordre_sais} - AIC: {modele_fit.aic:.2f}, BIC: {modele_fit.bic:.2f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"SARIMA{ordre}{ordre_sais} - Erreur: {str(e)[:50]}\")\n",
    "\n",
    "# Tableau comparatif\n",
    "df_sarima = pd.DataFrame(resultats_sarima)[['Ordre', 'AIC', 'BIC']].sort_values('AIC')\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARAISON DES MODÈLES SARIMA\")\n",
    "print(\"=\"*70)\n",
    "print(df_sarima.to_string(index=False))\n",
    "\n",
    "# Sélection du meilleur\n",
    "meilleur_idx_sais = df_sarima.index[0]\n",
    "meilleur_sarima = resultats_sarima[meilleur_idx_sais]['modele']\n",
    "meilleur_ordre_sais = resultats_sarima[meilleur_idx_sais]['Ordre']\n",
    "\n",
    "print(f\"\\nMeilleur modèle : {meilleur_ordre_sais}\")\n",
    "\n",
    "# Résumé du meilleur modèle\n",
    "print(meilleur_sarima.summary())\n",
    "```\n",
    "\n",
    "#### 5.2.5 Diagnostic du modèle SARIMA\n",
    "\n",
    "```python\n",
    "# Diagnostic visuel\n",
    "meilleur_sarima.plot_diagnostics(figsize=(16, 12))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nVérifications :\")\n",
    "print(\"  1. Résidus doivent osciller autour de 0\")\n",
    "print(\"  2. Histogramme des résidus doit être proche d'une normale\")\n",
    "print(\"  3. Q-Q plot : points alignés sur la diagonale\")\n",
    "print(\"  4. ACF des résidus : pas de corrélation significative\")\n",
    "\n",
    "# Test de Ljung-Box sur les résidus\n",
    "residus_sarima = meilleur_sarima.resid\n",
    "ljung_box_sarima = acorr_ljungbox(residus_sarima, lags=20, return_df=True)\n",
    "\n",
    "print(\"Test de Ljung-Box (Autocorrélation des résidus) :\")\n",
    "print(ljung_box_sarima.head(10))\n",
    "print(\"\\np-value > 0.05 pour la plupart des lags → résidus = bruit blanc \")\n",
    "```\n",
    "\n",
    "#### 5.2.6 Prévisions (forecast) avec SARIMA\n",
    "\n",
    "```python\n",
    "# Prévisions sur l'ensemble de test\n",
    "n_prev_sais = len(test_sais)\n",
    "previsions_sarima = meilleur_sarima.forecast(steps=n_prev_sais)\n",
    "\n",
    "# Intervalles de confiance\n",
    "forecast_sarima = meilleur_sarima.get_forecast(steps=n_prev_sais)\n",
    "ic_sarima = forecast_sarima.conf_int()\n",
    "\n",
    "print(f\"Prévisions SARIMA calculées : {len(previsions_sarima)} valeurs\")\n",
    "\n",
    "# Visualisation des prévisions\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "# Données d'entraînement\n",
    "plt.plot(train_sais.index, train_sais.values, label='Entraînement', \n",
    "         linewidth=2, color='navy')\n",
    "\n",
    "# Données de test (valeurs réelles)\n",
    "plt.plot(test_sais.index, test_sais.values, label='Test (Réel)', \n",
    "         linewidth=2.5, color='green', marker='o', markersize=6)\n",
    "\n",
    "# Prévisions\n",
    "plt.plot(test_sais.index, previsions_sarima, label='Prévisions SARIMA', \n",
    "         linewidth=2.5, color='red', linestyle='--', marker='x', markersize=8)\n",
    "\n",
    "# Intervalle de confiance à 95%\n",
    "plt.fill_between(test_sais.index, \n",
    "                 ic_sarima.iloc[:, 0], \n",
    "                 ic_sarima.iloc[:, 1],\n",
    "                 color='red', alpha=0.2, label='Intervalle de confiance 95%')\n",
    "\n",
    "plt.title(f'Prévisions avec {meilleur_ordre_sais}', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Ventes', fontsize=12)\n",
    "plt.legend(fontsize=11, loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservation :\")\n",
    "print(\"  - Les prévisions SARIMA capturent à la fois la tendance ET la saisonnalité\")\n",
    "print(\"  - Le pattern saisonnier est bien reproduit dans les prévisions\")\n",
    "\n",
    "# Évaluation des performances\n",
    "metriques_sarima = calculer_metriques(test_sais.values, previsions_sarima)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MÉTRIQUES DE PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"RMSE : {metriques_sarima['RMSE']:.4f}\")\n",
    "print(f\"MAE  : {metriques_sarima['MAE']:.4f}\")\n",
    "print(f\"MAPE : {metriques_sarima['MAPE']:.2f}%\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Comparaison avec un modèle ARIMA simple (sans composante saisonnière)\n",
    "print(\"\\nComparaison ARIMA vs SARIMA :\")\n",
    "try:\n",
    "    from statsmodels.tsa.arima.model import ARIMA\n",
    "    arima_simple = ARIMA(train_sais, order=(1,1,1)).fit()\n",
    "    prev_arima_simple = arima_simple.forecast(steps=len(test_sais))\n",
    "    metriques_arima = calculer_metriques(test_sais.values, prev_arima_simple)\n",
    "    \n",
    "    print(f\"\\nARIMA(1,1,1) sans saisonnalité :\")\n",
    "    print(f\"  RMSE : {metriques_arima['RMSE']:.4f}\")\n",
    "    print(f\"  MAE  : {metriques_arima['MAE']:.4f}\")\n",
    "    print(f\"  MAPE : {metriques_arima['MAPE']:.2f}%\")\n",
    "    \n",
    "    print(f\"\\n{meilleur_ordre_sais} :\")\n",
    "    print(f\"  RMSE : {metriques_sarima['RMSE']:.4f}\")\n",
    "    print(f\"  MAE  : {metriques_sarima['MAE']:.4f}\")\n",
    "    print(f\"  MAPE : {metriques_sarima['MAPE']:.2f}%\")\n",
    "    \n",
    "    amelioration = ((metriques_arima['RMSE'] - metriques_sarima['RMSE']) / metriques_arima['RMSE']) * 100\n",
    "    print(f\"\\nSARIMA améliore la RMSE de {amelioration:.1f}% par rapport à ARIMA simple\")\n",
    "except:\n",
    "    print(\"  Comparaison non disponible\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b19d6de-cca2-4d4a-a246-fcf43bc8639d",
   "metadata": {},
   "source": [
    "### EXERCICE 6 : SARIMA - Dataset AirPassengers\n",
    "\n",
    "Pour conclure ce notebook et mettre en application, nous allons mettre en œuvre SARIMA sur une série avec saisonnalité et comparer avec ARIMA\n",
    "\n",
    "Reprenons le dataset **AirPassengers** (1949-1960, mensuel) que nous avons laissé de côté dans l'exercice 5 car il nécessite SARIMA, pas juste ARIMA.\n",
    "\n",
    "**Rappel du problème** : \n",
    "- Tendance croissante\n",
    "- Variance croissante\n",
    "- Mais **Saisonnalité mensuelle (S=12)**\n",
    "- Après log + diff(1), la série n'était pas totalement stationnaire (p ≈ 0.07)\n",
    "  → ARIMA seul ne suffit pas, il faut capturer la saisonnalité !\n",
    "\n",
    "**Consigne** :\n",
    "1. Chargez et visualisez la série (avec transformation log)\n",
    "2. Décomposition saisonnière pour confirmer S=12\n",
    "3. Testez la stationnarité avec différenciations ordinaire ET saisonnière\n",
    "4. Analysez ACF et PACF pour identifier les ordres\n",
    "5. Entraînez plusieurs modèles SARIMA(p,d,q)(P,D,Q)[12]\n",
    "6. **Comparez ARIMA vs SARIMA** pour montrer l'amélioration\n",
    "7. Diagnostiquez le meilleur modèle\n",
    "8. Réalisez des prévisions\n",
    "\n",
    "**Modèles attendus** : SARIMA(0,1,1)(0,1,1)[12] ou SARIMA(0,1,1)(1,1,0)[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43154613-8d5e-4925-95ca-10092bf3a89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du dataset Air Passengers\n",
    "\n",
    "air_data = get_rdataset(\"AirPassengers\", \"datasets\")\n",
    "serie_airpassengers = air_data.data['value']\n",
    "dates = pd.date_range(start='1949-01-01', periods=len(serie_airpassengers), freq='MS')\n",
    "serie_airpassengers.index = dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2674667-8238-4552-b494-7459ef4406aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCICE 6 - VOTRE CODE\n",
    "\n",
    "# 1. Visualisation et transformation log\n",
    "# serie_air_log = np.log(serie_airpassengers)\n",
    "# plt.figure(...)\n",
    "# ...\n",
    "\n",
    "# 2. Décomposition saisonnière\n",
    "# decomp_air = seasonal_decompose(serie_air_log, model='additive', period=12)\n",
    "# ...\n",
    "\n",
    "# 3. S = 12 (mensuel)\n",
    "\n",
    "# 4. Tests de stationnarité et différenciations\n",
    "# test_stationnarite(serie_air_log, \"Log\")\n",
    "# serie_air_diff_ord = serie_air_log.diff().dropna()\n",
    "# serie_air_diff_sais = serie_air_log.diff(12).dropna()\n",
    "# serie_air_diff_combi = serie_air_log.diff(12).diff().dropna()\n",
    "# ...\n",
    "\n",
    "# 5. ACF et PACF\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "# plot_acf(serie_air_diff_combi, lags=40, ...)\n",
    "# plot_pacf(serie_air_diff_combi, lags=40, ...)\n",
    "# ...\n",
    "\n",
    "# 6-7. Entraînement SARIMA et comparaison avec ARIMA\n",
    "# modeles_sarima = [((0,1,1), (0,1,1,12)), ((0,1,1), (1,1,0,12)), ...]\n",
    "# modeles_arima = [(0,1,1), (1,1,1), ...]\n",
    "# Comparer les AIC/BIC\n",
    "# ...\n",
    "\n",
    "# 8. Diagnostic\n",
    "# meilleur_modele.plot_diagnostics(...)\n",
    "# ...\n",
    "\n",
    "# 9. Prévisions\n",
    "# N'oubliez pas de reconvertir avec np.exp() !\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fb069c-b6e3-4fb2-b752-c899766246e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Décomposition saisonnière (S=12 pour mensuel)\n",
    "decomp_air = seasonal_decompose(serie_air_log, model='additive', period=12)\n",
    "\n",
    "fig, axes = plt.subplots(4, 1, figsize=(14, 12))\n",
    "fig.suptitle('Décomposition Saisonnière (Période = 12 mois)', fontsize=16, fontweight='bold')\n",
    "\n",
    "decomp_air.observed.plot(ax=axes[0], color='steelblue', linewidth=2)\n",
    "axes[0].set_ylabel('Observé', fontsize=11)\n",
    "axes[0].set_title('Série Originale (log)', fontsize=12)\n",
    "\n",
    "decomp_air.trend.plot(ax=axes[1], color='green', linewidth=2)\n",
    "axes[1].set_ylabel('Tendance', fontsize=11)\n",
    "axes[1].set_title('Tendance (croissance du trafic aérien)', fontsize=12)\n",
    "\n",
    "decomp_air.seasonal.plot(ax=axes[2], color='orange', linewidth=2)\n",
    "axes[2].set_ylabel('Saisonnalité', fontsize=11)\n",
    "axes[2].set_title('Saisonnalité (pic en été, creux en hiver)', fontsize=12)\n",
    "\n",
    "decomp_air.resid.plot(ax=axes[3], color='red', linewidth=1)\n",
    "axes[3].set_ylabel('Résidus', fontsize=11)\n",
    "axes[3].set_xlabel('Mois', fontsize=11)\n",
    "axes[3].set_title('Résidus', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "conclusions = '''\n",
    "Période identifiée : S = 12 (mensuelle/annuelle)\n",
    "La décomposition montre clairement :\n",
    "- Tendance : croissance linéaire (en log)\n",
    "- Saisonnalité : pattern annuel répété\n",
    "- Résidus : relativement faibles et aléatoires\n",
    "'''\n",
    "\n",
    "print(conclusions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817f28b8-cd82-4c93-9ea9-4d88115f4de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6-7. Entraînement et comparaison ARIMA vs SARIMA\n",
    "split_air = int(len(serie_air_log) * 0.8)\n",
    "train_air = serie_air_log[:split_air]\n",
    "test_air = serie_air_log[split_air:]\n",
    "\n",
    "print(f\"Train : {len(train_air)} mois ({train_air.index[0].strftime('%Y-%m')} à {train_air.index[-1].strftime('%Y-%m')})\")\n",
    "print(f\"Test  : {len(test_air)} mois ({test_air.index[0].strftime('%Y-%m')} à {test_air.index[-1].strftime('%Y-%m')})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARAISON : ARIMA vs SARIMA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Modèles SARIMA (avec composante saisonnière)\n",
    "print(\"\\nModèles SARIMA (p,d,q)(P,D,Q)[12] :\")\n",
    "modeles_sarima = [\n",
    "    ((0,1,1), (0,1,1,12)),  # Modèle classique Box-Jenkins\n",
    "    ((0,1,1), (1,1,0,12)),  # Alternative\n",
    "    ((1,1,1), (0,1,1,12)),  # Avec AR court\n",
    "    ((0,1,1), (1,1,1,12)),  # Combinaison\n",
    "    ((1,1,0), (0,1,1,12)),  # AR court, MA saisonnier\n",
    "]\n",
    "\n",
    "resultats_sarima = []\n",
    "for ordre, ordre_sais in modeles_sarima:\n",
    "    try:\n",
    "        modele = SARIMAX(train_air, order=ordre, seasonal_order=ordre_sais,\n",
    "                        enforce_stationarity=False, enforce_invertibility=False)\n",
    "        modele_fit = modele.fit(disp=False)\n",
    "        resultats_sarima.append({\n",
    "            'Ordre': f\"SARIMA{ordre}{ordre_sais}\",\n",
    "            'Type': 'SARIMA',\n",
    "            'AIC': modele_fit.aic,\n",
    "            'BIC': modele_fit.bic,\n",
    "            'modele': modele_fit\n",
    "        })\n",
    "        print(f\"  SARIMA{ordre}{ordre_sais} - AIC: {modele_fit.aic:.2f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  SARIMA{ordre}{ordre_sais} - Erreur\")\n",
    "\n",
    "# Modèles ARIMA (SANS composante saisonnière - pour comparaison)\n",
    "print(\"\\nModèles ARIMA (p,d,q) SANS saisonnalité (pour comparaison) :\")\n",
    "modeles_arima = [\n",
    "    (0,1,1),  # MA(1)\n",
    "    (1,1,1),  # ARMA(1,1)\n",
    "    (2,1,1),  # ARMA(2,1)\n",
    "    (1,1,0),  # AR(1)\n",
    "]\n",
    "\n",
    "resultats_arima = []\n",
    "for ordre in modeles_arima:\n",
    "    try:\n",
    "        modele = ARIMA(train_air, order=ordre)\n",
    "        modele_fit = modele.fit()\n",
    "        resultats_arima.append({\n",
    "            'Ordre': f\"ARIMA{ordre}\",\n",
    "            'Type': 'ARIMA',\n",
    "            'AIC': modele_fit.aic,\n",
    "            'BIC': modele_fit.bic,\n",
    "            'modele': modele_fit\n",
    "        })\n",
    "        print(f\"  ARIMA{ordre} - AIC: {modele_fit.aic:.2f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ARIMA{ordre} - Erreur\")\n",
    "\n",
    "# Combiner les résultats\n",
    "tous_resultats = resultats_sarima + resultats_arima\n",
    "df_comparaison = pd.DataFrame(tous_resultats)[['Type', 'Ordre', 'AIC', 'BIC']].sort_values('AIC')\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARAISON GLOBALE (classés par AIC) :\")\n",
    "print(\"=\"*70)\n",
    "print(df_comparaison.to_string(index=False))\n",
    "\n",
    "meilleur_global = tous_resultats[df_comparaison.index[0]]\n",
    "meilleur_modele_air = meilleur_global['modele']\n",
    "meilleur_ordre_air = meilleur_global['Ordre']\n",
    "meilleur_type = meilleur_global['Type']\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(f\"MEILLEUR MODÈLE : {meilleur_ordre_air} ({meilleur_type})\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Analyse de la différence\n",
    "meilleur_arima = df_comparaison[df_comparaison['Type'] == 'ARIMA'].iloc[0]\n",
    "meilleur_sarima = df_comparaison[df_comparaison['Type'] == 'SARIMA'].iloc[0]\n",
    "\n",
    "print(f\"\\nANALYSE :\")\n",
    "print(f\"  Meilleur ARIMA : {meilleur_arima['Ordre']} (AIC = {meilleur_arima['AIC']:.2f})\")\n",
    "print(f\"  Meilleur SARIMA : {meilleur_sarima['Ordre']} (AIC = {meilleur_sarima['AIC']:.2f})\")\n",
    "print(f\"  Amélioration AIC : {meilleur_arima['AIC'] - meilleur_sarima['AIC']:.2f} points\")\n",
    "print(f\"\\nCONCLUSION :\")\n",
    "print(f\"  SARIMA est NETTEMENT MEILLEUR qu'ARIMA pour cette série !\")\n",
    "print(f\"  La composante saisonnière (P,D,Q)[12] est ESSENTIELLE.\")\n",
    "print(f\"  C'est pourquoi nous ne pouvions pas modéliser AirPassengers\")\n",
    "print(f\"  correctement dans l'exercice 5 (ARIMA seul).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4284718-4ed4-48fd-9ff6-c883da18f88f",
   "metadata": {},
   "source": [
    "## Pour aller plus loin\n",
    "\n",
    "### Modèles, bibliothèques\n",
    "\n",
    "- **SARIMAX** : ajoute des variables exogènes\n",
    "- **Darts** : une bibliothèque pour les séries temporelles\n",
    "```python\n",
    "!pip install darts --quiet\n",
    "\n",
    "import darts\n",
    "print(f\"Darts version: {darts.__version__}\")\n",
    "```\n",
    "- **Prophet** (Facebook) : gestion automatique de la saisonnalité\n",
    "- **LSTM/GRU** : réseaux de neurones récurrents pour séries temporelles\n",
    "- **Transformer models** : attention mechanism pour séries temporelles\n",
    "\n",
    "### Où trouver des séries temporelles :\n",
    "\n",
    "- API comme Yahoo! Finance `pip install yfinance` pour des données boursières\n",
    "- API comme [Google Trends](https://trends.google.com/)  `pip install pytrends` (popularité des recherches Google dans le temps), par exemple essayez d’analyser et de mettre en relation des recherches comme `'hot weather'` et `'ice cream'`\n",
    "- API données météo par exemple, etc.\n",
    "- les sites déjà conseillés mettant à disposition des données  ([Kaggle](https://kaggle.com/), [data.gouv.fr](https://www.data.gouv.fr/), etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce15ad1-ecb4-4dea-8115-d08a202016c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
